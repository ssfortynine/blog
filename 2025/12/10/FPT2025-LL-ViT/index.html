<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> (FPT2025)LL-ViT · ssfortynine's Blog</title><meta name="description" content="(FPT2025)LL-ViT - ssfortynine"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/cat.png"><link rel="stylesheet" href="/css/apollodark.css"><link rel="search" type="application/opensearchdescription+xml" href="https://ssfortynine.xyz/sitemap.xml/atom.xml" title="ssfortynine's Blog"><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="ssfortynine's Blog" type="application/atom+xml">
</head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/cat.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">WEIBO</a></li><li class="nav-list-item"><a href="https://github.com/ssfortynine" target="_blank" class="nav-list-link">GITHUB</a></li><li class="nav-list-item"><a href="/atom.xml" target="_self" class="nav-list-link">RSS</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">(FPT2025)LL-ViT</h1><div class="post-info">Dec 10, 2025</div><div class="post-content"><h2 id="背景与动机"><a href="#背景与动机" class="headerlink" title="背景与动机"></a>背景与动机</h2><p>视觉变换器（ViTs）在计算机视觉任务中表现出色，但计算量大、内存占用高，难以在资源受限的边缘设备（如 FPGA）上部署。传统的优化方法（如量化、片外权重加载）通常在延迟、能耗或精度上存在严重的权衡。在典型的 ViT 模型中，<strong>通道混合器（即 MLP 层）占据了超过 60% 的模型权重和 50-70% 的乘累加（MAC）操作</strong>。</p>
<ul>
<li>作者提出使用<strong>基于查找表（LUT）的神经元</strong>来替代传统的 MLP 层。与传统的“无乘法网络”不同，LL-ViT 不是简单地将乘法替换为查找，而是采用了一种可以原生学习 LUT 函数的神经架构。（神经网络叠神经网络）<br><img src="/assets/IMG_0083.jpeg" alt="alt text"></li>
</ul>
<h2 id="算法与架构设计"><a href="#算法与架构设计" class="headerlink" title="算法与架构设计"></a>算法与架构设计</h2><p>LL-ViT 设计了一种全新的<strong>基于 LUT 的通道混合器 (LUT-based Channel Mixer)</strong>，并将其集成到标准的 Transformer 编码器中。</p>
<h3 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h3><p>LL-ViT 保持了标准 ViT 的宏观结构，由一系列编码器块组成。</p>
<ul>
<li><strong>令牌混合器 (Token Mixer)：</strong> 保留了多头自注意力（MHA）机制，用于捕获令牌间的空间关系。</li>
<li><strong>通道混合器 (Channel Mixer)：</strong> 将传统的 MLP（由矩阵乘法和非线性激活组成）替换为<strong>基于 LUT 的无乘法模块</strong>。<br><img src="/assets/IMG_0085.jpeg" alt="alt text"></li>
</ul>
<h3 id="基于-LUT-的通道混合器算法细节"><a href="#基于-LUT-的通道混合器算法细节" class="headerlink" title="基于 LUT 的通道混合器算法细节"></a>基于 LUT 的通道混合器算法细节</h3><p>其处理流程如下：<br><img src="/assets/IMG_0086.jpeg" alt="alt text"></p>
<ol>
<li><strong>输入处理与展开：</strong><br> 由于通道混合器独立处理每个令牌，输入激活矩阵首先被展平，逐行通过后续层。</li>
<li><strong>温度计编码 (Thermometer Encoding)：</strong><br> 将连续的浮点特征值转换为二进制位序列，以便作为 LUT 的输入地址。类似于二值神经网络（BNN），通过比较器将数值转化为位串。训练过程中使用直通估计器 (Straight-Through Estimator, STE) 来计算梯度，解决离散化导致的不可微问题。</li>
</ol>
<div class="tip">
输入的是浮点数，查找表看不懂，所以用温度计编码处理输入（就像是温度计的水银柱）数值越大，亮起的“1”就越多。这样就将复杂的连续数值变成了计算机最喜欢 0 和 1 比特流。
</div>

<ol start="3">
<li><strong>可学习的 LUT 神经元层 (Learned LUT Neurons)：</strong><ul>
<li>这些神经元不进行乘加运算$$y&#x3D;\omega x+b$$，而是直接执行查找操作。前一层的输出位被组合成地址，在 LUT 中查找输出。<br><img src="/assets/IMG_0087.jpeg" alt="alt text"></li>
<li><strong>训练方法：</strong> 采用了 <strong>DWN (Differentiable Weightless Networks)</strong> 中的技术，利用**扩展有限差分 (EFD)**来定义 LUT 条目的梯度，使得可以通过反向传播直接训练 LUT 的内容及其连接方式。</li>
<li>论文发现两层 LUT 结构（分别为 768 和 192 个 LUT）配合 8 位温度计编码效果最佳。</li>
</ul>
</li>
</ol>
<div class="tip">
将上一步生成的比特流（0 和 1）直接用作为地址索引，比如输入的是 `110` 就去找查找表中第 110 号位置存的是什么（输出通常是 0 或 1）
</div>

<ol start="4">
<li><strong>条件求和层 (Conditional Summation Layer) —— 关键设计</strong>：<ul>
<li>传统的 LUT 网络通常用于分类（输出类别概率），但作为 Transformer 的中间层，它必须输出实值特征向量以保持精度并支持残差连接。</li>
<li>该论文引入了一组可学习的编码值（权重 Wij）。</li>
<li>这是一个<strong>无乘法</strong>的操作，仅根据 LUT 的输出决定是否累加某个值（相当于条件加法）表现为矩阵乘法，完全可微，允许使用 FP 32 进行高精度训练。训练后，这些编码值被量化为 INT 4，进一步压缩模型。<br><img src="/assets/IMG_0088.jpeg" alt="alt text"><br>其中 x_j 是最后一层 LUT 的输出（0或1）。</li>
</ul>
</li>
</ol>
<div class="tip">
查找表找出来的只是一堆 0 和 1，图像分类任务需要精确的数值（比如概率），所以给每个查找表分配一个“权重”，如果查表结果是 1，则加上这个权重值，如果是 0 则忽略。则输出的结果就是 $$Output=\sum (权重 \times 查表结果)$$（这里面其实也没有乘法，只有加法）
</div>

<p><img src="/assets/IMG_0090.jpeg" alt="alt text"></p>
<h2 id="硬件加速器"><a href="#硬件加速器" class="headerlink" title="硬件加速器"></a>硬件加速器</h2><p>LUT 神经元直接映射到 FPGA 的硬件 LUT 资源上，无需消耗 BRAM 来存储权重。设计了乒乓缓冲区（Ping-Pong Buffer）和专用处理单元（PE），实现了通道维度的并行处理和行级流水线。由于模型极度压缩，权重可完全驻留在 FPGA 片上内存中，消除了高能耗的片外内存访问。<br><img src="/assets/IMG_0091.jpeg" alt="alt text"></p>
<h3 id="3-实验评估与结果"><a href="#3-实验评估与结果" class="headerlink" title="3. 实验评估与结果"></a>3. 实验评估与结果</h3><p>论文以 I-ViT-T（INT8 量化模型）作为基线，在 CIFAR-10、CIFAR-100 和 Tiny-ImageNet 等数据集上进行了评估</p>
<ul>
<li><p><strong>模型精度：</strong></p>
<ul>
<li><strong>CIFAR-10:</strong> 95.5% (基线为 95.4%)</li>
<li><strong>CIFAR-100:</strong> 78.8%</li>
<li><strong>Tiny-ImageNet:</strong> 60.9%<br>LL-ViT 在大幅削减计算量的同时，保持了与基线相当甚至略优的精度，这解决了以前基于 LUT 的网络无法处理复杂视觉任务的问题。</li>
</ul>
</li>
<li><p><strong>资源与效率 (在 Virtex FPGA 上)：</strong></p>
<ul>
<li><strong>模型压缩：</strong> 权重减少超过 <strong>60%</strong>。</li>
<li><strong>计算减少：</strong> 乘法操作减少 <strong>50%</strong>。</li>
<li><strong>能效提升：</strong> 相比全量化的 ViT 加速器，能效提升 <strong>1.9倍</strong>。</li>
<li><strong>延迟降低：</strong> 延迟降低 <strong>1.3倍</strong>。</li>
<li><strong>吞吐量：</strong> 在 10.9W 的功耗下达到了 <strong>1083 FPS</strong>。</li>
</ul>
</li>
<li><p><strong>对比分析：</strong></p>
<ul>
<li>与其他无乘法网络（如 LUT-NN）相比，LL-ViT 通过原生学习 LUT，在减少查找和加法操作数量的同时实现了更高的性能。</li>
<li>相比激进量化（如 3-bit）的方案（如 HG-PIPE），LL-ViT 在功耗上低得多（约 1&#x2F;4），更适合边缘场景。</li>
</ul>
</li>
</ul>
<h3 id="4-总结"><a href="#4-总结" class="headerlink" title="4. 总结"></a>4. 总结</h3><p>LL-ViT 成功证明了将<strong>可学习的 LUT 神经元</strong>集成到 <strong>Vision Transformer</strong> 的可行性。通过替换最耗资源的 MLP 层，LL-ViT 实现了算法与硬件的协同设计，在不牺牲精度的前提下，显著降低了模型的内存占用、计算需求和能耗.</p>
</div></article></div><aside id="toc" class="post-toc-sidebar"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%83%8C%E6%99%AF%E4%B8%8E%E5%8A%A8%E6%9C%BA"><span class="toc-number">1.</span> <span class="toc-text">背景与动机</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%97%E6%B3%95%E4%B8%8E%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1"><span class="toc-number">2.</span> <span class="toc-text">算法与架构设计</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84"><span class="toc-number">2.1.</span> <span class="toc-text">整体架构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E-LUT-%E7%9A%84%E9%80%9A%E9%81%93%E6%B7%B7%E5%90%88%E5%99%A8%E7%AE%97%E6%B3%95%E7%BB%86%E8%8A%82"><span class="toc-number">2.2.</span> <span class="toc-text">基于 LUT 的通道混合器算法细节</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%A1%AC%E4%BB%B6%E5%8A%A0%E9%80%9F%E5%99%A8"><span class="toc-number">3.</span> <span class="toc-text">硬件加速器</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%AE%9E%E9%AA%8C%E8%AF%84%E4%BC%B0%E4%B8%8E%E7%BB%93%E6%9E%9C"><span class="toc-number">3.1.</span> <span class="toc-text">3. 实验评估与结果</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E6%80%BB%E7%BB%93"><span class="toc-number">3.2.</span> <span class="toc-text">4. 总结</span></a></li></ol></li></ol></aside><a href="#" onclick="toggleTOC();return false;" class="toc-toggle"></a></main><footer><div class="paginator"><a href="/2025/12/18/Rust-net-monitor/" class="prev">PREV</a><a href="/2025/12/10/FPT2025-Toward-Domain/" class="next">NEXT</a></div><div id="disqus_thread"></div><script>var disqus_shortname = 'ssfortynine seansun';
var disqus_identifier = '2025/12/10/FPT2025-LL-ViT/';
var disqus_title = '(FPT2025)LL-ViT';
var disqus_url = 'https://ssfortynine.xyz/sitemap.xml/2025/12/10/FPT2025-LL-ViT/';
(function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//ssfortynine seansun.disqus.com/count.js" async></script><div class="copyright"><p>© 2025 <a href="https://ssfortynine.xyz/sitemap.xml">ssfortynine</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/ssfortynine/hexo-theme-apollodark" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script></body></html>