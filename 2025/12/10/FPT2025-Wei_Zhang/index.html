<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> (FPT2025)简化FPGA开发：敏捷设计流程带来的挑战和机遇——张薇教授（香港科技大学） · ssfortynine's Blog</title><meta name="description" content="(FPT2025)简化FPGA开发：敏捷设计流程带来的挑战和机遇——张薇教授（香港科技大学） - ssfortynine"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/cat.png"><link rel="stylesheet" href="/css/apollodark.css"><link rel="search" type="application/opensearchdescription+xml" href="https://ssfortynine.xyz/sitemap.xml/atom.xml" title="ssfortynine's Blog"><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="ssfortynine's Blog" type="application/atom+xml">
</head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/cat.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="/tags" target="_self" class="nav-list-link">TAGS</a></li><li class="nav-list-item"><a href="https://github.com/ssfortynine" target="_blank" class="nav-list-link">GITHUB</a></li><li class="nav-list-item"><a href="/atom.xml" target="_self" class="nav-list-link">RSS</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">(FPT2025)简化FPGA开发：敏捷设计流程带来的挑战和机遇——张薇教授（香港科技大学）</h1><div class="post-info">Dec 10, 2025<span class="post-tags"><a href="/tags/Lecture/" class="tag-pill"><span class="hash">#</span><span class="tag-name">Lecture</span></a></span></div><div class="post-content"><h2 id="HLS-编译流程与设计空间爆炸"><a href="#HLS-编译流程与设计空间爆炸" class="headerlink" title="HLS 编译流程与设计空间爆炸"></a>HLS 编译流程与设计空间爆炸</h2><p><img src="/assets/5195998540c45ea6b8039eda79ba3146.jpg" alt="alt text"><br>这张图展示了 HLS 生成 RTL 代码的流程并给出了一个示例，展示了增加 HLS pragma 之后代码的区别</p>
<ul>
<li>gemm（矩阵乘法）的原始代码（gemm.cpp）和优化代码（gemm_opt.cpp）</li>
<li>原始代码使用三重嵌套循环实现矩阵乘法</li>
<li>通过添加<code>#pragma HLS UNROLL factor=2</code>指令，HLS工具会将循环展开，让多个计算同时进行，从而大幅提高速度。<br>可以看到生成的 verilog 的不同</li>
</ul>
<p><img src="/assets/84861a947b1c100bb2c96737079d2c00.jpg" alt="alt text"><br>但问题在于：HLS 有26个常用指令，每个指令有多个参数，组合起来有500万种可能的配置。想象一下，如果每个配置都需要人工尝试，开发人员需要尝试500万次才能找到最佳方案，这显然是不现实的。</p>
<p>所以，HLS 工具需要自动优化能力，帮助开发人员从500万种可能性中快速找到最佳配置。优化后，性能可以提升100倍，这说明了 HLS 指令优化的巨大价值。</p>
<p>图中指出了一些性能优化模型结合 DSE 将原始 HLS 迭代生成调优后的 HLS 代码</p>
<h2 id="分析式性能建模的整体框架"><a href="#分析式性能建模的整体框架" class="headerlink" title="分析式性能建模的整体框架"></a>分析式性能建模的整体框架</h2><p>性能建模通常从 C&#x2F;C++代码开始，通过一个特征化库（Characterized Library）进行分析，最终构建出分析模型 (Analytical Model)。该模型可用于对硬件设计的性能、功耗和面积（PPA）进行早期评估，以 COMBA (ICCAD’17)为例，展示了一段带有函数调用的循环的代码以及对应的控制流图，说明如何通过将结构化分析将逻辑转化为可量化的模型</p>
<p><strong>从代码分析出发，通过建立精确的循环流水线、循环展开、数据流 II 和内存资源等模型，能够高精度地预测硬件行为的性能与资源消耗</strong><br><img src="/assets/844beaa355d27eb2d1e34ec320887ffc.jpg" alt="alt text"></p>
<h3 id="核心延迟建模的方法"><a href="#核心延迟建模的方法" class="headerlink" title="核心延迟建模的方法"></a>核心延迟建模的方法</h3><p>性能建模的关键在于确预测程序（尤其是循环结构）的执行延迟。图中重点阐述了两种主流的延迟模型</p>
<ol>
<li>循环流水线延迟模型（Loop Pipelining Latency Model）: 该模型通过公式计算循环在流水线执行的总周期数，综合考虑了单次迭代的延迟（D_i）、迭代间隔 (II_i)、循环带宽 (B_i)和实际利用率 (U_i) 等因素。反映了在现代硬件（如 FPGA、ASIC）中，循环并非简单串行执行，而是通过流水线重叠不同迭代来提升性能<br>$$<br>Cycle_{L_k}&#x3D;D_i+II_i\cdot (\frac{B_i}{U_i}\cdot B_{i-1}B_{i-2}\cdot\cdot\cdot B_k-1)<br>$$</li>
<li>循环展开延迟模型（Loop Unrolling Latency Model）: 当采用循环展开优化时，延迟计算变得更为复杂。该模型通过递推公式，将外层循环与内层展开后的循环延迟结合起来计算，考虑了不同层级的带宽利用和展开因子 (U_k)，用于评估展开策略对整体延迟的影响<br>$$<br>C_{L_k}^{U_k}&#x3D;C_{L_k+1}^{U_{k+1}}\cdot \frac{B_{k+1}}{U_{k+1}}\cdot U_k+C_{L_k/ L_{k+1}}^{U_k}<br>$$</li>
</ol>
<h3 id="迭代间隔与资源约束建模"><a href="#迭代间隔与资源约束建模" class="headerlink" title="迭代间隔与资源约束建模"></a>迭代间隔与资源约束建模</h3><p>除了延迟、性能建模还需考虑资源限制对并行度的约束</p>
<ul>
<li>数据流 II 模型（Dataflow IOI Model）: 迭代间隔 (II)是流水线中启动连续两次迭代所需的最小周期数。该模型指出，整体 II 取决于所有子模块中最大的 II, 这通常是由最慢的资源或数据依赖决定的<br>$$<br>II&#x3D;II_{max}^{sub}&#x3D;max_{i}(II_i^{sub})<br>$$</li>
<li>内存资源模型 (Memory Resource Model)：该模型公式用于估算实现特定数据结构（如数组）所需的资源存储量。它考虑了数据位宽、存储深度、分区数量等多个维度，确保设计在满足性能目标的同时不超出可用的片上存储资源<br>$$<br>R_{bom}&#x3D;[\frac{\#bits}{width}]\cdot [\frac{\#element}{depth}]\cdot \#partition \cdot d<br>$$</li>
</ul>
<h3 id="优化技术：链接（Chaining）"><a href="#优化技术：链接（Chaining）" class="headerlink" title="优化技术：链接（Chaining）"></a>优化技术：链接（Chaining）</h3><p>图示对比了链接 (Chaining)与非链接 (No Chaining)的操作流程。链接允许将多个逻辑操作在同一个时钟周期内组合执行，从而减少总延迟。</p>
<h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p>最后，图片通过基准测试展示了该性能建模方法的<strong>准确性和实用性</strong>：</p>
<ul>
<li>在<strong>JPEG、Seidel、Rician</strong>等测试用例中，模型预测的延迟与实际硬件实现的误差非常小（<strong>1.54%、0.91%、1.12%</strong>），证明了其高精度。</li>
<li>在<strong>运行时间</strong>方面，对于 Polybench 测试集，模型生成仅需<strong>秒级</strong>；而对于更复杂的应用（如 JPEG、Seidel、Rician），也只需<strong>分钟级</strong>，体现了该方法在实际工程中的高效性。</li>
</ul>
<h2 id="GNN-性能预测"><a href="#GNN-性能预测" class="headerlink" title="GNN 性能预测"></a>GNN 性能预测</h2><p>用图神经网络 (GNN)破解传统高性能计算系统设计中的性能预测难题。其核心思想是将<strong>硬件设计转化为图结构</strong>，让 GNN 学习从设计特征到最终功耗、性能和面积 (PPA 的复杂映射关系，从而实现快速、准确的早期评估，对比传统方法与基于 GNN 的性能预测：</p>
<table>
<thead>
<tr>
<th>特性维度</th>
<th>传统 HLS 性能评估方法</th>
<th>基于 GNN 的性能预测方法</th>
</tr>
</thead>
<tbody><tr>
<td><strong>核心建模方式</strong></td>
<td>基于分析模型、规则或耗时仿真</td>
<td><strong>数据驱动</strong>，从历史设计数据中学习复杂模式</td>
</tr>
<tr>
<td><strong>输入表示</strong></td>
<td>代码、中间表示（IR）或网表</td>
<td><strong>控制数据流图（CDFG）</strong>，将操作和依赖关系转化为图结构</td>
</tr>
<tr>
<td><strong>关键预测维度</strong></td>
<td>通常较为单一或分离</td>
<td><strong>端到端的PPA联合预测</strong>（功耗、性能、面积）</td>
</tr>
<tr>
<td><strong>主要优势</strong></td>
<td>原理清晰，对已知模式有效</td>
<td>能捕获<strong>非线性关系</strong>和<strong>复杂 pragma 指令交互</strong>，预测速度快（毫秒级）</td>
</tr>
<tr>
<td><strong>核心挑战</strong></td>
<td>设计空间巨大导致探索不完备；工具早期估计不准确<a target="_blank" rel="noopener" href="https://espace2.etsmtl.ca/id/eprint/30389/"></a></td>
<td><strong>数据需求大</strong>；模型可解释性如“黑盒”；<strong>泛化能力</strong>面临挑战</td>
</tr>
</tbody></table>
<h3 id="GNN-实现性能预测"><a href="#GNN-实现性能预测" class="headerlink" title="GNN 实现性能预测"></a>GNN 实现性能预测</h3><p>GNN 解决了传统方式难以处理的两个问题：设计空间的指数级复杂性和高级优化指令 (pragma)带来的非线性影响</p>
<p><img src="/assets/37445b3b491947d941f8b764d9264231.jpg" alt="alt text"></p>
<ol>
<li><p><strong>图构建</strong>：将设计转化为 CDFG<br> 如图所示，GNN 的输入不是原始代码，而是从 C&#x2F;C++代码经过中间表示 (IR)转换得到的控制数据流图。图中的节点表示运算符（如加法、乘法、访存），边则代表数据控制依赖关系。这种表示方法保留了程序的结构和并行性信息</p>
</li>
<li><p><strong>层次化建模</strong><br> 层次化图结构是实现复杂设计的关键。它通过<strong>内存（循环子图）和外层（模块间连接）的分层抽象</strong>，让 GNN 能够理解局部计算模式（如一个流水线循环），再整合全局互连和优化（如循环展开、数组分割）的影响，融合不同来源和抽象级别的设计特征</p>
</li>
<li><p><strong>消息传递与预测</strong><br> GNN 通过“消息传递”机制再图结构中迭代聚合邻域信息。在这个过程中，模型能学习到特定操作（比如一个乘法器）再特定上下文（如处于一个深度流水线中）下对资源和时序的真实影响，最终聚合全图信息，输出对延迟 (Latency)、查找表 (LUT）、触发器 (FF)、数字信号处理器（DSP）等关键指标的预测</p>
</li>
</ol>
<h2 id="DSE-算法比较"><a href="#DSE-算法比较" class="headerlink" title="DSE 算法比较"></a>DSE 算法比较</h2><table>
<thead>
<tr>
<th>特性维度</th>
<th><strong>迭代搜索 (启发式&#x2F;ML)</strong></th>
<th><strong>数学规划 (MILP&#x2F;NLP)</strong></th>
<th><strong>LLM 驱动的 DSE (新趋势)</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>核心思想</strong></td>
<td>模拟自然或学习过程进行<strong>启发式探索</strong></td>
<td>将设计空间转化为<strong>数学优化问题</strong>并精确求解</td>
<td>利用大语言模型的<strong>常识与代码能力</strong>生成设计</td>
</tr>
<tr>
<td><strong>优化目标</strong></td>
<td>通用目标，大规模近似<strong>帕累托前沿</strong></td>
<td>特定领域，追求<strong>理论最优解</strong>或高质量可行解</td>
<td>将自然语言描述直接转化为<strong>优化设计点</strong></td>
</tr>
<tr>
<td><strong>关键优点</strong></td>
<td><strong>灵活性高</strong>，适用于黑盒模型；<strong>全局探索</strong>能力强</td>
<td><strong>最优性有保证</strong>，提供整体视角；可严格建模复杂约束</td>
<td><strong>样本效率极高</strong>（零样本&#x2F;少样本）；<strong>端到端</strong>自动化；<strong>交互直观</strong></td>
</tr>
<tr>
<td><strong>主要挑战</strong></td>
<td><strong>样本效率低</strong>；对超参数<strong>敏感</strong>；易陷局部最优</td>
<td><strong>建模复杂</strong>；<strong>求解耗时</strong>；问题规模扩大时<strong>复杂度爆炸</strong></td>
<td><strong>结果不可靠</strong>（幻觉、不一致）；缺乏<strong>理论保证</strong>；领域知识依赖强</td>
</tr>
<tr>
<td><strong>典型应用</strong></td>
<td>早期、大规模设计空间初筛；HLS PPA 预测模型优化</td>
<td>脉动阵列、Stencil 计算等<strong>规则结构化硬件</strong>的精细优化</td>
<td>快速原型设计；基于高层描述探索架构灵感；自动化设计脚本生成</td>
</tr>
</tbody></table>
<p>未来的 DSE 趋势并非只能采用一种方法，而是<strong>多种方法的融合</strong>：利用 LLM 快速生成高质量起点，通过数学规划在局部进行精细调优，再借助基于 ML 的迭代搜索在全局范围内验证鲁棒性，从而构建出更强大、更智能的下一代 EDA 工具链</p>
<h2 id="HLS-编译流程的演变"><a href="#HLS-编译流程的演变" class="headerlink" title="HLS 编译流程的演变"></a>HLS 编译流程的演变</h2><p>传统的 HLS 编译流程<br><img src="/assets/d83e000451fd10027d5e47c6aecf98d6.jpg" alt="alt text"><br>传统的 HLS 采用单一 IR (LLVM IR)，缺乏清晰的循环结构，不利于高级优化。而新的 MLIR 支持多级 IR，可以保留结构信息，允许不同级别进行优化<br><img src="/assets/3e69ddce2796e7017672870ee879ab79.jpg" alt="alt text"></p>
<table>
<thead>
<tr>
<th>特性维度</th>
<th><strong>LLVM IR (传统单级表示)</strong></th>
<th><strong>MLIR (现代多级表示)</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>核心哲学</strong></td>
<td>“万能”的<strong>单一、稳定、底层</strong>的编译器IR</td>
<td><strong>可扩展、多层次</strong>的编译器基础设施框架</td>
</tr>
<tr>
<td><strong>抽象级别</strong></td>
<td>主要集中在低层，接近机器指令</td>
<td><strong>贯穿高级算法到低级硬件</strong>的多层抽象</td>
</tr>
<tr>
<td><strong>结构信息保留</strong></td>
<td><strong>丢失大量高级语义</strong>（如循环、数据流结构）</td>
<td><strong>原生保留并显式表达</strong>高级结构（循环、任务、数据流）</td>
</tr>
<tr>
<td><strong>优化方式</strong></td>
<td>主要在固定层级进行通用优化</td>
<td><strong>渐进式降低抽象级别</strong>，在每一级进行<strong>领域特定优化</strong></td>
</tr>
<tr>
<td><strong>领域适配性</strong></td>
<td>通用性强，但领域特定扩展困难</td>
<td><strong>通过“方言”机制，原生支持领域特定扩展</strong></td>
</tr>
</tbody></table>
<h3 id="通用编译到硬件设计的核心需求"><a href="#通用编译到硬件设计的核心需求" class="headerlink" title="通用编译到硬件设计的核心需求"></a>通用编译到硬件设计的核心需求</h3><p>传统 LLVM IR 在 CPU&#x2F;软件编译上非常成功，但在面对 HLS 时却显露出根本性局限：</p>
<ol>
<li><p><strong>语义鸿沟</strong>：LLVM IR在设计上<strong>剥离了高级语义</strong>（如循环的并行性、数组的分块方式、流水线约束等），而这些恰恰是HLS进行高质量硬件综合所必须的信息。这导致许多本可在高层进行的优化（如循环变换、内存层级映射）无法实施或效果不佳。</p>
</li>
<li><p><strong>优化僵化</strong>：其优化流程相对固定，难以灵活插入<strong>领域特定优化</strong>（如为 FPGA 定制循环流水线策略、为 AI 加速器定制数据流映射）。优化过早降低到低层，丧失了在高抽象级别探索不同实现策略的机会。</p>
</li>
</ol>
<h3 id="MLIR-的核心创新：方言与多层次-IR"><a href="#MLIR-的核心创新：方言与多层次-IR" class="headerlink" title="MLIR 的核心创新：方言与多层次 IR"></a>MLIR 的核心创新：方言与多层次 IR</h3><p>MLIR 通过两大核心设计解决了上述问题：</p>
<ul>
<li><p><strong>方言机制</strong>：这是MLIR的基石。不同抽象级别的操作（如高层的 <code>linalg.matmul</code> 表示矩阵乘法，中层的 <code>affine.for</code> 表示循环，低层的 <code>llvm.load</code> 表示访存）可以共存于同一模块中。这允许HLS工具定义自己的方言（如表示硬件流水线的 <code>pipeline</code> 操作或表示硬件资源的 <code>resource</code> 约束），<strong>将设计意图直接编码在IR中</strong>。</p>
</li>
<li><p><strong>渐进式 lowering</strong>：MLIR的编译流程不是一个“断崖式”的下降。如图所示，优化可以分层次、分阶段进行：</p>
<ul>
<li>在<strong>图形级</strong>，可进行算法级任务划分和粗粒度流水。</li>
<li>在<strong>内核级</strong>，可进行内存布局优化和内核融合。</li>
<li>在<strong>循环级</strong>，可进行展开、流水线、数据流变换。</li>
<li>在<strong>指令级</strong>，最终生成目标 RTL 或 IP 核。<strong>每一级的优化都在最适合的抽象层级上进行，且信息可向下一级传递</strong>。</li>
</ul>
</li>
</ul>
<p>MLIR 的实践项目</p>
<ul>
<li><strong>CIRCT项目</strong>：这是基于MLIR构建开源硬件编译工具链的核心项目。它提供了从高级语言（如Chisel、FIRRTL）到低级硬件描述（如Verilog）的一系列MLIR方言和转换通道，成为了连接算法与硬件的“编译器中间层”</li>
<li><strong>厂商工具革新</strong>：主流FPGA厂商（如Xilinx&#x2F;Xilinx Vitis）和EDA公司正在将MLIR集成到其下一代工具中。例如，通过定义专属方言，工具可以更智能地理解AI模型中的算子，并自动映射到最优的DSP阵列或存储架构上</li>
<li><strong>与 DSE 结合</strong>：结合上一张幻灯片提到的<strong>设计空间探索（DSE）</strong>，MLIR 因其结构化的 IR，使得自动化工具能更容易地分析和施加不同的优化策略（如尝试不同的循环展开因子或流水线启动间隔），并快速评估其效果，从而极大加速了优化决策过程</li>
</ul>
<h2 id="MLIR-带来的新机遇"><a href="#MLIR-带来的新机遇" class="headerlink" title="MLIR 带来的新机遇"></a>MLIR 带来的新机遇</h2><h3 id="算法-硬件解耦-Algorithm-Hardware-Decoupling"><a href="#算法-硬件解耦-Algorithm-Hardware-Decoupling" class="headerlink" title="算法-硬件解耦 (Algorithm-Hardware Decoupling)"></a>算法-硬件解耦 (Algorithm-Hardware Decoupling)</h3><p>传统 HLS 中，算法代码和硬件优化指令混在一起，MLIR 允许将算法和硬件优化分开，开发者只需专注于算法，硬件优化由编译器自动完成。<br><img src="/assets/67b237b749d86d64c766625554817517.jpg" alt="alt text"></p>
<ul>
<li>将算法描述和硬件特定指令分离</li>
<li>使用 DSL 描述算法，通过调度构造器指定硬件特性</li>
</ul>
<h3 id="异构-FPGA-的统一编译栈（Unified-Compilation-Stack）"><a href="#异构-FPGA-的统一编译栈（Unified-Compilation-Stack）" class="headerlink" title="异构 FPGA 的统一编译栈（Unified Compilation Stack）"></a>异构 FPGA 的统一编译栈（Unified Compilation Stack）</h3><p>现代 FPGA 包含多种计算单元（CPU、PL、AIE），传统 HLS 需要为每种设备单独优化，但是 MLIR 提供统一的编译接口，可以自动适配不同的计算单元。<br><img src="/assets/3b000a84be3025391d449452c170cef8.jpg" alt="alt text"></p>
<ul>
<li>将 CPU、PL、AIE 等不同计算单元统一编译</li>
</ul>
<h3 id="动态调度与静态调度比较"><a href="#动态调度与静态调度比较" class="headerlink" title="动态调度与静态调度比较"></a>动态调度与静态调度比较</h3><p><img src="/assets/2f7bcd65e9f7ce6e860b11fbbe76ee89.jpg" alt="alt text"><br>调度是 HLS 优化的关键环节——决定任务如何在硬件上执行。该图比较了两种调度方式：</p>
<ul>
<li><strong>静态调度</strong>：就像固定时间表，无论任务如何变化，都按固定顺序执行。传统 HLS 使用静态调度，虽然简单，但无法充分利用硬件并行性。</li>
<li><strong>动态调度</strong>：Dynamatic 项目使用动态调度，能根据程序运行时的特性自适应调整，提取更多并行性，尤其适合处理”不规则循环”（如条件判断导致的执行路径变化）</li>
</ul>
<p>数据显示，Dynamatic 可以将延迟减少3.5倍，但会增加2.11倍的资源消耗。对于某些应用，这种权衡是值得的，因为延迟减少带来的性能提升远超过资源增加。</p>
<h3 id="动态调度方法实例"><a href="#动态调度方法实例" class="headerlink" title="动态调度方法实例"></a>动态调度方法实例</h3><p>HLS 正从<strong>静态、确定性的编译时调度</strong>，转向<strong>动态、弹性、运行时管理的硬件生成</strong>。本质上是将现代 CPU 中<strong>乱序执行</strong>的智能与灵活性引入到定制硬件中，以应对日益复杂的计算需求。<br><img src="/assets/398b6e08af25ca2de3600f7262706a54.jpg" alt="alt text"></p>
<table>
<thead>
<tr>
<th>特性维度</th>
<th><strong>传统静态调度 HLS (如 Vitis HLS)</strong></th>
<th><strong>动态调度 HLS (弹性数据流架构)</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>调度决策时机</strong></td>
<td><strong>编译时</strong>完全确定</td>
<td><strong>运行时</strong>动态决定</td>
</tr>
<tr>
<td><strong>电路特性</strong></td>
<td><strong>刚性、同步</strong>的时序电路</td>
<td><strong>弹性、延迟不敏感</strong>的握手协议电路</td>
</tr>
<tr>
<td><strong>并行性挖掘</strong></td>
<td>依赖编译分析，限于<strong>规则、可预测</strong>的模式</td>
<td>可挖掘<strong>不规则、数据依赖</strong>的潜在并行</td>
</tr>
<tr>
<td><strong>内存依赖处理</strong></td>
<td>需静态分析，对不确定访问保守</td>
<td>可动态解析，支持<strong>非确定性</strong>内存访问</td>
</tr>
<tr>
<td><strong>核心优势</strong></td>
<td>硬件开销小，时序可控，工具链成熟</td>
<td>性能潜力高，对复杂控制流&#x2F;变量延迟适应性强</td>
</tr>
<tr>
<td><strong>主要代价</strong></td>
<td>对不规则算法性能受限</td>
<td><strong>面积开销大</strong>（增加控制逻辑），时序更难优化</td>
</tr>
</tbody></table>
<h4 id="刚性流水线到弹性数据流"><a href="#刚性流水线到弹性数据流" class="headerlink" title="刚性流水线到弹性数据流"></a>刚性流水线到弹性数据流</h4><p>传统 HLS 将 C 代码综合成类似同步数据流的硬件：每个操作在固定的时钟周期发生。这要求所有循环边界、内存延迟和分支路径都必须在编译时确定，极大限制了不规则算法（如图处理、稀疏计算）的优化能力</p>
<p>动态调度 HLS (也是弹性数据流 HLS)则采用不用范式：</p>
<ul>
<li><strong>延迟不敏感设计</strong>：模块间通过握手协议通信，而非全局时钟同步。一个模块只有在数据到达且下游就绪时才会执行。这自然消除了对固定组合逻辑延迟的担忧，使电路对工艺变化、电压频率缩放更鲁棒性</li>
<li><strong>动态调度</strong>：图中展示的 Merge、Branch、Select 等组件时关键。例如：Merge 单元动态选择最先到达的数据流；Branch 单元根据运行时条件将数据分发到不同路径。实现数据驱动执行</li>
</ul>
<h4 id="核心组件"><a href="#核心组件" class="headerlink" title="核心组件"></a>核心组件</h4><ol>
<li><strong>控制组件</strong>：<ul>
<li><strong>Merge</strong>：动态仲裁多个输入通道，将数据汇入单一流。</li>
<li><strong>Branch</strong>：根据条件将数据流分发至不同路径。</li>
<li><strong>Select</strong>：从多个数据源中选择一个输出。</li>
</ul>
</li>
<li><strong>存储与同步组件</strong>：<ul>
<li><strong>Buffer&#x2F;FIFO</strong>：解耦生产者与消费者，是构建弹性流水线的核心，允许前后级以不同速率执行。</li>
<li><strong>Fork&#x2F;Join</strong>：复制数据流并同步多条路径。</li>
</ul>
</li>
<li><strong>计算组件</strong>：<ul>
<li><strong>Func(…)</strong>：封装实际计算功能（如加法器、乘法器）的单元，其前后均有握手接口。<br>![alt text](&#x2F;assets&#x2F;Pasted image 20251209154935.png)<br>右侧的示例流程清晰展示了动态性：<code>read A[i]</code> 和 <code>read B[i]</code> 两个操作可以<strong>异步、并行地</strong>访问内存，谁先完成谁就先行进入加法器。加法完成后，结果被动态送入分支单元进行判断，后续路径的选择完全由运行时数据决定。</li>
</ul>
</li>
</ol>
<h2 id="HLS-优化"><a href="#HLS-优化" class="headerlink" title="HLS 优化"></a>HLS 优化</h2><p>现在的 HLS 设计流程<br><img src="/assets/c6a6ac8d02d1eaeb6d21ca3903efc9a5.jpg" alt="alt text"></p>
<h3 id="基于模板的设计流程"><a href="#基于模板的设计流程" class="headerlink" title="基于模板的设计流程"></a>基于模板的设计流程</h3><p><img src="/assets/3e987c0f974a402d723df7474c588089.jpg" alt="alt text"><br>现在芯片设计逐渐从<strong>手写静态的、固定的 RTL 代码</strong>，转向<strong>编写能够动态生成定制化硬件的“生成器”程序</strong>。其核心在于，通过<strong>元编程（Meta-Programming）</strong> 将硬件设计提升到一个更高、更参数化的抽象层次，以应对复杂片上系统（SoC）的敏捷开发需求。</p>
<table>
<thead>
<tr>
<th>特性维度</th>
<th><strong>传统 RTL 设计流程</strong></th>
<th><strong>基于模板&#x2F;生成器的设计流程</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>设计载体</strong></td>
<td>手写&#x2F;编辑<strong>静态的Verilog&#x2F;VHDL文件</strong></td>
<td>编写<strong>高级语言（如Scala&#x2F;Chisel）的生成器代码</strong></td>
</tr>
<tr>
<td><strong>核心产出</strong></td>
<td>针对单一配置的、固定的<strong>网表&#x2F;RTL</strong></td>
<td>一个可根据参数<strong>实例化无数种设计</strong>的<strong>生成器程序</strong></td>
</tr>
<tr>
<td><strong>复用与定制</strong></td>
<td>通过复制粘贴、手动修改模块实现，易出错</td>
<td>通过<strong>参数化、继承、组合</strong>在架构层面实现类型安全的复用</td>
</tr>
<tr>
<td><strong>设计探索</strong></td>
<td>修改配置需重新编写代码，迭代慢</td>
<td>调整参数重新生成，<strong>快速进行设计空间探索</strong></td>
</tr>
<tr>
<td><strong>验证重点</strong></td>
<td>验证特定实现的正确性</td>
<td>验证<strong>生成器逻辑</strong>的正确性，确保其所有合法输出均正确</td>
</tr>
<tr>
<td><strong>核心优势</strong></td>
<td>直观，对最终电路有完全控制，工具链成熟</td>
<td><strong>生产力爆炸性提升</strong>，架构一致性极强，利于IP复用与系统集成</td>
</tr>
<tr>
<td><strong>主要挑战</strong></td>
<td>难以管理大规模复杂性，设计空间探索成本高</td>
<td><strong>调试抽象鸿沟</strong>，生成代码的可读性，以及<strong>结构刚性</strong></td>
</tr>
</tbody></table>
<h4 id="元编程与生成器引擎"><a href="#元编程与生成器引擎" class="headerlink" title="元编程与生成器引擎"></a>元编程与生成器引擎</h4><p>以 Chisel 为例简述“<strong>元编程 → 细化 → RTL 实例</strong>”流程</p>
<ol>
<li><strong>元编程</strong>：设计师使用 Scala 等高级语言，编写的是<strong>描述硬件结构和行为的代码</strong>，而非最终的硬件描述本身。这些代码是<strong>参数化</strong>的，可以是一个处理器核的配置（如寄存器位数、缓存大小），也可以是一个互联网络的拓扑结构。</li>
<li><strong>细化</strong>：当给定一组具体参数后，<strong>生成器引擎</strong>（如 Chisel 编译器）会执行这些 Scala 代码。执行过程并非计算数值，而是<strong>构建一个内部的硬件组件对象图</strong>，即“逻辑图”或“RTL 模板”。这个过程是类型安全的，并允许复杂的编译时逻辑。</li>
<li><strong>RTL 实例</strong>：最终，这个内部对象图被<strong>翻译</strong>成标准的 Verilog RTL 代码。这就是“零 RTL 开销”的含义：设计师<strong>从不直接编写或维护最终的 Verilog</strong>，所有 Verilog 都是无错的、由工具从高级描述生成的。</li>
</ol>
<h4 id="优势与局限"><a href="#优势与局限" class="headerlink" title="优势与局限"></a>优势与局限</h4><p><strong>生成器封装了领域专家的最优设计知识</strong></p>
<ul>
<li>例如，一个矩阵乘法脉动阵列的生成器，内部已经固化了对数据流、内存层级和计算阵列的最优组织方式。用户通过调整阵列尺寸、数据位宽等参数，即可在<strong>保证架构最优的前提下</strong>，获得一个针对新需求的高性能实例。</li>
</ul>
<p><strong>调试复杂与结构刚性</strong></p>
<ul>
<li>当生成的 Verilog 出现问题时，设计师需要逆向追溯回生成它的 Scala 代码逻辑。这要求调试者同时理解硬件行为和复杂的软件生成逻辑。</li>
<li>生成器通常预设了<strong>固定的微架构模板</strong>。例如，一个缓存生成器可能允许你设置大小和相联度，但很难将其底层结构从组相联改为全相联。这要求生成器在<strong>灵活性与复杂性</strong>之间做出权衡，过度追求灵活性会使生成器代码本身变得难以维护。</li>
</ul>
<h4 id="典型案例：Rocket-Chip-系统"><a href="#典型案例：Rocket-Chip-系统" class="headerlink" title="典型案例：Rocket Chip 系统"></a>典型案例：Rocket Chip 系统</h4><p>整个复杂 SoC（包含 Rocket CPU 核、TileLink 总线、L2缓存、外设等）<strong>不是一个固定设计</strong>，而是一个由 Chisel 编写的、高度模块化的<strong>生成器框架</strong></p>
<ul>
<li><strong>可组合性</strong>：<code>RocketTile</code>、<code>SystemBus</code>、<code>PeripheryBus</code> 等都是可配置、可替换的组件。用户可以通过混合匹配，快速生成从嵌入式微控制器到多核应用处理器的不同变体。</li>
<li><strong>一致性接口</strong>：所有模块通过标准化的TileLink总线协议互联，这由生成器在架构层面保证，确保了系统集成的正确性。</li>
<li><strong>Chipyard 项目</strong>：正是构建在此基础上的完整<strong>SoC 设计、仿真与流片平台</strong>。</li>
</ul>
<h3 id="混合设计流程-Hybird-Design-Flow"><a href="#混合设计流程-Hybird-Design-Flow" class="headerlink" title="混合设计流程 (Hybird Design Flow)"></a>混合设计流程 (Hybird Design Flow)</h3><p>现代异构计算系统（特别是 CPU+FPGA）设计复杂性的一个系统级解决方案。它并非是单一工具，而是一个集成框架，核心目标是将软件开发的敏捷性与硬件优化的极致性能相结合，实现从算法到可部署加速系统的全栈加速。</p>
<p>![alt text](&#x2F;assets&#x2F;Pasted image 20251209172650.png)<br>该流程将软件与硬件设计分开设计，并通过标准化接口进行协作</p>
<ul>
<li>将高层次算法、控制流、数据准备与任务调度交给主机端 (CPU)，使用 C&#x2F;C++等高级语言开发，利用 CPU 的通用性和丰富的软件生态</li>
<li>将计算密集型、可并行的核心计算内核交给 FPGA 端，通过 HLS 或 RTL 生成实现极致加速，发挥 FPGA 的并行能力和能效优势</li>
<li>通过 OpenCL 异构编程框架和 Xilinx 运行时（XRT）作为接口，自动处理主机与 FPGA 之间的内存分配、数据迁移、内核启动与同步等复杂且易错的底层细节</li>
</ul>
<p>GraFlex——一种基于 FPGA 的灵活散集式（scatter-gather）图处理框架，配备可扩展的互连网络。</p>
<ul>
<li>GraFlex 采用整体同步并行（Bulk-Synchronous Parallel, BSP）模型进行全局控制与同步，通过基于高层次综合（HLS）的设计流程，实现高性能图处理系统的快速部署。</li>
<li>GraFlex 通过软硬件协同优化提升系统性能：它配置了紧凑的<strong>图数据格式、图划分策略以及内存通道分配机制</strong>，以支持可扩展设计</li>
<li>同时，采用资源高效的多级蝶形互连网络，实现片上数据通信并促进吞吐量匹配</li>
<li>为应对碎片化的内存访问请求，提出了合并式内存访问引擎，以提高带宽利用率</li>
<li>实验结果表明，与当前最先进的工作相比，GraFlex 在遍历吞吐量上平均提升高达 2.09 倍，同时显著降低了功耗和资源消耗。以广度优先搜索（BFS）为例的案例研究表明，借助所实现的散集机制及合理的实现选择，其平均算法吞吐量提升了6.58倍。</li>
</ul>
<h4 id="流程解析"><a href="#流程解析" class="headerlink" title="流程解析"></a>流程解析</h4><p><img src="/assets/deepseek_mermaid_20251209_56e607.svg" alt="alt text"></p>
<ol>
<li><strong>设计入口</strong>：对应不同的设计风格和优化目标可采用<ul>
<li><strong>基于 Chisel 的元编程</strong>：用于生成高度定制化、架构复杂的<strong>控制与数据路径</strong>（如图中的 Scatter&#x2F;Gather PE）。它适合构建底层基础设施和需要精细控制微架构的模块。</li>
<li><strong>基于 C&#x2F;C++的 HLS</strong>：用于快速将算法循环或函数转换为硬件加速器。它适合算法工程师快速进行原型验证和性能探索。</li>
</ul>
</li>
<li><strong>自动化内核封装与系统集成</strong>：生成的 RTL 内核会被自动封装成<strong>OpenCL 内核接口</strong>。这是关键一步，它为标准化的主机-设备交互提供了硬件抽象。随后，通过<strong>参数化实例化</strong>，该内核与来自<strong>基础设施 IP 库</strong>的必备组件（如总线接口 AXI、片上存储 BRAM&#x2F;URAM、DMA 控制器等）集成，形成一个完整的<strong>系统块设计</strong>。</li>
<li><strong>全栈编译与部署</strong>：主机端程序与 FPGA 比特流分别编译。最终，通过<strong>Xilinx 运行时（XRT）</strong> 和 Vitis 工具链实现自动集成，形成一个可部署的应用程序。主机程序通过 OpenCL API 调用 FPGA 加速内核，XRT 则透明地管理所有底层硬件操作。</li>
</ol>
<h3 id="LLM-驱动的设计流程"><a href="#LLM-驱动的设计流程" class="headerlink" title="LLM 驱动的设计流程"></a>LLM 驱动的设计流程</h3><p>传统设计流程中，工程师必须将自己对系统的构思，通过严格遵循语法的硬件描述语言（如 Verilog）或工具命令（如 TCL）进行设计。这要求极高的专业性和精准度，任何语法或语义错误都可能导致设计失败。<br>![alt text](&#x2F;assets&#x2F;5911b5aae9153219d3047929705b3484 1.jpg)<br>LLM 驱动的流程彻底改变了这一动态：</p>
<ul>
<li><strong>输入</strong>：设计师用自然语言描述功能、性能目标或架构想法（如“设计一个支持AXI4总线的32位RISC-V CPU核，主频目标500MHz”）。</li>
<li><strong>核心</strong>：LLM充当一位<strong>精通硬件设计、编程语言和工具链的“全能助理”</strong>，将模糊的意图转化为精确的可执行步骤。</li>
<li><strong>输出</strong>：它生成的不是单一代码，而是一个<strong>可工作的工具链输入集合</strong>（HDL、Testbench、约束文件、TCL 脚本），从而直接启动一个标准化的实现流程。</li>
</ul>
<h4 id="构建可靠的-LLM-驱动"><a href="#构建可靠的-LLM-驱动" class="headerlink" title="构建可靠的 LLM 驱动"></a>构建可靠的 LLM 驱动</h4><p><img src="/assets/be9c7d94b5f30b3ca4008f86975f1f65.jpg" alt="alt text"></p>
<ul>
<li><strong>检索增强生成（RAG）</strong> 来解决 LLM“幻觉”和知识过时问题。它会从<strong>公司内部的设计库、IP 数据手册、最佳实践文档和过往错误案例库</strong>中实时检索相关信息，并作为上下文提供给 LLM。这确保了生成的代码符合内部规范、正确调用现有 IP，并规避已知陷阱。</li>
<li><strong>反馈机制</strong>。当生成的代码经过综合、布局布线或仿真后，<strong>时序违规报告、功能覆盖率数据、功耗分析结果</strong>等都会被结构化地反馈给 LLM。LLM 可以据此自动分析问题根源（例如：“关键路径在某个多周期乘法器中，建议插入流水线寄存器”），并生成修正后的代码。这形成了一个<strong>自动化的调试迭代环</strong>，极大地压缩了手动调试的时间。</li>
<li>设计专用领域模型<ul>
<li><strong>微调</strong> 使用高质量的硬件设计代码和对话数据对基础 LLM 进行训练，使其深刻理解硬件设计模式、资源-时序权衡和 EDA 工具语义。</li>
<li><strong>多智能体</strong> 系统可以扮演不同角色：一个“架构师”负责顶层模块划分，一个“验证工程师”负责编写测试用例，一个“后端专家”负责生成物理约束。它们相互协作与校验，共同完成复杂任务。</li>
<li><strong>符号解释</strong> 则是对生成代码进行形式化分析，在仿真前就从数学逻辑上保证某些属性的正确性，提升初始代码质量。</li>
</ul>
</li>
</ul>
<h4 id="实验结果-1"><a href="#实验结果-1" class="headerlink" title="实验结果"></a>实验结果</h4><p><img src="/assets/7cb31e38babf55b723827d4141b54975.jpg" alt="alt text"><br>该图展示了 LLM 在 HDL（硬件描述语言）生成中的最新进展。VerilogEval 数据集是评估 LLM 生成 HDL 代码质量的基准，包含156个案例。</p>
<ul>
<li>GPT-4o：能正确生成60.1%的HDL代码（人类评估），67.7%的代码（机器评估）</li>
<li>Claude 3.7 Sonnet：75.4%和85.3%</li>
<li>MAGE（专为HDL设计的LLM）：94.8%和95.7%</li>
<li>HAVEN：61.1%和77.3%<br>这些数据表明，经过专门训练的 LLM（如 MAGE）能生成高质量的 HDL 代码，准确率接近96%。这意味着，未来开发人员可能只需要用自然语言描述硬件需求，LLM 就能自动生成符合要求的 HDL 代码，就像用自然语言写软件一样简单。</li>
</ul>
<h2 id="未来方向"><a href="#未来方向" class="headerlink" title="未来方向"></a>未来方向</h2><p>如何融合编译器的可靠性、模板设计的性能以及 LLM 的灵活性-&gt;如何充分利用所有优势<br><img src="/assets/6ffde9f602f996cbe21a1d0d6f16ea02.jpg" alt="alt text"></p>
<h3 id="端到端的自主设计平台"><a href="#端到端的自主设计平台" class="headerlink" title="端到端的自主设计平台"></a>端到端的自主设计平台</h3><p>SODA Synthesizer 是一个<strong>开源、模块化、端到端</strong>的硬件编译器框架，旨在自动化地从高级框架描述生成优化的硬件设计。<br><img src="/assets/Pastedimage20251209170921.png" alt="alt text"></p>
<h4 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a>系统架构</h4><p>SODA 采用两级编译架构，强调模块化与可扩展性</p>
<p><strong>在前端设计了 SODA-OPT：</strong></p>
<ul>
<li>基于 MLIR 构建，自动分析 MLIR 代码，识别适合硬件加速的代码区域（内核）并将其提取。</li>
<li>利用 MLIR 方言（如 linalg, affine）的语义信息，进行架构无关的循环变换等高级优化，而<strong>无需手动代码标注</strong>。</li>
<li>通过自定义的 <code>soda</code> 方言，自动将应用划分为<strong>主机程序</strong>（负责协调）和<strong>硬件加速器内核</strong>。<br>生成两类 LLVM IR——优化后的内核 IR（供后端 HLS 使用）和主机代码 IR（供 CPU 编译执行）</li>
</ul>
<p><strong>在后端采用 PandA-Bambu 开源的 HLS 工具</strong></p>
<ul>
<li>接收前端生成的 LLVM IR，执行低位宽分析、调度、绑定等标准 HLS 步骤，生成 Verilog&#x2F;VHDL RTL 代码及测试平台。</li>
</ul>
<p>前后端协同，支持通过不同的编译 pass 序列和参数进行自动化设计空间探索。SODA Synthesizer 通过其创新的<strong>MLIR-based 前端</strong>与强大的<strong>开源 HLS 后端</strong>相结合，提供了一个切实可行的端到端解决方案</p>
<h2 id="跨层"><a href="#跨层" class="headerlink" title="跨层"></a>跨层</h2><h3 id="背景与问题"><a href="#背景与问题" class="headerlink" title="背景与问题"></a>背景与问题</h3><ul>
<li><strong>多芯片FPGA的挑战：</strong> 为了容纳大规模加速器，多芯片（由多个SLR组成）FPGA被广泛使用。然而，跨越芯片边界的连线（SLL）会带来显著的延迟（约1ns），导致时序问题。</li>
<li><strong>现有方法的局限：</strong>   <ul>
<li>传统的HLS指令优化通常只关注单一芯片的资源约束，忽略了多芯片间的跨芯片延迟和特定区域的资源限制。</li>
<li>全局布局规划（Floorplanning）算法（如基于 ILP 的方法）虽然能解决布局问题，但计算复杂度高，运行时间极长，难以与迭代式的指令搜索过程高效结合。</li>
</ul>
</li>
</ul>
<h3 id="FADO-框架"><a href="#FADO-框架" class="headerlink" title="FADO 框架"></a>FADO 框架</h3><p>作者提出了一种<strong>指令与布局规划协同优化（Co-optimization）的方法</strong>，将该问题建模为多维装箱问题（Bin-packing variants）。FADO 包含两个版本的迭代优化流程：</p>
<h4 id="FADO-1-0：基于综合（Synthesis-based）的流"><a href="#FADO-1-0：基于综合（Synthesis-based）的流" class="headerlink" title="FADO 1.0：基于综合（Synthesis-based）的流"></a>FADO 1.0：基于综合（Synthesis-based）的流</h4><ul>
<li><strong>方法：</strong><ul>
<li><strong>QoR 库：</strong> 预先运行HLS工具生成函数级别的质量结果（QoR）库（包含延迟和资源消耗）。</li>
<li><strong>贪婪搜索：</strong> 基于延迟瓶颈（Latency bottleneck）引导的指令搜索。</li>
<li><strong>增量式布局合法化：</strong> 替代全局布局算法。使用在线“最差适应”（Worst-Fit）算法平衡资源，以及离线“最佳适应递减”（Best-Fit Decreasing）算法重排布局。</li>
<li><strong>流水线插入：</strong> 在跨芯片边界的长连线上增量添加流水线寄存器。</li>
</ul>
</li>
<li><strong>缺点：</strong> 构建 QoR 库需要极长的预处理时间（数小时）</li>
</ul>
<h4 id="FADO-2-0：基于解析模型（Analytical-Model）的流程（本文扩展重点）"><a href="#FADO-2-0：基于解析模型（Analytical-Model）的流程（本文扩展重点）" class="headerlink" title="FADO 2.0：基于解析模型（Analytical Model）的流程（本文扩展重点）"></a>FADO 2.0：基于解析模型（Analytical Model）的流程（本文扩展重点）</h4><ul>
<li><strong>改进点：</strong> 旨在消除耗时的QoR库生成过程，并探索更广阔的设计空间。</li>
<li><strong>解析 QoR 模型：</strong> 基于COMBA模型开发并校准，支持任意数据类型和位宽。它能快速估算给定指令配置下的延迟和资源，无需运行HLS综合。</li>
<li><strong>智能搜索策略：</strong> 重新设计了指令搜索算法，通过分析循环层级结构（单循环与多循环搜索），不仅收敛速度更快，还能平衡 BRAM、URAM 和 LUTRAM 的使用，从而提升频率</li>
</ul>
<h3 id="关键技术细节"><a href="#关键技术细节" class="headerlink" title="关键技术细节"></a>关键技术细节</h3><ul>
<li><strong>问题建模：</strong> 将问题公式化为最小化总延迟，同时满足每个 SLR 的资源约束、跨芯片连接约束（SLL 数量）以及特定模块（如通过 RAM 连接的模块）的分组约束。</li>
<li><strong>增量布局规划（Incremental Floorplanning）：</strong> 这是FADO的核心。当指令改变导致模块资源变化时，FADO不进行全局重排，而是通过在线和离线算法微调模块位置，极大地减少了搜索时间。</li>
<li><strong>Look-ahead&#x2F;Look-back 机制：</strong> 为了应对非单调的设计空间（即资源增加不一定带来延迟减少），FADO 1.0 引入了向前&#x2F;向后搜索采样策略；FADO 2.0 则通过改进的搜索顺序自然地解决了这一问题。</li>
</ul>
<h3 id="实验结果-2"><a href="#实验结果-2" class="headerlink" title="实验结果"></a>实验结果</h3><p>在 AMD Alveo U250 FPGA 上，使用混合了数据流（Dataflow）和非数据流内核的大规模基准测试进行了评估：</p>
<ul>
<li><strong>与全局布局规划相比：</strong><ul>
<li><strong>速度：</strong> FADO 1.0 的搜索时间缩短了 <strong>693倍到4925倍</strong>。</li>
<li><strong>性能：</strong> 设计性能（以执行时间衡量）提升了 <strong>1.16倍到8.78倍</strong>。</li>
</ul>
</li>
<li><strong>FADO 2.0 vs. FADO 1.0：</strong><ul>
<li>FADO 2.0 通过解析模型消除了预处理时间。</li>
<li>得益于更广阔的搜索空间和存储资源平衡策略，FADO 2.0 优化后的设计性能比 FADO 1.0 平均进一步提升了 <strong>1.40倍</strong>（排除一个极端特例）。</li>
<li>FADO 2.0 相比基于解析模型的全局布局规划基线，性能平均提升了 <strong>2.66倍</strong>。</li>
</ul>
</li>
</ul>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>*PPT 及其图示来自 FPT 2025 讲座——简化 FPGA 开发：敏捷设计流程带来的挑战和机遇（张薇教授）</p>
</div><div class="post-footer-tags"><a href="/tags/Lecture/" class="tag-pill"><span class="hash">#</span><span class="tag-name">Lecture</span></a></div></article></div><aside id="toc" class="post-toc-sidebar"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#HLS-%E7%BC%96%E8%AF%91%E6%B5%81%E7%A8%8B%E4%B8%8E%E8%AE%BE%E8%AE%A1%E7%A9%BA%E9%97%B4%E7%88%86%E7%82%B8"><span class="toc-number">1.</span> <span class="toc-text">HLS 编译流程与设计空间爆炸</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E6%9E%90%E5%BC%8F%E6%80%A7%E8%83%BD%E5%BB%BA%E6%A8%A1%E7%9A%84%E6%95%B4%E4%BD%93%E6%A1%86%E6%9E%B6"><span class="toc-number">2.</span> <span class="toc-text">分析式性能建模的整体框架</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E5%BB%B6%E8%BF%9F%E5%BB%BA%E6%A8%A1%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-number">2.1.</span> <span class="toc-text">核心延迟建模的方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%AD%E4%BB%A3%E9%97%B4%E9%9A%94%E4%B8%8E%E8%B5%84%E6%BA%90%E7%BA%A6%E6%9D%9F%E5%BB%BA%E6%A8%A1"><span class="toc-number">2.2.</span> <span class="toc-text">迭代间隔与资源约束建模</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E6%8A%80%E6%9C%AF%EF%BC%9A%E9%93%BE%E6%8E%A5%EF%BC%88Chaining%EF%BC%89"><span class="toc-number">2.3.</span> <span class="toc-text">优化技术：链接（Chaining）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C"><span class="toc-number">2.4.</span> <span class="toc-text">实验结果</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GNN-%E6%80%A7%E8%83%BD%E9%A2%84%E6%B5%8B"><span class="toc-number">3.</span> <span class="toc-text">GNN 性能预测</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#GNN-%E5%AE%9E%E7%8E%B0%E6%80%A7%E8%83%BD%E9%A2%84%E6%B5%8B"><span class="toc-number">3.1.</span> <span class="toc-text">GNN 实现性能预测</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DSE-%E7%AE%97%E6%B3%95%E6%AF%94%E8%BE%83"><span class="toc-number">4.</span> <span class="toc-text">DSE 算法比较</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HLS-%E7%BC%96%E8%AF%91%E6%B5%81%E7%A8%8B%E7%9A%84%E6%BC%94%E5%8F%98"><span class="toc-number">5.</span> <span class="toc-text">HLS 编译流程的演变</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%9A%E7%94%A8%E7%BC%96%E8%AF%91%E5%88%B0%E7%A1%AC%E4%BB%B6%E8%AE%BE%E8%AE%A1%E7%9A%84%E6%A0%B8%E5%BF%83%E9%9C%80%E6%B1%82"><span class="toc-number">5.1.</span> <span class="toc-text">通用编译到硬件设计的核心需求</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MLIR-%E7%9A%84%E6%A0%B8%E5%BF%83%E5%88%9B%E6%96%B0%EF%BC%9A%E6%96%B9%E8%A8%80%E4%B8%8E%E5%A4%9A%E5%B1%82%E6%AC%A1-IR"><span class="toc-number">5.2.</span> <span class="toc-text">MLIR 的核心创新：方言与多层次 IR</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MLIR-%E5%B8%A6%E6%9D%A5%E7%9A%84%E6%96%B0%E6%9C%BA%E9%81%87"><span class="toc-number">6.</span> <span class="toc-text">MLIR 带来的新机遇</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%97%E6%B3%95-%E7%A1%AC%E4%BB%B6%E8%A7%A3%E8%80%A6-Algorithm-Hardware-Decoupling"><span class="toc-number">6.1.</span> <span class="toc-text">算法-硬件解耦 (Algorithm-Hardware Decoupling)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BC%82%E6%9E%84-FPGA-%E7%9A%84%E7%BB%9F%E4%B8%80%E7%BC%96%E8%AF%91%E6%A0%88%EF%BC%88Unified-Compilation-Stack%EF%BC%89"><span class="toc-number">6.2.</span> <span class="toc-text">异构 FPGA 的统一编译栈（Unified Compilation Stack）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8A%A8%E6%80%81%E8%B0%83%E5%BA%A6%E4%B8%8E%E9%9D%99%E6%80%81%E8%B0%83%E5%BA%A6%E6%AF%94%E8%BE%83"><span class="toc-number">6.3.</span> <span class="toc-text">动态调度与静态调度比较</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8A%A8%E6%80%81%E8%B0%83%E5%BA%A6%E6%96%B9%E6%B3%95%E5%AE%9E%E4%BE%8B"><span class="toc-number">6.4.</span> <span class="toc-text">动态调度方法实例</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%9A%E6%80%A7%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%88%B0%E5%BC%B9%E6%80%A7%E6%95%B0%E6%8D%AE%E6%B5%81"><span class="toc-number">6.4.1.</span> <span class="toc-text">刚性流水线到弹性数据流</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6"><span class="toc-number">6.4.2.</span> <span class="toc-text">核心组件</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HLS-%E4%BC%98%E5%8C%96"><span class="toc-number">7.</span> <span class="toc-text">HLS 优化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E6%A8%A1%E6%9D%BF%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%B5%81%E7%A8%8B"><span class="toc-number">7.1.</span> <span class="toc-text">基于模板的设计流程</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%83%E7%BC%96%E7%A8%8B%E4%B8%8E%E7%94%9F%E6%88%90%E5%99%A8%E5%BC%95%E6%93%8E"><span class="toc-number">7.1.1.</span> <span class="toc-text">元编程与生成器引擎</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%98%E5%8A%BF%E4%B8%8E%E5%B1%80%E9%99%90"><span class="toc-number">7.1.2.</span> <span class="toc-text">优势与局限</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B8%E5%9E%8B%E6%A1%88%E4%BE%8B%EF%BC%9ARocket-Chip-%E7%B3%BB%E7%BB%9F"><span class="toc-number">7.1.3.</span> <span class="toc-text">典型案例：Rocket Chip 系统</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B7%B7%E5%90%88%E8%AE%BE%E8%AE%A1%E6%B5%81%E7%A8%8B-Hybird-Design-Flow"><span class="toc-number">7.2.</span> <span class="toc-text">混合设计流程 (Hybird Design Flow)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90"><span class="toc-number">7.2.1.</span> <span class="toc-text">流程解析</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#LLM-%E9%A9%B1%E5%8A%A8%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%B5%81%E7%A8%8B"><span class="toc-number">7.3.</span> <span class="toc-text">LLM 驱动的设计流程</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9E%84%E5%BB%BA%E5%8F%AF%E9%9D%A0%E7%9A%84-LLM-%E9%A9%B1%E5%8A%A8"><span class="toc-number">7.3.1.</span> <span class="toc-text">构建可靠的 LLM 驱动</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C-1"><span class="toc-number">7.3.2.</span> <span class="toc-text">实验结果</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%AA%E6%9D%A5%E6%96%B9%E5%90%91"><span class="toc-number">8.</span> <span class="toc-text">未来方向</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9A%84%E8%87%AA%E4%B8%BB%E8%AE%BE%E8%AE%A1%E5%B9%B3%E5%8F%B0"><span class="toc-number">8.1.</span> <span class="toc-text">端到端的自主设计平台</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84"><span class="toc-number">8.1.1.</span> <span class="toc-text">系统架构</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B7%A8%E5%B1%82"><span class="toc-number">9.</span> <span class="toc-text">跨层</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%83%8C%E6%99%AF%E4%B8%8E%E9%97%AE%E9%A2%98"><span class="toc-number">9.1.</span> <span class="toc-text">背景与问题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#FADO-%E6%A1%86%E6%9E%B6"><span class="toc-number">9.2.</span> <span class="toc-text">FADO 框架</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#FADO-1-0%EF%BC%9A%E5%9F%BA%E4%BA%8E%E7%BB%BC%E5%90%88%EF%BC%88Synthesis-based%EF%BC%89%E7%9A%84%E6%B5%81"><span class="toc-number">9.2.1.</span> <span class="toc-text">FADO 1.0：基于综合（Synthesis-based）的流</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#FADO-2-0%EF%BC%9A%E5%9F%BA%E4%BA%8E%E8%A7%A3%E6%9E%90%E6%A8%A1%E5%9E%8B%EF%BC%88Analytical-Model%EF%BC%89%E7%9A%84%E6%B5%81%E7%A8%8B%EF%BC%88%E6%9C%AC%E6%96%87%E6%89%A9%E5%B1%95%E9%87%8D%E7%82%B9%EF%BC%89"><span class="toc-number">9.2.2.</span> <span class="toc-text">FADO 2.0：基于解析模型（Analytical Model）的流程（本文扩展重点）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF%E7%BB%86%E8%8A%82"><span class="toc-number">9.3.</span> <span class="toc-text">关键技术细节</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C-2"><span class="toc-number">9.4.</span> <span class="toc-text">实验结果</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="toc-number">10.</span> <span class="toc-text">参考资料</span></a></li></ol></aside><a href="#" onclick="toggleTOC();return false;" class="toc-toggle"></a></main><footer><div class="paginator"><a href="/2025/12/10/FPT2025-Shouyi_Yin/" class="prev">PREV</a><a href="/2025/12/10/FPT2025-vaughn_betz/" class="next">NEXT</a></div><div id="disqus_thread"></div><script>var disqus_shortname = 'ssfortynine seansun';
var disqus_identifier = '2025/12/10/FPT2025-Wei_Zhang/';
var disqus_title = '(FPT2025)简化FPGA开发：敏捷设计流程带来的挑战和机遇——张薇教授（香港科技大学）';
var disqus_url = 'https://ssfortynine.xyz/sitemap.xml/2025/12/10/FPT2025-Wei_Zhang/';
(function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//ssfortynine seansun.disqus.com/count.js" async></script><div class="copyright"><p>© 2025 - 2026 <a href="https://ssfortynine.xyz/sitemap.xml">ssfortynine</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/ssfortynine/hexo-theme-apollodark" target="_blank">hexo-theme-apollodark</a>.</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script></body></html>