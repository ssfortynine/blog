<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>NixOS 安装 Synopsys VCS/Verdi（包含安装包）</title>
      <link href="/2026/01/08/synopsys-tools-install/"/>
      <url>/2026/01/08/synopsys-tools-install/</url>
      
        <content type="html"><![CDATA[<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>在 <a href="https://github.com/ssfortynine/Xilinx-nix">xilinx-nix</a> 中提供了安装 Synopsys 工具和 Xilinx 工具的Nix Shell环境</p><p>在安装 Xilinx 或 Synopsys 工具时，您只需通过该脚本处理安装程序的依赖问题。若遇到报错，可根据提示增补缺失的系统包，即可顺利运行下载器或安装向导。在 xilinx-nix 中提供了两个 Nix 安装环境文件。</p><ul><li><code>xilinx_fhs_install.nix</code>：涵盖了 Xilinx 2024.1 下载器及安装程序所需的核心依赖。</li><li><code>vcs_fhs_install.nix</code>：涵盖了运行 SynopsysInstaller 所需的核心依赖，支持根据实际安装版本灵活调整依赖包。</li></ul><p><strong>使用方法</strong>（在 NixOS 或已安装 Nix 的系统中）：</p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进入 Xilinx 安装环境</span></span><br><span class="line">nix-shell xilinx_fhs_install.nix </span><br><span class="line"><span class="comment"># 进入 Synopsys 安装环境</span></span><br><span class="line">nix-shell vcs_fhs_install.nix</span><br></pre></td></tr></table></figure><p><strong>软件版本说明</strong>：</p><ul><li>NixOS: 25.11</li><li>Xilinx Vivado: 2024.1（从官网下载Linux版安装器）</li><li>Synopsys VCS: 2023.03-SP2（根据Xilinx UG900文档中支持的仿真器版本）</li><li>Synopsys Verdi: 2023版本（建议不低于VCS版本，其他版本未测试）</li></ul><p><strong>学习资源</strong>：</p><ul><li>软件下载（无需VIP，高速下载）： <a href="https://pan.baidu.com/s/1uBfHgb0L5AbcC9fC5SSESA?pwd=u14z%E8%8B%A5%E5%A4%B1%E6%95%88%E8%AF%B7%E5%9C%A8%E5%8D%9A%E5%AE%A2%E8%AF%84%E8%AE%BA%E5%8C%BA%E7%95%99%E8%A8%80">百度网盘链接</a>，我会及时更新）</li><li>Synopsys安装包参考，非 NixOS 系统的人可以直接根据提供资料安装：<a href="https://bbs.eetop.cn/thread-991668-1-1.html">Synopsys vcs verdi 2023 安装包</a></li><li>新版破解工具，主要提供了新版的scl_keygen，这个工具上一个帖子没有：<a href="https://bbs.eetop.cn/thread-963732-1-1.html">求教synopsys lic制作方式</a></li><li>安装教程参考：<a href="https://zhuanlan.zhihu.com/p/599939753">Synopsy2020以上版本EDA软件安装教程</a></li></ul><h3 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h3><p>在开始之前，请确保你的安装目录已按以下结构组织好相关文件。这些文件包括了 Synopsys Installer、SCL 授权工具、VCS&#x2F;Verdi 安装包以及 Nix 配置文件（Nix 文件在 github 仓库里，Xilinx 下载器官方网站下载 Linux 版本，其余的在网盘链接内）。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── installer/             <span class="comment"># Synopsys 安装程序</span></span><br><span class="line">│   ├── SynopsysInstaller_v5.8.run</span><br><span class="line">│   └── ...</span><br><span class="line">├── scl/                   <span class="comment"># SCL (Synopsys Common Licensing)</span></span><br><span class="line">│   └── 2021.03/</span><br><span class="line">├── vcs_all_vU-2023.03-SP2/ <span class="comment"># VCS 源码包</span></span><br><span class="line">├── verdi_vV-2023.12-SP2/   <span class="comment"># Verdi 源码包</span></span><br><span class="line">├── 1patch                 <span class="comment"># 补丁工具</span></span><br><span class="line">├── scl_keygen/            <span class="comment"># License 生成器 (Windows 可执行文件)</span></span><br><span class="line">├── FPGAs_AdaptiveSoCs_Unified_2024.1_0522_2023_Lin64.bin <span class="comment"># Xilinx 安装包</span></span><br><span class="line">├── vcs_fhs_install.nix    <span class="comment"># VCS 的 Nix FHS 配置文件</span></span><br><span class="line">└── xilinx_fhs_install.nix <span class="comment"># Xilinx 的 Nix FHS 配置文件</span></span><br></pre></td></tr></table></figure><h3 id="安装-Synopsys-VCS-Verdi"><a href="#安装-Synopsys-VCS-Verdi" class="headerlink" title="安装 Synopsys VCS &amp; Verdi"></a>安装 Synopsys VCS &amp; Verdi</h3><h4 id="启动-Nix-FHS-Shell"><a href="#启动-Nix-FHS-Shell" class="headerlink" title="启动 Nix FHS Shell"></a>启动 Nix FHS Shell</h4><p>由于 EDA 工具对系统库（如 <code>libGL, libX11</code>）有极其复杂的依赖，我们使用 <code>vcs_fhs_install.nix</code> 构造一个模拟传统 Linux 目录结构的 Shell 环境：</p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nix-shell vcs_fhs_install.nix</span><br></pre></td></tr></table></figure><p><em>首次运行会下载大量依赖包，请确保网络环境畅通。</em> 当所需依赖包都下载完之后即可进入 nix-shell 环境。<br><img src="/assets/file-20251224161722988.png" alt="alt text"></p><h4 id="关于安装路径的建议"><a href="#关于安装路径的建议" class="headerlink" title="关于安装路径的建议"></a>关于安装路径的建议</h4><div class="tip"> <p>强烈建议将软件安装在 <code>/opt/synopsys</code> 下，而非用户家目录 (<code>~/</code>)。</p></div><p><strong>原因分析：</strong><br>在 <code>xilinx-nix</code> 或 <code>chisel-nix</code> 的配置中，通常会包含路径自检逻辑。如果你尝试安装在 <code>$HOME</code> 下，Nix 在构建 Derivation 时，由于 <code>nixbld</code> 用户没有权限读取权限为 <code>700</code> 的用户目录，会导致如下报错：  </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">env</span> VC_STATIC_HOME=<span class="string">&#x27;...&#x27;</span> points to unknown location</span><br></pre></td></tr></table></figure><p>这个报错来源于 <code>xilinx-nix/vcs-fhs-env.nix</code> 的 <code>profile</code> 中写的那行自检代码：</p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[ ! -e <span class="string">&quot;<span class="subst">$&#123;vcStaticHome&#125;</span>&quot;</span> ] &amp;&amp; echo <span class="string">&quot;env VC_STATIC_HOME=&#x27;<span class="subst">$&#123;vcStaticHome&#125;</span>&#x27; points to unknown location&quot;</span> &amp;&amp; exit <span class="number">1</span></span><br></pre></td></tr></table></figure><p>虽然设置了 <code>__noChroot = true</code> 和 <code>sandbox = relaxed</code>，但这只是允许 Nix 访问外部路径，并不意味着它有权限读取私有家目录。Nix 的构建是由系统用户 <code>nixbld1</code>, <code>nixbld2</code> 等执行，在 NixOS 上，用户家目录（<code>/home/$usrname</code>）的权限默认通常是 <code>700</code>（仅自己可见）。你可以开放用户家目录的读取权限，这样操作会导致一些安全问题，推荐还是把 synopsys 安装到 <code>/opt/...</code> 文件下。</p><div class="tip"><p>在 chisel-nix 和 xilinx-nix 中都采用了<code>__noChroot=true</code>，Nix 的构建默认是在严格隔离的沙盒中进行的（无网络、无法访问 <code>/usr</code> 等）。但 VCS 在编译的时候需要连接 License Server 检查许可证。如果关在沙盒里会报错，所以要开启这个属性。</p><p>而开启这个属性需要 NixOS 25.11 用户在<code>configuration. Nix</code>中设置<code>nix. Settings. Sandbox=&quot;relaxed&quot;</code>。</p></div>#### 执行安装程序**1. 初始化 Installer**进入 installer 目录并运行命令：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./SynopsysInstaller_v5.8.run</span><br></pre></td></tr></table></figure><p>当提示安装目录时，输入 . 安装在当前目录即可。<br><img src="/assets/file-20251224163920393.png" alt="alt text"></p><p><strong>2. 运行 setup.sh</strong>：<br>安装完之后会在本地目录出现一个 <code>setup.sh</code> 脚本，运行这个脚本就可以安装 vcs 和 verdi 到指定文件目录下。图中的步骤需要输入源文件地址，这个指的是 Synopsys 安装包的地址（<code>vcs_all_vU-2023.03-SP2</code> 的地址）。<br><img src="/assets/file-20251224170013139.png" alt="alt text"></p><p>下一个步骤就是填写你的安装地址，这里填写的是 <code>/opt/synopsys</code>，剩下的步骤就是一路 next 到安装完成即可，verdi 的安装步骤和 vcs 一样，这里不多说。</p><p><img src="/assets/file-20251224170500242.png" alt="alt text"></p><p>最后将下载的 scl 文件夹移动到安装目录即可。网盘链接里面附带的 <code>Synopsys.dat</code> 我已经试过，不能使用。建议还是按照破解流程走一遍，生成一份 license。</p><h3 id="破解与-License-生成"><a href="#破解与-License-生成" class="headerlink" title="破解与 License 生成"></a>破解与 License 生成</h3><h4 id="运行-1patch"><a href="#运行-1patch" class="headerlink" title="运行 1patch"></a>运行 <code>1patch</code></h4><p>在 <code>nix-shell</code>环境中，对所有安装好的组件执行 patch。注意权限不足时需使用 <code>sudo</code>（或在 shell 中以 root 运行）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">chmod</span> +x 1patch</span><br><span class="line">./1patch -ecc /opt/synopsys/vcs/U-2023.03-SP2</span><br><span class="line">./1patch -ecc /opt/synopsys/verdi/V-2023.12-SP2</span><br><span class="line">./1patch -ecc /opt/synopsys/scl/2021.03</span><br></pre></td></tr></table></figure><h4 id="生成-License-Wine"><a href="#生成-License-Wine" class="headerlink" title="生成 License (Wine)"></a>生成 License (Wine)</h4><p>由于 <code>scl_keygen.exe</code> 是 Windows 程序，我们需要在 Nix 中临时调用 Wine（是一个允许类 Unix 操作系统在 X Window System 运行 Microsoft Windows 程式的软件）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nix-shell -p wine</span><br><span class="line">wine scl_keygen.exe</span><br></pre></td></tr></table></figure><p><img src="/assets/file-20251224171838241.png" alt="alt text"></p><p>出现 Synopsys License Generator 窗口，即运行成功。这里需要填写 <code>Hostid</code> 和 <code>Hostname</code> 以及 <code>port</code> (27000)，linux 执行命令:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ip address  <span class="comment"># 查看mac地址,mac地址就是hostid</span></span><br><span class="line">hostname <span class="comment"># 查看hostname</span></span><br></pre></td></tr></table></figure><p>点击 Generate 就会在本目录下生成一个 <code>Synopsys.dat</code> 文件，将该文件放置在 <code>/opt/synopsys/scl</code> 目录下。</p><p><strong>注意</strong>：需要修改 <code>Synopsys.dat</code> 文件中的 <code>snsplmd</code> 路径为你的路径。</p><p><img src="/assets/file-20251224172403496.png" alt="alt text">    </p><p>到此，vcs 和 verdi 已经安装完毕。</p><h3 id="安装-Xilinx-Vivado-Vitis-2024-1"><a href="#安装-Xilinx-Vivado-Vitis-2024-1" class="headerlink" title="安装 Xilinx Vivado&#x2F;Vitis 2024.1"></a>安装 Xilinx Vivado&#x2F;Vitis 2024.1</h3><p>Xilinx 的安装过程相对独立，但体积庞大，建议预留足够的磁盘空间。确保在 Xilinx 官网上下载了 <code>FPGAs_AdaptiveSoCs_Unified_2024.1_0522_2023_Lin64.bin</code> 文件之后，输入 Shell 命令:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进入 xilinx 安装环境</span></span><br><span class="line">nix-shell xilinx_fhs_install.nix</span><br><span class="line"><span class="comment"># 给下载器添加运行权限</span></span><br><span class="line"><span class="built_in">chmod</span> +775 ./FPGAs_AdaptiveSoCs_Unified_2024.1_0522_2023_Lin64.bin</span><br><span class="line"><span class="comment"># 运行下载器</span></span><br><span class="line">./FPGAs_AdaptiveSoCs_Unified_2024.1_0522_2023_Lin64.bin</span><br></pre></td></tr></table></figure><p>进入 xilinx 的安装环境，给下载器添加运行权限之后就可以运行，安装步骤与 windows 上的操作类似。</p><p>xilinx 环境比较简单，<code>xilinx_fhs_env</code> 环境即可安装与运行，安装完成在 <code>.bashrc </code> (<code>.zshrc </code>) 文件中添加环境变量，同理为了之后在 <code>xilinx-nix</code> 中运行 xilinx，必须要安装在 <code>/opt/..</code> 文件目录下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Xilinx</span></span><br><span class="line"><span class="comment"># 在 xilinx-nix 中需要用到 xilinx 的安装路径</span></span><br><span class="line"><span class="built_in">export</span> XILINX_STATIC_HOME=/opt/Xilinx </span><br><span class="line"><span class="built_in">source</span> /opt/Xilinx/Vitis/2024.1/settings64.sh</span><br><span class="line"><span class="built_in">source</span> /opt/Xilinx/Vivado/2024.1/settings64.sh</span><br><span class="line"><span class="built_in">source</span> /opt/Xilinx/Vitis_HLS/2024.1/settings64.sh</span><br></pre></td></tr></table></figure><p>环境配置参考了 nix-environment 中的 xilinx-vitis: <a href="https://github.com/nix-community/nix-environments/tree/master/envs/xilinx-vitis">https://github.com/nix-community/nix-environments/tree/master/envs/xilinx-vitis</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> Tools </tag>
            
            <tag> Nix </tag>
            
            <tag> Synopsys </tag>
            
            <tag> Simluation </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>解析基于 Nix 的 Chisel 开发基础设施 Chisel-nix</title>
      <link href="/2025/12/18/Nix-chisel-nix/"/>
      <url>/2025/12/18/Nix-chisel-nix/</url>
      
        <content type="html"><![CDATA[<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>传统的电子设计自动化（EDA）环境长期面临“环境熵增”的困境：闭源商业工具对特定 Linux 发行版的依赖、多版本编译器（JDK&#x2F;LLVM）的冲突以及复杂的许可证（License）管理，导致开发环境难以迁移与复现。</p><p>最近研究了 <strong>Chisel-nix</strong> 项目，它利用 Nix 这一声明式包管理器，为 Chisel 硬件开发构建了一套极为现代化的基础设施。</p><hr><h2 id="声明式环境"><a href="#声明式环境" class="headerlink" title="声明式环境"></a>声明式环境</h2><p>Chisel-nix 的核心在于将<strong>硬件设计流程函数式化</strong>。从源码编译到最终的仿真报告，每一个步骤都是 Nix 依赖图中的一个节点。</p><p>针对商业 EDA 工具（如 Synopsys VCS, Cadence JasperGold）深度依赖传统 Linux 文件系统标准（FHS）的问题，Chisel-nix 采用了 <code>buildFHSEnv</code> 技术：</p><ul><li><strong>命名空间隔离</strong>：在 Nix Store 的只读环境中虚拟化出 <code>/bin, /lib, /usr </code>等标准路径。</li><li><strong>Impure 状态注入</strong>：利用 <code>getEnv&#39;</code>函数与 <code>--impure</code> 参数，在保证构建逻辑一致的前提下，动态注入宿主机的 License 路径。</li><li><strong>兼容性层</strong>：针对旧版商业软件，通过 Nix 强制挂载 <code>libxcrypt-legacy</code> 等过时库，实现了在现代 NixOS 系统上运行陈旧二进制文件的能力。</li></ul><h2 id="跨域参数同步"><a href="#跨域参数同步" class="headerlink" title="跨域参数同步"></a>跨域参数同步</h2><p>在复杂的 DPI（Direct Programming Interface）仿真中，最常见的 Bug 来源于软硬件参数的不一致——例如硬件位宽改成了 64 位，但 C++&#x2F;Rust 编写的测试平台仍在使用 32 位。</p><p>Chisel-nix 引入了一个非常优雅的<strong>参数同步机制</strong>：</p><ol><li><strong>统一配置</strong>：在 <code>configs/*.json</code> 中定义所有核心参数（位宽、超时、时钟频率）。</li><li><strong>编译时注入</strong>：Nix 在构建流水线中，将这些 JSON 参数转化为环境变量。</li><li><strong>自动对齐</strong>：Chisel 侧读取参数生成电路；同时，Rust 编写的 DPI 库在编译时通过 <code>env!</code>宏捕获这些变量。</li></ol><p>这意味着你只需修改一处 JSON，整个软硬件环境就会自动重构并保持对齐。这种设计极大地降低了系统集成时的低级错误率</p><h2 id="细粒度的流水线"><a href="#细粒度的流水线" class="headerlink" title="细粒度的流水线"></a>细粒度的流水线</h2><p>Chisel-nix 将原本笨重的硬件构建流程拆解为多个细粒度的节点，这更像是在用软件工程的思维管理硬件：</p><ul><li><strong>中间表示（IR）的价值</strong>：它不仅仅是从 Chisel 直接跳到 Verilog，而是经过了 FIRRTL 到 MLIR (CIRCT) 的深度变换。项目将 <code>elaborate</code>、<code>mlirbc</code>、<code>rtl</code> 分别定义为独立的 Derivations。</li><li><strong>按需开启的验证层</strong>：通过 Chisel 的 Layers 特性，开发者可以在 <code>rtl.nix</code> 中动态决定是否开启 Assert 或 Probe。这允许我们在不改动核心逻辑代码的情况下，通过 Nix 参数轻松切换“生产模式”和“调试模式”。</li></ul><h2 id="现代化的验证栈：Rust-DPI-商业工具"><a href="#现代化的验证栈：Rust-DPI-商业工具" class="headerlink" title="现代化的验证栈：Rust + DPI + 商业工具"></a>现代化的验证栈：Rust + DPI + 商业工具</h2><p>Chisel-nix 提供了统一的接口来调用开源（Verilator）与商业（VCS）仿真器。</p><ul><li><strong>高效的 Rust DPI</strong>：利用 Rust 强大的类型系统和内存安全性编写仿真驱动，相比 C++ 更加稳健。    </li><li><strong>商业工具的完美集成</strong>：通过封装脚本（Wrapper），它解决了商业工具运行时需要写权限的问题，并集成了 Verdi 调试数据库（KDB）和覆盖率报告生成。</li><li><strong>冒烟测试集成</strong>：每一个仿真器的构建都伴随着一个内嵌的测试作业。这种“构建即测试”的理念，保证了产出的二进制文件永远是可用的。</li></ul><h2 id="拓展：什么是-passthru"><a href="#拓展：什么是-passthru" class="headerlink" title="拓展：什么是 passthru"></a>拓展：什么是 <code>passthru</code></h2><p>在 Nix 中，<code>stdenv.mkDerivation</code> 是构建软件包的核心。大多数人更注意的是它的 <code>buildPhase</code> 或 <code>installPhase</code> 参数，但在处理像 Chisel-nix 这样复杂的硬件项目时，<code>passthru</code> 的属性提高了整个流水线的灵活性。</p><p>在 Chisel-nix 中，<code>passthru</code> 属性完成了三个任务：解决硬件开发中的元数据传递、依赖更新和自动化测试。</p><div class="tip"><h4 id="什么是passthru？"><a href="#什么是passthru？" class="headerlink" title="什么是passthru？"></a>什么是<code>passthru</code>？</h4><p>简单来说，<code>passthru</code> 是一个存放“非构建必需数据”的仓库。它里面的内容不会影响软件包的哈希值（即不触发重新编译），但它允许我们将相关的工具、测试脚本或配置参数与主程序打包在一起。</p></div><h3 id="开发者工具链的生命周期管理"><a href="#开发者工具链的生命周期管理" class="headerlink" title="开发者工具链的生命周期管理"></a>开发者工具链的生命周期管理</h3><p>在 Nix中，涉及外部依赖的滚动更新（如 Scala 的 Ivy 依赖）为了保证 Nix 构建的确定性，我们需要手动维护一个锁文件（lock file）。Chisel-nix 通过 <code>passthru.bump</code> 将特定于包的维护工具直接封装在构件定义。</p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">passthru</span> = &#123;</span><br><span class="line">  <span class="attr">bump</span> = writeShellApplication &#123;</span><br><span class="line">    <span class="attr">name</span> = <span class="string">&quot;bump-gcd-mill-lock&quot;</span>;</span><br><span class="line">    <span class="attr">text</span> = <span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="string">      mif run -p &quot;<span class="subst">$&#123;src&#125;</span>&quot; -o ./nix/dependencies/locks/gcd-lock.nix &quot;$@&quot;</span></span><br><span class="line"><span class="string">    &#x27;&#x27;</span>;</span><br><span class="line">  &#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>此举将复杂的依赖更新逻辑（如计算 Maven 坐标的 SHA-256）从宿主系统环境抽象至包级别。开发者无需安装特定的更新器，仅通过 <code>nix run .#package.bump</code> 即可触发闭环的依赖自更新。这种“包即工具箱”的设计，极大地提升了开发者的工作效率。</p><h3 id="跨阶段元数据交互与参数同步"><a href="#跨阶段元数据交互与参数同步" class="headerlink" title="跨阶段元数据交互与参数同步"></a>跨阶段元数据交互与参数同步</h3><p>在 Chisel-nix 中硬件流水线采用长链条的变换过程（Scala 编译 -&gt; Elaborate -&gt; MLIR 优化 -&gt; RTL 生成 -&gt; 仿真)。为了让后续步骤知道前一步生成了什么，Chisel-nix 利用 <code>passthru</code> 传递元数据。例如，在 <code>elaborate.nix</code> 中：</p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">passthru</span> = &#123;</span><br><span class="line">  <span class="keyword">inherit</span> elaborator;</span><br><span class="line">  <span class="keyword">inherit</span> (elaborator) target; <span class="comment"># 将 &quot;GCD&quot; 或 &quot;GCDTestBench&quot; 传给下游</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>当后续的 <code>rtl.nix</code> 拿到 <code>elaborate</code> 的输出时，它可以直接通过 <code>elaborate.target</code> 知道顶层模块的名字。这种方式避免了在每个脚本里重复定义参数，保证了整个流水线在不同阶段对“设计目标”的认知是高度统一的。</p><h3 id="自动化验证与冒烟测试"><a href="#自动化验证与冒烟测试" class="headerlink" title="自动化验证与冒烟测试"></a>自动化验证与冒烟测试</h3><p>在商业 EDA 流程中，我们经常遇到仿真器编译通过但运行崩溃的情况。Chisel-nix 在 <code>vcs.nix</code> 或 <code>verilated.nix</code> 中利用 <code>passthru.tests</code> 嵌入了自动化验证：</p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">passthru.tests.<span class="attr">simple-sim</span> = runCommand <span class="string">&quot;<span class="subst">$&#123;binName&#125;</span>-test&quot;</span> &#123; ... &#125; <span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="string">  <span class="subst">$&#123;finalAttr.finalPackage&#125;</span>/bin/<span class="subst">$&#123;binName&#125;</span> # 直接运行刚编译出的仿真器</span></span><br><span class="line"><span class="string">  # 检查输出结果并保存至 $out</span></span><br><span class="line"><span class="string">&#x27;&#x27;</span>;</span><br></pre></td></tr></table></figure><ul><li>每当你构建一个仿真器，Nix 都会通过这个属性构建立即进行冒烟测试。如果由于链接库或 License 问题导致仿真器无法跑通，Nix 会直接报错并拒绝产出这个包。这种做法就是将<strong>持续集成（CI）逻辑下放到包定义层面</strong>。</li></ul><h3 id="商业-EDA-环境的透明化"><a href="#商业-EDA-环境的透明化" class="headerlink" title="商业 EDA 环境的透明化"></a>商业 EDA 环境的透明化</h3><p>闭源 EDA 工具通常运行在复杂的 FHS（Filesystem Hierarchy Standard）环境中，其内部逻辑对开发者而言往往是“黑盒”。</p><p>Chisel-nix 通过 <code>passthru</code> 将 <code>vcs-fhs-env</code> 等环境定义显式暴露。这一设计方便开发者调试，通过访问 <code>passthru</code> 导出的环境定义快速审查虚拟环境中的库文件组成，从而在闭源二进制程序发生段错误（Segmentation Fault）时，能够精确地进行环境回溯与路径修复。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Chisel-nix 为Chisel 定制了一个<strong>高度自动化且具备强约束力</strong>的协作流程。新学习 Chisel 的开发者和团队无需为环境苦恼，在几秒钟内就可以获得与资深工程师完全一致的开发环境。而且 Chisel-nix 作为一个优秀且有创新的 Nix 框架，具有一定的学习价值。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Chisel </tag>
            
            <tag> Nix </tag>
            
            <tag> DEV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>用 Rust 构建一个实时的终端网络流量监控器</title>
      <link href="/2025/12/18/Rust-net-monitor/"/>
      <url>/2025/12/18/Rust-net-monitor/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>当局域网网速突然变慢时，我们不仅想知道“<strong>网速慢了</strong>”，更想知道“<strong>是谁在占用带宽</strong>”。（实验室的网总是不好，用这个小工具看看到底是谁在占用带宽，当做复习 Rust 的练手）</p><p>虽然 Linux 上有经典的 iftop，但它的界面有些古老。而 btop 虽然界面炫酷，但它主要监控系统资源（CPU&#x2F;内存），在网络流量的具体来源分析上功能有限。</p><p>目前可以实现的功能如下，未来如果需要什么功能再增加</p><ul><li><strong>实时流量监控</strong>：基于 <code>libpcap</code> 的底层抓包。</li><li><strong>绘制图表</strong>：使用 <code>Ratatui</code> 绘制波形图，类似于 Btop++风格</li><li><strong>统计网速</strong>：基于滑动窗口算法计算 1 分钟平均网速，过滤瞬时抖动。</li><li><strong>自动日志</strong>：支持流量快照记录，并自动轮转日志文件。</li><li><strong>识别主机名和厂商</strong>：支持 DNS 反向解析和 MAC 地址厂商识别。</li></ul><p>代码仓库： <a href="https://github.com/ssfortynine/net_monitor">https://github.com/ssfortynine/net_monitor</a></p><div class="tip"><p>目前识别主机名和厂商，通过 <code>mDNS</code>识别只能识别一些简单设备（本机以及路由器），其他的设备设置了防火墙，根据这个方法无法读取到主机名。</p><ul><li>尝试使用了一些网络工具<code>nmlookup</code>也只能查找到小部分，大部分 PC 机查找不到<br>识别厂商名比较简单，只需要识别 MAC 地址的前缀即可，但是 OUI 数据集不好搜索，现在的 MAC 地址前缀不只是前 6 位，文件夹下保存了 Nmap MAC 的前缀</li></ul><p>虽然可以识别 Vendor ，但是我们实验室使用的机子都是一家厂商，所以 MAC 地址也都一样，所以我就把这个功能搁置了，感觉没有什么用</p></div><h2 id="Rust-库选择"><a href="#Rust-库选择" class="headerlink" title="Rust 库选择"></a>Rust 库选择</h2><ul><li><strong>核心库</strong>：<ul><li><code>pcap / pnet</code>: 处理底层网络包捕获。</li><li><code>ratatui</code>: 目前 Rust 生态最强大的 TUI 库，用于绘制界面。</li><li><code>crossterm</code>: 处理终端输入和原始模式。</li></ul></li><li><strong>辅助库</strong>：<ul><li><code>log4rs</code>: 处理日志轮转（限制文件大小、自动删除旧日志）。</li><li><code>dns-lookup</code>: 解析 IP 对应的域名。</li><li><code>chrono</code>: 时间处理</li></ul></li></ul><h2 id="架构设计：生产者-消费者模型"><a href="#架构设计：生产者-消费者模型" class="headerlink" title="架构设计：生产者-消费者模型"></a>架构设计：生产者-消费者模型</h2><p>为了保证界面渲染流畅（500ms 刷新一次）且不丢失任何一个数据包，系统采用了经典的线程分离设计：</p><ol><li><strong>捕获线程（Producer）</strong>：置于后台，处于混杂模式（Promiscuous Mode）监听网卡。它负责解析数据包，并累加每个 IP 产生的字节数。</li><li><strong>UI 线程（Consumer）</strong>：主线程负责定时从共享内存读取数据。它计算速率、更新历史采样点，并最终渲染图形。</li><li><strong>共享状态（SharedStats）</strong>：仅保存增量，UI 线程每读取一次便将其清零，简化了锁的竞争时间。</li></ol><h2 id="关键算法：基于滑动窗口的速率统计"><a href="#关键算法：基于滑动窗口的速率统计" class="headerlink" title="关键算法：基于滑动窗口的速率统计"></a>关键算法：基于滑动窗口的速率统计</h2><p>简单的“瞬时速率”会导致图表剧烈跳动，难以观察长期趋势。我在系统中引入了 <code>IpHistory</code> 结构体，利用双端队列（VecDeque）实现了一个滑动窗口：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">IpHistory</span> &#123;</span><br><span class="line">    <span class="keyword">pub</span> samples: VecDeque&lt;<span class="type">u64</span>&gt;, <span class="comment">// 存储每个采样周期的字节数</span></span><br><span class="line">    <span class="keyword">pub</span> total_sum: <span class="type">u64</span>,         <span class="comment">// 窗口内字节总和</span></span><br><span class="line">    <span class="keyword">pub</span> peak_rate: <span class="type">f64</span>,         <span class="comment">// 历史峰值速率</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span> <span class="title class_">IpHistory</span> &#123;</span><br><span class="line">    <span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">update</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>, bytes: <span class="type">u64</span>) <span class="punctuation">-&gt;</span> <span class="type">f64</span> &#123;</span><br><span class="line">        <span class="keyword">self</span>.samples.<span class="title function_ invoke__">push_back</span>(bytes);</span><br><span class="line">        <span class="keyword">self</span>.total_sum += bytes;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 维护滑动窗口长度（例如 60 秒）</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">self</span>.samples.<span class="title function_ invoke__">len</span>() &gt; MAX_SAMPLES &#123;</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">let</span> <span class="variable">Some</span>(removed) = <span class="keyword">self</span>.samples.<span class="title function_ invoke__">pop_front</span>() &#123;</span><br><span class="line">                <span class="keyword">self</span>.total_sum -= removed;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 计算平均速率：总和 / (样本数量 * 采样周期)</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">duration_secs</span> = <span class="keyword">self</span>.samples.<span class="title function_ invoke__">len</span>() <span class="keyword">as</span> <span class="type">f64</span> * (TICK_RATE_MS <span class="keyword">as</span> <span class="type">f64</span> / <span class="number">1000.0</span>);</span><br><span class="line">        <span class="keyword">self</span>.total_sum <span class="keyword">as</span> <span class="type">f64</span> / duration_secs</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="底层逻辑：从字节流到-IP-地址"><a href="#底层逻辑：从字节流到-IP-地址" class="headerlink" title="底层逻辑：从字节流到 IP 地址"></a>底层逻辑：从字节流到 IP 地址</h2><p>数据采集模块的核心在于对网络协议栈的逐层拆解。利用 <code>pnet</code> 库解析数据包：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1. 解析以太网帧</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">let</span> <span class="variable">Some</span>(ethernet) = EthernetPacket::<span class="title function_ invoke__">new</span>(packet.data) &#123;</span><br><span class="line">    <span class="comment">// 2. 确认是否为 IPv4 协议</span></span><br><span class="line">    <span class="keyword">if</span> ethernet.<span class="title function_ invoke__">get_ethertype</span>() == EtherTypes::Ipv4 &#123;</span><br><span class="line">        <span class="comment">// 3. 解析 IPv4 数据包</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">let</span> <span class="variable">Some</span>(ipv4) = Ipv4Packet::<span class="title function_ invoke__">new</span>(ethernet.<span class="title function_ invoke__">payload</span>()) &#123;</span><br><span class="line">            <span class="keyword">let</span> <span class="variable">len</span> = packet.header.len <span class="keyword">as</span> <span class="type">u64</span>;</span><br><span class="line">            <span class="keyword">let</span> <span class="variable">src</span> = ipv4.<span class="title function_ invoke__">get_source</span>();</span><br><span class="line">            <span class="keyword">let</span> <span class="variable">dst</span> = ipv4.<span class="title function_ invoke__">get_destination</span>();</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 逻辑判断：如果源 IP 是本机，则为上传（TX），反之为下载（RX）</span></span><br><span class="line">            <span class="keyword">if</span> src == local_ip &#123;</span><br><span class="line">                stats.tx_delta += len;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                stats.rx_delta += len;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="TUI-视觉优化"><a href="#TUI-视觉优化" class="headerlink" title="TUI 视觉优化"></a>TUI 视觉优化</h2><p>终端的字符像素通常是 1x1，绘制曲线会有严重的锯齿。我选用了 <code>Ratatui</code> 的 <code>Marker::Braille</code>（盲文）。盲文符号由 8 个点组成，可以将一个字符单元拆分为 2x4 的微小“像素点”。</p><blockquote><p>这个部分是参考 Btop++ 的 UI风格</p></blockquote><p>同时，针对流量排行表（Top Talkers）设置动态颜色：</p><ul><li><strong>红色</strong>：当平均网速超过 1MB&#x2F;s 时，提醒用户该设备正在进行大流量操作。</li><li><strong>绿色</strong>：轻量级流量显示。</li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>OUI 数据库的来源： <a href="https://github.com/Ringmast4r/OUI-Master-Database?tab=readme-ov-file">https://github.com/Ringmast4r/OUI-Master-Database?tab=readme-ov-file</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> Rust </tag>
            
            <tag> Network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>(FPT2025)LL-ViT</title>
      <link href="/2025/12/10/FPT2025-LL-ViT/"/>
      <url>/2025/12/10/FPT2025-LL-ViT/</url>
      
        <content type="html"><![CDATA[<h2 id="背景与动机"><a href="#背景与动机" class="headerlink" title="背景与动机"></a>背景与动机</h2><p>视觉变换器（ViTs）在计算机视觉任务中表现出色，但计算量大、内存占用高，难以在资源受限的边缘设备（如 FPGA）上部署。传统的优化方法（如量化、片外权重加载）通常在延迟、能耗或精度上存在严重的权衡。在典型的 ViT 模型中，<strong>通道混合器（即 MLP 层）占据了超过 60% 的模型权重和 50-70% 的乘累加（MAC）操作</strong>。</p><ul><li>作者提出使用<strong>基于查找表（LUT）的神经元</strong>来替代传统的 MLP 层。与传统的“无乘法网络”不同，LL-ViT 不是简单地将乘法替换为查找，而是采用了一种可以原生学习 LUT 函数的神经架构。（神经网络叠神经网络）<br><img src="/assets/IMG_0083.jpeg" alt="alt text"></li></ul><h2 id="算法与架构设计"><a href="#算法与架构设计" class="headerlink" title="算法与架构设计"></a>算法与架构设计</h2><p>LL-ViT 设计了一种全新的<strong>基于 LUT 的通道混合器 (LUT-based Channel Mixer)</strong>，并将其集成到标准的 Transformer 编码器中。</p><h3 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h3><p>LL-ViT 保持了标准 ViT 的宏观结构，由一系列编码器块组成。</p><ul><li><strong>令牌混合器 (Token Mixer)：</strong> 保留了多头自注意力（MHA）机制，用于捕获令牌间的空间关系。</li><li><strong>通道混合器 (Channel Mixer)：</strong> 将传统的 MLP（由矩阵乘法和非线性激活组成）替换为<strong>基于 LUT 的无乘法模块</strong>。<br><img src="/assets/IMG_0085.jpeg" alt="alt text"></li></ul><h3 id="基于-LUT-的通道混合器算法细节"><a href="#基于-LUT-的通道混合器算法细节" class="headerlink" title="基于 LUT 的通道混合器算法细节"></a>基于 LUT 的通道混合器算法细节</h3><p>其处理流程如下：<br><img src="/assets/IMG_0086.jpeg" alt="alt text"></p><ol><li><strong>输入处理与展开：</strong><br> 由于通道混合器独立处理每个令牌，输入激活矩阵首先被展平，逐行通过后续层。</li><li><strong>温度计编码 (Thermometer Encoding)：</strong><br> 将连续的浮点特征值转换为二进制位序列，以便作为 LUT 的输入地址。类似于二值神经网络（BNN），通过比较器将数值转化为位串。训练过程中使用直通估计器 (Straight-Through Estimator, STE) 来计算梯度，解决离散化导致的不可微问题。</li></ol><div class="tip">输入的是浮点数，查找表看不懂，所以用温度计编码处理输入（就像是温度计的水银柱）数值越大，亮起的“1”就越多。这样就将复杂的连续数值变成了计算机最喜欢 0 和 1 比特流。</div><ol start="3"><li><strong>可学习的 LUT 神经元层 (Learned LUT Neurons)：</strong><ul><li>这些神经元不进行乘加运算$$y&#x3D;\omega x+b$$，而是直接执行查找操作。前一层的输出位被组合成地址，在 LUT 中查找输出。<br><img src="/assets/IMG_0087.jpeg" alt="alt text"></li><li><strong>训练方法：</strong> 采用了 <strong>DWN (Differentiable Weightless Networks)</strong> 中的技术，利用**扩展有限差分 (EFD)**来定义 LUT 条目的梯度，使得可以通过反向传播直接训练 LUT 的内容及其连接方式。</li><li>论文发现两层 LUT 结构（分别为 768 和 192 个 LUT）配合 8 位温度计编码效果最佳。</li></ul></li></ol><div class="tip">将上一步生成的比特流（0 和 1）直接用作为地址索引，比如输入的是 `110` 就去找查找表中第 110 号位置存的是什么（输出通常是 0 或 1）</div><ol start="4"><li><strong>条件求和层 (Conditional Summation Layer) —— 关键设计</strong>：<ul><li>传统的 LUT 网络通常用于分类（输出类别概率），但作为 Transformer 的中间层，它必须输出实值特征向量以保持精度并支持残差连接。</li><li>该论文引入了一组可学习的编码值（权重 Wij）。</li><li>这是一个<strong>无乘法</strong>的操作，仅根据 LUT 的输出决定是否累加某个值（相当于条件加法）表现为矩阵乘法，完全可微，允许使用 FP 32 进行高精度训练。训练后，这些编码值被量化为 INT 4，进一步压缩模型。<br><img src="/assets/IMG_0088.jpeg" alt="alt text"><br>其中 x_j 是最后一层 LUT 的输出（0或1）。</li></ul></li></ol><div class="tip">查找表找出来的只是一堆 0 和 1，图像分类任务需要精确的数值（比如概率），所以给每个查找表分配一个“权重”，如果查表结果是 1，则加上这个权重值，如果是 0 则忽略。则输出的结果就是 $$Output=\sum (权重 \times 查表结果)$$（这里面其实也没有乘法，只有加法）</div><p><img src="/assets/IMG_0090.jpeg" alt="alt text"></p><h2 id="硬件加速器"><a href="#硬件加速器" class="headerlink" title="硬件加速器"></a>硬件加速器</h2><p>LUT 神经元直接映射到 FPGA 的硬件 LUT 资源上，无需消耗 BRAM 来存储权重。设计了乒乓缓冲区（Ping-Pong Buffer）和专用处理单元（PE），实现了通道维度的并行处理和行级流水线。由于模型极度压缩，权重可完全驻留在 FPGA 片上内存中，消除了高能耗的片外内存访问。<br><img src="/assets/IMG_0091.jpeg" alt="alt text"></p><h3 id="3-实验评估与结果"><a href="#3-实验评估与结果" class="headerlink" title="3. 实验评估与结果"></a>3. 实验评估与结果</h3><p>论文以 I-ViT-T（INT8 量化模型）作为基线，在 CIFAR-10、CIFAR-100 和 Tiny-ImageNet 等数据集上进行了评估</p><ul><li><p><strong>模型精度：</strong></p><ul><li><strong>CIFAR-10:</strong> 95.5% (基线为 95.4%)</li><li><strong>CIFAR-100:</strong> 78.8%</li><li><strong>Tiny-ImageNet:</strong> 60.9%<br>LL-ViT 在大幅削减计算量的同时，保持了与基线相当甚至略优的精度，这解决了以前基于 LUT 的网络无法处理复杂视觉任务的问题。</li></ul></li><li><p><strong>资源与效率 (在 Virtex FPGA 上)：</strong></p><ul><li><strong>模型压缩：</strong> 权重减少超过 <strong>60%</strong>。</li><li><strong>计算减少：</strong> 乘法操作减少 <strong>50%</strong>。</li><li><strong>能效提升：</strong> 相比全量化的 ViT 加速器，能效提升 <strong>1.9倍</strong>。</li><li><strong>延迟降低：</strong> 延迟降低 <strong>1.3倍</strong>。</li><li><strong>吞吐量：</strong> 在 10.9W 的功耗下达到了 <strong>1083 FPS</strong>。</li></ul></li><li><p><strong>对比分析：</strong></p><ul><li>与其他无乘法网络（如 LUT-NN）相比，LL-ViT 通过原生学习 LUT，在减少查找和加法操作数量的同时实现了更高的性能。</li><li>相比激进量化（如 3-bit）的方案（如 HG-PIPE），LL-ViT 在功耗上低得多（约 1&#x2F;4），更适合边缘场景。</li></ul></li></ul><h3 id="4-总结"><a href="#4-总结" class="headerlink" title="4. 总结"></a>4. 总结</h3><p>LL-ViT 成功证明了将<strong>可学习的 LUT 神经元</strong>集成到 <strong>Vision Transformer</strong> 的可行性。通过替换最耗资源的 MLP 层，LL-ViT 实现了算法与硬件的协同设计，在不牺牲精度的前提下，显著降低了模型的内存占用、计算需求和能耗.</p>]]></content>
      
      
      
        <tags>
            
            <tag> Papers </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>(FPT2025)Toward Domain-Aware Energy-Efficient Reconfigurable Architectures</title>
      <link href="/2025/12/10/FPT2025-Toward-Domain/"/>
      <url>/2025/12/10/FPT2025-Toward-Domain/</url>
      
        <content type="html"><![CDATA[<h2 id="研究背景与动机"><a href="#研究背景与动机" class="headerlink" title="研究背景与动机"></a>研究背景与动机</h2><p>当前，工业物联网、智能工厂、智慧医疗和自动驾驶等应用层出不穷，且都运行在边缘设备上。这些边缘设备通常由电池供电，功率预算非常有限。然而，这些应用却在不断演变，需求也在时刻变化。</p><p>为了满足这些应用对<strong>可重构性</strong>（Reconfigurability）和<strong>高能效</strong>（Energy Efficiency）的双重需求，我们需要设计灵活的硬件架构。</p><ul><li><strong>ASIC</strong> 虽然能效高但缺乏灵活性，且非重复工程成本（NRE）高昂。</li><li><strong>FPGA</strong> 虽然灵活，但基于比特级的编程导致能效不如专用电路。</li><li><strong>粗粒度可重构架构（CGRA）</strong> 则提供了一个极佳的中间选择。它由处理单元（PE）阵列组成，通过片上网络互连，支持字级编程，比FPGA更具能效优势。<br><img src="/assets/Pastedimage20251209185226.png" alt="alt text"><br>目前大多数 CGRA 采用<strong>同构</strong>（Homogeneous）设计，即所有 PE 支持相同的操作集。这种“一刀切”的设计会导致严重的功耗浪费，因为实际应用中的操作需求是不规则的。因此，我的研究重点是如何通过<strong>异构</strong>（Heterogeneous）设计，在不牺牲灵活性的前提下，利用<strong>领域感知</strong>（Domain-Aware）的特性来大幅降低功耗。</li></ul><h2 id="核心贡献一：DA-CGRA-架构生成流程"><a href="#核心贡献一：DA-CGRA-架构生成流程" class="headerlink" title="核心贡献一：DA-CGRA 架构生成流程"></a>核心贡献一：DA-CGRA 架构生成流程</h2><p>提出了一种利用编译器信息来设计领域特定 CGRA 的方法，称为 <strong>DA-CGRA</strong>。其生成流程如下：<br><img src="/assets/Pastedimage20251209185242.png" alt="alt text"></p><ul><li><p><strong>性能剖析（Profiling）：</strong><br>  首先，我们从应用代码（如 C 代码）入手，使用 <strong>Morpher</strong> 工具生成数据流图（DFG）。接着，利用 Python 脚本对 DFG 进行深度剖析，提取关键信息，包括操作类型（加、减、乘等）、操作数量、内存访问模式以及循环展开因子。</p></li><li><p><strong>操作融合与PE提取：</strong><br>  在分析DFG时，我们发现乘法器的功耗远高于加&#x2F;减法器（引入乘法会导致PE功耗增加约41%）。为了优化能效，我们在融合同一层级的操作时，避免强制所有PE都包含乘法器。最终，我们设计了三种定制化的PE：</p><ol><li><strong>ALU</strong>：功能最全，支持MAC、加减乘、移位和逻辑运算，主要用于复杂的地址生成（对应幻灯片中的红色PE）。</li><li><strong>RALU (Reduced ALU)</strong>：仅支持乘法、加法和减法，用于核心计算。</li><li><strong>ADD&#x2F;SUB</strong>：仅支持加法和减法，去掉了昂贵的乘法器。<br><img src="/assets/Pastedimage20251209185546.png" alt="alt text"></li></ol></li><li><p><strong>架构实现：</strong><br>  基于上述分析，我们生成了包含 <strong>4x5 PE 阵列</strong> 的异构架构，并在左右两侧配备了多组暂存器存储器（Scratchpad Memory）以支持数据和配置的快速存取。在互连方面，我们采用了<strong>8 端口交叉开关（Crossbar）</strong>，虽然比 4 端口功耗稍高，但支持对角线传输，能显著减少启动间隔（II），从而将整体性能提升 3倍。</p></li></ul><h2 id="核心贡献二：系统级能效优化（SCISSORS-项目）"><a href="#核心贡献二：系统级能效优化（SCISSORS-项目）" class="headerlink" title="核心贡献二：系统级能效优化（SCISSORS 项目）"></a>核心贡献二：系统级能效优化（SCISSORS 项目）</h2><p>除了架构层面的 DA-CGRA，我还研究了系统级的能效优化技术，即 <strong>SCISSORS</strong> 项目。这项技术的核心是利用<strong>近阈值计算</strong>（Near-Threshold Computing）来降低电压，从而节省能耗。</p><ul><li><p><strong>挑战与解决方案：</strong><br>  降低电压会导致时序错误。为了解决这个问题，我们提出了一种基于算法的容错（ABFT）机制。以矩阵乘法为例，我们在硬件中加入了<strong>校验和</strong>（Checksum）计算逻辑</p></li><li><p><strong>动态电压调节：</strong><br>  系统在接收 DMA 数据后计算校验和。如果在计算结果中检测到错误（实际校验和与预期不符），系统会通过反馈机制通知电压调节器。我们在 <strong>Xilinx ZCU 102 FPGA</strong> 板上进行了验证，通过动态调整 PL 端（可编程逻辑端）的电压（VCCINT），找到“首次失效点”（Point of First Failure），使系统在保证精度的前提下运行在最低电压，从而最大化能效。</p></li></ul><h2 id="实验结果与对比评估"><a href="#实验结果与对比评估" class="headerlink" title="实验结果与对比评估"></a>实验结果与对比评估</h2><p>我们使用 Synopsys Design Compiler 在45nm 工艺下对 DA-CGRA 进行了综合，并与现有的先进 CGRA 架构进行了对比，包括同构的 HM-HyCUBE、ADRES，以及异构的 RipTide 和 FLEX。</p><ul><li><strong>能效优势：</strong> DA-CGRA的表现优于FLEX和RipTide。具体数据表明，在运行FFT应用时，DA-CGRA的能效比FLEX提高了 <strong>23%</strong>，比RipTide提高了 <strong>38%</strong>。</li><li><strong>性能提升：</strong> 相比于性能最好的同构架构 HM-HyCUBE，DA-CGRA 实现了 <strong>3.2倍</strong> 的性能提升。</li><li><strong>功耗分布：</strong> 由于我们精简了 PE 结构（去除了不必要的乘法器），大部分功耗被有效用于实际计算和数据存储，显著提升了整体效率。</li></ul><h2 id="总结与未来工作"><a href="#总结与未来工作" class="headerlink" title="总结与未来工作"></a>总结与未来工作</h2><p>论文作者博士工作通过架构级优化（领域感知异构设计）和电路&#x2F;系统级技术（近阈值计算与容错）显著降低了可重构架构的能耗。未来，计划将进一步研究 CGRA 的设计空间探索（DSE）方法论。</p><h2 id="问答环节还原与补充"><a href="#问答环节还原与补充" class="headerlink" title="问答环节还原与补充"></a>问答环节还原与补充</h2><p><strong>问题 1：关于FPGA上的电压调节</strong></p><ul><li><strong>提问</strong>：你在FPGA板上测试了这个系统，但我通过编程很难直接调整FPGA的电压，你是怎么做到的？</li><li><strong>回答</strong>：是的，我们实际上使用了 <strong>PMBus</strong> 接口。通过I2C总线，我们可以控制板上的电压调节器。这是通过PS端（处理器系统）来完成的，我们编写了程序来动态调整VCCINT（内核电压）、VCCBRAM（块RAM电压）以及辅助电路的电压。我们可以单独调节，也可以一起调节，从而实现欠压测试。</li></ul><p><strong>问题 2：关于失效点与频率的关系</strong></p><ul><li><strong>提问</strong>：在低频率下，失效点似乎向后移动了。你们测试过更低的频率吗？比如100MHz？</li><li><strong>回答</strong>：我们测试了不同的频率。正如结果所示，在200MHz以下我们几乎没有观察到错误。当频率较高（如250MHz）时，错误会在较高的电压下就开始出现；而频率较低（如215MHz）时，我们可以在更低的电压下才观察到错误。这取决于加速器的关键路径延迟和我们设定的频率。</li></ul><p><strong>问题 3：关于Morpher工具的使用</strong></p><ul><li><strong>提问</strong>：你在DFG生成过程中提到了Morpher工具，操作融合是自动完成的吗？</li><li><strong>回答</strong>：Morpher主要用于生成数据流图（DFG）。至于操作融合和架构参数提取，是通过我们编写的 <strong>Python脚本</strong> 完成的。例如，脚本会识别DFG中用于地址生成的多个节点，并将它们合并，或者决定哪些加减法操作可以共用一个PE。这不是Morpher自带的功能，而是我们的贡献。</li></ul><p><strong>问题 4：关于开源计划</strong></p><ul><li><strong>提问</strong>：你计划开源你的代码吗？</li><li><strong>回答</strong>：目前我还在攻读博士学位，正在整理相关工作。在完成博士学位后，我计划将部分代码开源。</li></ul><p><strong>问题 5：关于互连网络的优化</strong></p><ul><li><strong>提问</strong>：在架构生成中，针对互连网络（Interconnect）有没有做专门的优化？</li><li><strong>回答</strong>：在互连方面，我们主要采用了 <strong>8端口交叉开关（8-output Crossbar）</strong>。虽然这比4端口更复杂，但鉴于我们采用了异构PE设计，我们需要更灵活的路由来保证数据流通，这能提供更高的并行度和旁路能力。所以目前的重点是灵活性，针对互连的深度定制优化在这一版中不是核心重点。</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Papers </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>(FPT2025)da4ml:针对 FPGA 上超低延迟神经网络的快速、可扩展且精确的 CMVM 优化框架</title>
      <link href="/2025/12/10/FPT2025-da4ml/"/>
      <url>/2025/12/10/FPT2025-da4ml/</url>
      
        <content type="html"><![CDATA[<p>Da4ml 一个针对 FPGA 上超低延迟神经网络的快速、可扩展且精确的 CMVM 优化框架。</p><ul><li>基于图的分解和成本感知的 CSE</li><li>da4ml 框架实现为一个开源库，集成到 hls4ml 工具中，da4ml 也可以直接生成可综合的 RTL，以启用 CMS 进行 AXOL1TL 异常检测出发的生产部署</li></ul><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><h3 id="常数矩阵算法"><a href="#常数矩阵算法" class="headerlink" title="常数矩阵算法"></a>常数矩阵算法</h3><p>分布式算术是一种无乘法器方法，通过用移位加（或减）操作替代乘积累加操作在硬件中实现乘法，这些操作通常映射到 FPGA 上的 LUT。</p><p>在无精度损失的情况下使用加法器树实现 CMVM 操作的最先进算法仍是提出的 H_cmvm 算法</p><ul><li>该算法寻找将 CMVM 问题转换为潜在更简单子问题的可能变换，并使用类似于启发式的方法来评估每个变换的成本</li><li>该算法还支持通过限制搜索相空间来制定生成加法器树的最大允许加法器深度<br>计算成本高昂</li></ul><h3 id="超低延迟神经网络"><a href="#超低延迟神经网络" class="headerlink" title="超低延迟神经网络"></a>超低延迟神经网络</h3><p>设计中资源消耗最多的部分通常是全连接层或卷积层中的矩阵向量乘法。</p><h2 id="Da4ml-算法"><a href="#Da4ml-算法" class="headerlink" title="Da4ml 算法"></a>Da4ml 算法</h2><h3 id="Hls4ml"><a href="#Hls4ml" class="headerlink" title="Hls4ml"></a>Hls4ml</h3><p>Hls4ml 为用户提供了一个高层接口，用于连接流行的机器学习框架和 how 后端，是用户能够以最小努力在 FPGA 上部署神经网络</p><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>Da4ml 是一种基于 CSE 的混合算法。与其他基于 CSE 的算法类似，该算法在常数矩阵的离散表示上运行。</p><p>在这项工作中，我们采用规范带符号数字表示，CSD 是一种数字的带符号数字表示，永远没有两个连续的非零数字，并且非零数字的数量保证是最少的。因此，对于一个有 x 位数字的数，CSD 表示最多有 [x&#x2F;2+1] 个非零数字，平均占总数字数的 1&#x2F;3</p><ul><li>首先，用于 M 仅包含定点整数，通过跨行和列应用位移位来对其进行归一化，使得除了零之外没有行&#x2F;列的所有项都是偶数。记录得到的缩放因子，并将应用于输入&#x2F;输出向量</li><li>基于一种图的方式将常数矩阵 M 分解为两个子矩阵 M1, M2，该方法捕获了跨行的高级公共模式。然后，它对两个子矩阵应用 CSE 以最小化冗余计算，最终优化的加法器树显著减少了 LUT 使用并改善了延迟。</li></ul><h3 id="理解与实现"><a href="#理解与实现" class="headerlink" title="理解与实现"></a>理解与实现</h3><p>对于 FPGA 这样的硬件来说，<strong>乘法器</strong>（Multiplier）很贵（占资源多），但<strong>移位</strong>（Shift）几乎是免费的（只是连线变一下），<strong>加法</strong>（Add）则介于两者之间。</p><p>因此，da4ml 的目标就是：<strong>把所有的乘法都变成“移位 + 加法”，然后想办法把重复的加法合并掉。</strong></p><hr><h3 id="第一步：理解“移位代替乘法”与-CSD-表示法"><a href="#第一步：理解“移位代替乘法”与-CSD-表示法" class="headerlink" title="第一步：理解“移位代替乘法”与 CSD 表示法"></a>第一步：理解“移位代替乘法”与 CSD 表示法</h3><p>在二进制里，乘以 2 的幂次方就是移位。比如 $$x \times 8$$ 就是把x 向左移 3 位。但是，乘以 7 怎么办？</p><ul><li><strong>普通二进制方法：</strong>$$7&#x3D;4+2+1$$ (二进制 111)。  这里需要 <strong>2 次加法</strong>。</li><li><strong>CSD (Canonical Signed Digit) 方法（论文重点）：</strong>$$7&#x3D;8-1$$ 这里只需要 <strong>1 次减法</strong>（加法和减法在硬件上代价一样）。</li></ul><p><strong>CSD 的核心原则：</strong> 允许使用负数（-1），尽量减少非零位的数量，绝不让两个非零位相邻。</p><h3 id="第二步：将矩阵乘法拆碎（第一阶段的简化理解）"><a href="#第二步：将矩阵乘法拆碎（第一阶段的简化理解）" class="headerlink" title="第二步：将矩阵乘法拆碎（第一阶段的简化理解）"></a>第二步：将矩阵乘法拆碎（第一阶段的简化理解）</h3><p>假设我们有以下矩阵乘法 <br>$$<br>y_0&#x3D;3x_0+3x_1<br>$$<br>$$<br>y_1&#x3D;5x_0+7x_1<br>$$<br>我们先把常数 3, 5, 7 转换成 CSD：</p><ul><li>$$3 \rightarrow 4-1 \rightarrow (1 \ll 2)-(1\ll 0)$$</li><li>$$5 \rightarrow 4+1 \rightarrow (1 \ll 2)+(1\ll 0)$$</li><li>$$7 \rightarrow 8-1 \rightarrow (1 \ll 3)-(1\ll 0)$$<br>现在把 y 的计算全部展开成最基础的项（Term）：</li></ul><ul><li><strong>对于</strong> y_0:<ul><li>$$x_0 部分：0 \ll 2, -x_0 \ll 0$$</li><li>$$x_1 部分：x_1 \ll 2, -x_1 \ll 0$$</li></ul></li><li><strong>对于</strong> y_1<ul><li>$$x_0 部分：0 \ll 2, x_0 \ll 0$$</li><li>$$x_1 部分：0 \ll 3, -x_1 \ll 0$$</li></ul></li></ul><p>在这一步之前，它先看整列。比如，x_0  这一列在 y_0 是3，在 y_1 是5。如果很多列都是“3”和“5”的组合，它就把 (3, 5) 打包成一个图的节点。<br>该内容不包括 prim 算法</p><hr><h3 id="第三步：公共子表达式消除-CSE-——-核心中的核心"><a href="#第三步：公共子表达式消除-CSE-——-核心中的核心" class="headerlink" title="第三步：公共子表达式消除 (CSE) —— 核心中的核心"></a>第三步：公共子表达式消除 (CSE) —— 核心中的核心</h3><p>这是 da4ml 能够省资源的关键。找出重复出现的加法组合。</p><ol><li>$$y_0 需要：x 0 \ll2, -x 0\ll0, x 1\ll2, -x 1\ll0$$</li><li>$$y_1 需要：x0\ll2, x0\ll0, x1\ll3, -x1\ll0$$</li></ol><p>x_0 &lt;&lt; 2在 y_0 和 y_1 中都出现了。但这只是单项复用。更高级的是<strong>两项组合复用</strong>。</p><p>假设发现 $$A&#x3D;x_0 \ll 2$$ 和$$B&#x3D;-x_1 \ll 0$$在计算中经常一起出现（需要相加）。<br>如果不优化：</p><ul><li>$$y_0&#x3D;…+A+B+…（做一次加法）$$</li><li>$$y_1&#x3D;…+A+B+…（又做一次加法）$$<br>优化后 (CSE)：</li></ul><ul><li>$$T_1&#x3D;A+B（做一次加法）$$</li></ul><ul><li>$$Y_0&#x3D;…+T_1+…$$</li><li>$$Y_1&#x3D;…+T_1+…$$<br>这样就节省了一次加法运算。</li></ul><h4 id="da4ml-的-CSE-算法逻辑"><a href="#da4ml-的-CSE-算法逻辑" class="headerlink" title="da4ml 的 CSE 算法逻辑"></a>da4ml 的 CSE 算法逻辑</h4><ol><li><strong>统计频率：</strong> 遍历所有还未计算的式子，找出所有可能的“两项相加”组合 </li><li><strong>计算代价：</strong> 论文提出了一个代价函数。不仅仅看频率，还要看位宽。<ul><li>简单理解：两个数位宽越接近、重叠越多，把它们加起来就越“贵”（消耗 LUT 多）。</li><li><strong>策略：</strong> 我们优先消除那些出现<strong>频率高</strong>且<strong>重叠多</strong>（消除后省得多）的组合。</li></ul></li><li><strong>替换：</strong> 选定最优组合（例如 $$T_{new}&#x3D;x_a \ll s_1 + x_b \ll s_2$$），把它变成一个新的“基础项”，放入池子。</li><li><strong>循环：</strong> 重复上述步骤，直到没有可以合并的项j</li></ol><hr><h3 id="第四步：da4ml-相比传统算法的改进点"><a href="#第四步：da4ml-相比传统算法的改进点" class="headerlink" title="第四步：da4ml 相比传统算法的改进点"></a>第四步：da4ml 相比传统算法的改进点</h3><ol><li><strong>不只看频率，看“对齐”：</strong><br> 在选择合并哪两个项时，da4ml 倾向于选择<strong>移位量相近</strong>的项。<ul><li>A&lt;&lt;10 和 B&lt;&lt;0 相加：这两个数在二进制上几乎不重叠，加法器很简单，甚至不需要进位链，只是简单的拼接。消除它的收益很低。</li><li>A&lt;&lt;2 和 B&lt;&lt;2 相加：完全重叠，每一位都要算进位，这是<strong>最贵</strong>的。</li></ul><ul><li><strong>da4ml 策略：</strong> 优先消除那些“贵”的加法（重叠多的）。</li></ul></li><li><strong>两阶段优化：</strong><br> 在第一阶段，它把常数矩阵 M 分解成了 $$M&#x3D;M_1 \times M_2$$<ul><li>M_1: 基础构件块。</li><li>M_2: 稀疏的组合系数。<br>这相当于先在宏观上找了一次规律（比如很多列都是由“基础列 A”和“基础列 B”加减得来的），然后再在微观上做 CSE。这大大加快了处理大规模矩阵的速度。</li></ul></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> Papers </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>(FPT2025)Poco-为任务并行 HLS 编程扩展多生产者多消费者缓冲区支持的新框架</title>
      <link href="/2025/12/10/FPT2025-Poco/"/>
      <url>/2025/12/10/FPT2025-Poco/</url>
      
        <content type="html"><![CDATA[<h2 id="背景与挑战"><a href="#背景与挑战" class="headerlink" title="背景与挑战"></a>背景与挑战</h2><p>PoCo 是一个为任务并行 HLS 编程扩展多生产者多消费者缓冲区支持的新框架</p><p>首先，当的任务并行系统框架，如 TAPA 和 PASTA, 主要采用<strong>单生产者单消费者模型</strong>，进行任务通信。这意味着，所有任务间的交互都必须通过点对点的通道（FIFO 流或 PASTA 缓冲区通道）显示实现。<br><img src="/assets/IMG_0043.jpeg" alt="alt text"></p><p>这种 SPSC 模型带来一个根本限制：<strong>任务之间无法共享一个统一的视图和片上存储器</strong>。如果一个片上内存需要被多个消费者访问，现有 HLS 工具和 TPS 框架都会遇到巨大挑战。</p><p>以 <strong>Shuffle</strong> 内核的例子所示，如图，我们有 4 个生产者任务 T 1 和 2 个消费者任务 T 2. 每个 T 1 写入自己独立的缓冲区，但是每个 T 2 需要读取所有 4 个缓冲区<br><img src="/assets/IMG_0042.jpeg" alt="alt text"></p><h3 id="挑战一：复杂的连接性与访问调度"><a href="#挑战一：复杂的连接性与访问调度" class="headerlink" title="挑战一：复杂的连接性与访问调度"></a>挑战一：复杂的连接性与访问调度</h3><p>在 SPSC 模型下，实现这种访问模式比较难，一个简单的实现会把 buffer 和 T 2 任务包装成一个巨大的单体任务，这会导致组合逻辑路径过长，难以进行跨芯片区域的布局，频率会很低。</p><p>采用 PASTA 实现，需要为每个缓冲区创建<strong>专用的消费者任务</strong>，然后在它们和真正的 T 2 任务之间再引入大量的数据 FIFO 来传递请求和响应。</p><p>如图中所示，这需要 4 个额外的缓冲消费者和 16 个新的 FIFO。这不仅增加了设计的复杂性，其性能还能严重依赖于这些中间任务如何仲裁请求。静态调度会导致带宽利用率低下，而实现动态优先级调度又非常困难，并且会破坏任务独立性的设计哲学</p><h3 id="挑战二：控制协调与资源重用"><a href="#挑战二：控制协调与资源重用" class="headerlink" title="挑战二：控制协调与资源重用"></a>挑战二：控制协调与资源重用</h3><p>在实际应用中，任务的资源使用通常是动态变化的。例如，不同的 T 1 实例可能产生不同数量的键值对。如果我们为每个任务静态分配固定大小的缓冲区，就必须按最大可能需求来分配，这会迅速耗尽宝贵的片上资源。</p><p>理想情况下，我们应该允许 buffer 在 producer 之间<strong>动态共享和重用</strong>。但这就需要在 producer 之间动态管理地址偏移，防止数据被意外覆盖，这对程序设计来说更为复杂。</p><h3 id="挑战三：不平衡管道中的带宽利用不足"><a href="#挑战三：不平衡管道中的带宽利用不足" class="headerlink" title="挑战三：不平衡管道中的带宽利用不足"></a>挑战三：不平衡管道中的带宽利用不足</h3><p>标准的 SPSC buffer 为 producer 和 consumer 各分配一个内存端口。但在<strong>不平衡管道</strong>中（例如 producer 快，consumer 慢），总有一个端口处于闲置状态，导致可用带宽仅利用了 50%<br><img src="/assets/IMG_0044.jpeg" alt="alt text"></p><h3 id="挑战四：布局与物理规划"><a href="#挑战四：布局与物理规划" class="headerlink" title="挑战四：布局与物理规划"></a>挑战四：布局与物理规划</h3><p>在现代多芯片 FPGA 上，将大型单体设计放置于单一区域会导致布线拥塞和频率下降。虽然我们可以尝试手动将一些 buffer 移到其他空闲区域，但这些会引入<strong>延迟敏感的路径</strong>，并且需要重新设计任务的接口和通信逻辑，过程非常繁琐。</p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>为了解决这些挑战，该论文提出了 PoCo 框架，其核心是一个共享 MPMC buffer 抽象。让设计者只是在用软件上的共享内存（shared memory），而底层自动处理了所有复杂连线、仲裁和优化</p><h3 id="简化的连接模型"><a href="#简化的连接模型" class="headerlink" title="简化的连接模型"></a>简化的连接模型</h3><p>在 Poco 中，引入一个新的概念：事务器。它可以是 produce、consumer或者两者兼有。每个事务器通过一个或多个定义好的 MPMC 缓冲区端口连接到共享缓冲区。每个端口实际上是一对请求&#x2F;响应 FIFO。如图 6 (a)</p><p>事务器只需要通过这些标准端口发送读写请求，完全无需关心其他事务器的存在。添加新事务器或扩大 buffer 规模，都不会干扰现有任务。<br><img src="/assets/IMG_0046.jpeg" alt="alt text"></p><h3 id="自动协调管理与动态内存分配"><a href="#自动协调管理与动态内存分配" class="headerlink" title="自动协调管理与动态内存分配"></a>自动协调管理与动态内存分配</h3><p>在后端实现了自动的协调机制</p><ul><li><p><strong>内存布局</strong>：buffer 被组织为多个 Block，每个 Block 包含多个 Page。Page 是最小的可锁定（用于读或写）的连续地址空间单元，地址用 index 访问<br><img src="/assets/IMG_0047.jpeg" alt="alt text"></p></li><li><p><strong>互斥访问</strong>：每个 block 由一对访问器管理（一个处理所有写请求，一个处理所有读请求）。我们利用 PASTA 框架为每个页面构建 SPSC 后端，但将页面间的 token 管理封装在父级包装器。通过确保一个页面在同一时刻只能被写入或读取，我们自动防止了数据冒险。</p></li><li><p><strong>动态分配</strong>：我们提供了 <code>allocate</code> 和 <code>free</code> 等 API，允许事务器在运行时动态请求和释放页面。这实质是在静态分配的内存池中动态分配索引。一旦 producer 分配了一个 page 并写入数据，它只需将 page index 共享给 consumer，consumer 就可以立即读取，类似于在软件中共享一个 index</p></li></ul><h3 id="针对不平衡管道的车道交换缓冲区"><a href="#针对不平衡管道的车道交换缓冲区" class="headerlink" title="针对不平衡管道的车道交换缓冲区"></a>针对不平衡管道的车道交换缓冲区</h3><p>为解决带宽利用不足的问题，设计了一个 RTL 模块：Lane-Switching Buffer(LBB)。它包装在双端口内存核外部，可以动态地将两个内存端口同时切换给 producer 或 consumer</p><p>其工作原理是监控 producer 和 consumer 的活动信号。当检测一方（如 producer）即将获得访问 token 时，它会预先将两个内存端口都切换到 producer 所在的“Lane”。这样，当 producer 活跃时，它可以利用完整的双端口带宽进行写入。这使得即使在生产-消费速度不匹配的场景下，也能最大化内存带宽利用率。将这种优化后的内存抽象称为 Lane-Switching Buffer，并将其作为 MPMC buffer 中每个 page 的实现基础</p><p><img src="/assets/IMG_0048.jpeg" alt="alt text"></p><div class="tip"><ul><li><strong>传统问题:</strong> FPGA 上的 BRAM 通常是双端口的（Port A 和 Port B）。传统的 Ping-Pong Buffer（乒乓缓存）通常固定 Port A 写，Port B 读。如果生产者写得很慢，消费者早就读完了在空等，Port B 就闲置了，这叫“负载不平衡”</li><li><strong>LBB 解决方案:</strong><ul><li>PoCo 设计了一个动态开关（Lane Switch）。    </li><li>它允许生产者或消费者 <strong>动态地</strong> 抢占任意一个空闲端口。  </li><li>如果只在写（没有读），两个端口都可以用来写（双倍写入带宽）。</li><li>如果只在读，两个端口都可以用来读。</li><li><strong>效果:</strong> 在负载不平衡的应用中，这能节省高达 50% 的 BRAM 资源，因为你不需要为了带宽去复制多份内存。</div></li></ul></li></ul><h3 id="布局感知的物理规划"><a href="#布局感知的物理规划" class="headerlink" title="布局感知的物理规划"></a>布局感知的物理规划</h3><p>Poco 框架的架构天然有利于物理规划</p><ul><li>其内部数据路经（如请求路由器、数据请求解析器等）由多个独立相同的单元任务组成，它们之间没有组合逻辑连接，因此可以分散布局在芯片的不同位置</li><li>除了 LBB 与访问器之间的接口，其他所有任务间连接都是延迟不敏感的，可以通过插入流水线寄存器来满足时序要求。</li><li>这使得该论文的工具能够自动识别那些对延迟不敏感的 buffer block，并将它们从拥挤的芯片区域移动到空闲区域。如图 5 所示，移动这些块只会增加固定的访问延迟，而不会影响吞吐量，从而在缓解拥塞的同时获得显著的频率提升。<br>![alt text](&#x2F;assets&#x2F;IMG_0041 1.jpeg)<br><img src="/assets/IMG_0051.jpeg" alt="alt text"></li></ul><div class="tip">在高端 FPGA 上，信号跨越芯片边界（Cross-SLR）非常慢。<ul><li><strong>问题:</strong> 如果把所有内存都放在一个地方，远处的任务访问它就会导致时序违例（Timing Violation），频率降低</li><li><strong>PoCo 的方法:</strong><ul><li>它将共享内存打散成多个 <strong>Block</strong></li><li>这些 Block 是独立的，通过互连网络连接。</li><li>PoCo 的算法会自动计算，把 Block 放置在离使用它的任务最近的物理区域（SLR）。</li><li>它会在跨越长距离的连线上自动插入“流水线寄存器”（Pipeline Registers），虽然增加了一点点延迟（Latency），但极大地提高了运行频率（Frequency）。</div></li></ul></li></ul><h2 id="实现架构与工作流程"><a href="#实现架构与工作流程" class="headerlink" title="实现架构与工作流程"></a>实现架构与工作流程</h2><p>PoCo 顶层架构包含多个自由运行的任务，构成内部数据路经。PoCo 不直接拉一根线去读内存，而是构建了一个类似“微型网络”的系统，整个读写过程变成了“发送请求-&gt;处理-&gt;接收响应”:</p><ol><li><strong>RQR（Request Router）请求路由器</strong>：将请求按类型（控制&#x2F;数据）路由</li><li><strong>CRP (Control Request Parser) &amp; PGM (Page Manager) 控制路经：</strong><ul><li>专门处理 <code>alloc</code> (申请内存页)和 <code>free</code>（释放内存页）</li><li>PGM 是一个硬件模块，维护一个位图（Bitmap）或空闲链表，能在一个时钟周期找到空闲内存页并返回其索引。这实现了动态内存管理</li></ul></li><li><strong>DRP (Data Request Parser)数据路经</strong>：处理具体的 <code>read</code> 和 <code>write</code> 数据请求</li><li><strong>Omega-MIN (Omega Network)</strong> ：一个高效的多级交换网络，负责将请求从任意事务器路由到正确的目标访问器。它负责将 T 个用户任务的请求，路由到 N 个内存块（Blocks）中去。这种网络结构在硬件中非常高效，延迟低且吞吐量大。</li><li><strong>I&#x2F;OHD(Input&#x2F;Output Handler)</strong>：即 block 的访问器，负责执行具体的读写操作，并与 Lane-Switching Buffer Block 交互。锁定具体的内存页 (Mutex)，确保同一时间只有一个任务在写入，防止数据冲突。</li><li>响应再通过 Omega-MIN 网络返回给响应生成器，最终送回事务器</li></ol><p>整个工具流基于 PASTA 构建。用户使用我们提供的 API 编写任务并行程序。前端解析器提取任务和 MPMC buffer 配置，生成相应的任务图和 RTL 模块。所有任务经 Vitis HLS 编译后，由我们粗粒度物理规划器（基于 AutoBridge）进行初始布局。最后，结合资源报告生成的约束，进行最终布局布线，生成比特流。<br>架构图：<br><img src="/assets/IMG_0050.jpeg" alt="alt text"><br>工作流程：<br><img src="/assets/IMG_0053.jpeg" alt="alt text"></p><h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>这篇文章的实验结果是真的很多，做的很完整，从 page 24-31 都在对比不同的架构 (SPSTA, TAPA), 以及不同的设计大小 (standard, Multi-die)</p><h2 id="开源"><a href="#开源" class="headerlink" title="开源"></a>开源</h2><p>*开源仓库: <a href="https://github.com/SFU-HiAccel/poco">https://github.com/SFU-HiAccel/poco</a></p><h2 id="问答"><a href="#问答" class="headerlink" title="问答"></a>问答</h2><blockquote><p>是否与 TAPA 框架进行比较？在论文的实验结果中看到了对比数据。我的问题是，直观上看，TAPA 也使用高级综合和自动布局技术。那么，相比 TAPA，你的框架主要优势是什么？是什么带来了频率上的大幅提升？</p></blockquote><p>这是一个非常好的问题。TAPA 最大限制在于它不支持 shared buffer 模型。在 TAPA 中，任务间只能通过点对点的 FIFO 流连接。</p><p>这意味着，如果一个进程需要访问多个大型数组，或者多个任务需要访问同一块内存，所有这些数据都必须通过 FIFO 接口进行打包和传输。这迫使整个计算任务连同其所需的所有缓冲区，都必须放置在同一个 FPGA 槽位中。</p><p>这正是 TAPA 在最终实现中所做的，也是其频率表现不佳的主要原因——它试图将大量组合逻辑和 buffer 积压在同一个区域，导致布线拥塞和长路经延迟。它无法利用空闲的芯片区域，因为其架构没有在任务和 shared memory 之间提供带寄存器的、延迟不敏感的接口</p><p>因此，PoCo 和 TAPA 在 buffer 与任务的接口上是根本不同的。TAPA 是直接、紧密的内存连接，而 PoCo 是通过标准化的请求&#x2F;响应与 shared buffer 通信。这种架构分离使我们能够将计算任务和内存块解耦，并利用我们框架的布局优化算法，将 buffer 灵活地分布到不同芯片区域，从而显著提升整体频率</p>]]></content>
      
      
      
        <tags>
            
            <tag> Papers </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>(FPT2025)OpenDRAM</title>
      <link href="/2025/12/10/FPT2025-OpenDRAM/"/>
      <url>/2025/12/10/FPT2025-OpenDRAM/</url>
      
        <content type="html"><![CDATA[<h2 id="背景与动机"><a href="#背景与动机" class="headerlink" title="背景与动机"></a>背景与动机</h2><p><strong>现状</strong>：大多数内存控制器 (MC) 的研究依赖于高级语言模拟器（如 C++），缺乏开源的 RTL 实现。FPGA 厂商提供的 IP（如 AMD MIG）是闭源的，难以修改和扩展<br><strong>挑战</strong>：现代 DRAM 的运行频率远高于 FPGA 运行频率（通常是 4:1的比例）。为了利用 DRAM 的全带宽，FPGA 端的控制器必须在一个时钟周期内发出 4 个 DRAM 命令。这导致了极高的时序收敛难度。</p><p>该论文提供了一个完全开源、高性能、支持 JEDEC 标准、且能通过 RTL 验证和真机测试的 DDR 4 控制器</p><h3 id="DRAM-控制原理"><a href="#DRAM-控制原理" class="headerlink" title="DRAM 控制原理"></a>DRAM 控制原理</h3><p>图 1 描绘了 DRAM 设备的组织，其中多个芯片独立运行，同时共同保存相同数据的不同段。单个芯片包含一组称为存储体的数据阵列。每个数据阵列由一组行和列（或页）组成。每个存储体还包含一个行缓冲区，可以缓存相应数据阵列的一行。</p><p>在 DDR 4 中，引入了存储体组的概念，将多个存储体组织在一起，以实现更高的并行性和改进数据的吞吐量。</p><p>当 MC 接收到读或写请求时，它首先执行地址转换，根据其地址将请求映射到对应的存储体、行和列。如果请求的行在行缓冲区可用（行命中），则 MC 发出 CAS 命令（写操作为 WR, 读操作为 RD），设备直接在行缓冲区中的请求列进行数据读写；这称为开放请求。否则（行未命中），控制器需要先发出 PRE 命令将行缓冲区内容写回数据阵列，然后发出 ACT 命令将请求的行传输到缓冲区，最后发出 CAS; 这称为关闭请求。<br><img src="/assets/IMG_0062.jpeg" alt="alt text"></p><p>图 2 描绘了单个存储体内读操作的序列和时序。</p><ul><li>发送到同一存储体的两个 ACT 命令之间最小时间约束称为行周期时间 (tRC)，等于行激活时间（tTAS）与行预充电时间 (tRP)之和。这些约束通过防止操作重叠并确保在向同一存储体发送第二个 ACT 命令之间有足够的时间关闭来保证数据的完整性。</li><li>发送 ACT 命令后，MC 必须等待满足 DRAM 将行数据从 DRAM 核心传输到行缓冲区所需的最短时间，然后才能发送 RD 或 WR 命令。此约束称为行列延迟 (tRCD)。虽然读和写操作都必须满足 (tRCD)，但它们随后的时序约束不同</li><li>读取延迟 (tRL)表示 RD 命令发出后数据被放置到数据总线上的时间，而写入延迟 (tWL)约束定义为发出 WR 命令与 MC 将数据放置在总线上之间的延迟，如图 2（b）所示。</li><li>在发送 PRE 命令之前，MC 必须分别遵守读和写操作的 RD 到 PRE（tRTP）或写数据到 PRE (tWR) 时序约束</li><li>图 2 (c)说明了 MC 在后续读或写命令之间必须满足的时序约束。CAS 到 CAS (tCCD)约束是相同类型的后续 CAS 命令之间必须经过的最小时钟周期数。</li><li>由于总线转换时间，在 RD 命令之后发送 WR 命令或相反之前，必须满足读-写 (tRTW)或写-读 (tWTR)时序约束。所有约束都是在两个命令之间，除了四激活窗口 (tFAW)，它定义了一个滚动窗口，在此期间最多可以向单个 rank 发出四个 j 激活命令，如图 2 (d)所示。</li><li>在 tFAW 施加读时间窗口内，MC 还必须遵守行到行延迟（tRRD）时序约束，该约束定义为必须经过的两个发送到不同存储体的 ACT 命令之间的周期数</li></ul><p><img src="/assets/IMG_0063.jpeg" alt="alt text"><br><img src="/assets/IMG_0064.jpeg" alt="alt text"></p><h3 id="内存接口生成器"><a href="#内存接口生成器" class="headerlink" title="内存接口生成器"></a>内存接口生成器</h3><p>AMD 的 MIG IP 生成 DDR 内存接口，包括用户接口、MC、校准和 PHY 模块（图 3）<br><img src="/assets/IMG_0065.jpeg" alt="alt text"></p><ul><li>用户接口捕获 l 来自 FPGA 逻辑的请求并管理数据</li><li>校准逻辑处理校准步骤</li><li>PHY 包括用于串行化&#x2F;反串行化和 PLL 硬 IP，以及用于初始化的软 IP<br>MC 和校准逻辑在较慢的时钟域中与 PHY 交互，该时钟域是 DRAM 设备频率的 1&#x2F;4。</li></ul><p><img src="/assets/IMG_0066.jpeg" alt="alt text"><br>MC 必须要在一个时钟周期内发出四个命令槽点数据包以满足 PHY 频率要求。在这四个槽中，MIG 的 PHY 限制 CAS 命令只能在槽 0 或槽 2 中发出。如图 4 所示，MIG 的 MC 包含多个组件：四个状态机（Group FSM）、仲裁器以及维护和刷新模块。</p><ul><li>x 4 和 x 8 型号（具有 4 个存储体组），每个组 FSM 分配给一个存储体组，在 x 16 型号（具有 2 个存储体组），每个存储体分配两个组 FSM。</li><li>每个 Group FSM 具有两个阶段，具有独立的队列和状态机。<ul><li>第一阶段入队请求并根据需要发出 PRE 和 ACT 命令</li><li>第二阶段管理 CAS 命令，在满足时序约束时发出</li></ul></li><li>在 Group FSM 内，MIG MC 根据请求到达顺序以 FIFO 方式仲裁请求，而不同组 Group 的命令使用循环轮询仲裁器选择。</li><li>这种仲裁方案不利用重排序来优先处理针对开放行的请求，从而限制了性能</li></ul><h2 id="OpenDram"><a href="#OpenDram" class="headerlink" title="OpenDram"></a>OpenDram</h2><p>一个高性能、可配置的 DDR 4 MC，具有基于存储体的 FR-FCFS 前端请求调度器和循环轮询后端命令调度器。沿用 MIG MC 模块设计。</p><p>前端在请求&#x2F;事务级别运行，而后端在 DRAM 命令级别运行。请求和命令的调度完全独立，可以修改而不影响。并引入 5 种命令调度器设计。（由于模块化设计可以随意切换调度，或者修改）</p><p>OpenDram 的 MC 核心架构如图 5。<br><img src="/assets/IMG_0067.jpeg" alt="alt text"></p><ul><li>请求调度器（<code>req_sch_b_i</code>, 其中 i 是存储体索引）执行请求的排队和仲裁，然后根据页表（<code>pg_tbl</code>）中存储体状态为选定的请求生成一组 DDR 4 命令 (PRE, ACT, CAS)</li><li>然后，这些命令被入队到相应的命令队列 (<code>cmd_q_b_i</code>)中。</li><li>与 MIG 的存储体组并行性不同，OpenDram 使用基于存储体的请求队列和命令队列来利用存储体并行性</li><li>命令调度器 (<code>cmd_sch</code>)选择最多 4 个命令，类似于 MIG, 同时最小化读写请求转换</li><li>命令作为数据包传递给 carl 模块，转换为 PHY 适当的信号</li><li>子模块 ref 和 periodic 从 MIG 借用，分别刷新过程运行时校准</li><li>刷新请求在每个刷新间隔 (tREF1)内，一旦挂起的读。写请求完成，就有机会地调度。</li><li>用户接口也从 MIG 中重用；该模块通过传入的请求入队到请求调度器的队列中，并未读请求返回相应，与内存控制器的系统侧交互</li></ul><h3 id="页表"><a href="#页表" class="headerlink" title="页表"></a>页表</h3><ul><li><p>页表中每个条目对应一个特定的存储体，并包含两条信息：该存储体中当前打开的行，以及一个指示存储体是空闲还是活动的单 bit</p></li><li><p>页表跟踪发送到 DRAM 中的 PRE、ACT 和 REF 命令。PRE 将相应存储体的空闲 bit 设置为 1，而 REF 将所有存储体的空闲 bit 设置为 1。</p></li><li><p>页表由每个唯一存储体的请求调度器模块内 FR-FCFS 仲裁器使用，以识别请求队列中针对该存储体的开放请求</p></li></ul><h3 id="请求调度器"><a href="#请求调度器" class="headerlink" title="请求调度器"></a>请求调度器</h3><p>MC 的前端在请求级别运行，包含三个主要组件：请求队列、请求调度器和命令生成器<br><img src="/assets/IMG_0068.jpeg" alt="alt text"></p><p>它有一个大小为 8 的请求队列，索引 0 (LSB)是最老的槽，索引 7（MSB）是最新的槽。<br>请求队列条目中的行地址与页表中存储的当前的行进行比较，生成指示请求是否为开放的标志。这些标志决定 MUX 2 的选择信号</p><ul><li>1）如果存在至少一个开放请求，优先编码器会使用 MUX 1 选择最老的开放请求</li><li>2）如果没有开放请求，则从索引 0 选择最老的请求。一旦选择了一个请求，就会生成相应的 D RAM 命令并进入对应存储体的命令队列</li></ul><h3 id="命令队列"><a href="#命令队列" class="headerlink" title="命令队列"></a>命令队列</h3><p>基于存储体的命令队列最多可容纳三个命令。<br>因为发送到同一存储体的两个连续命令之间最短的时间是 tCCD_L 的 6 个周期，因此，MC 无法在连续的周期内背靠背地向同一个存储体发送两个命令, 所以 MIG MC 只能在特定槽发出</p><h3 id="命令调度器"><a href="#命令调度器" class="headerlink" title="命令调度器"></a>命令调度器</h3><p>查看每个命令队列的前端命令，并在一个时钟周期内在四个槽中选择最多 4 个命令。词啊用循环轮询指针在命令队列之间进行仲裁。</p><p>命令调度器主要功能包括命令仲裁和约束跟踪器模块内的时序约束。</p><ul><li>约束跟踪器模块内的计数器组织成表，每个表按存储体实例化。在每个表中，指定了四个计数器，每个计数器专用于该存储体相关联特定命令类型（PRE, ACT, CD 和 WR），计算特定命令到达就绪状态（即计数器达到零），并可以被仲裁器选择之前剩余的对应槽点 DRAM 周期数。</li><li>该表的设计运行并行访问所有表中的所有条目。例如，命令调度器可以同时检查片间和片内约束。通过应用对就绪命令的循环轮询仲裁，命令调度器宁愿在 CAS 类型不同之前选相同类型的 CAS, 从而最小化读写切换。<br><img src="/assets/IMG_0070.png" alt="alt text"><br>提出了 5 个版本的命令调度器，在性能和频率之间提供不同的权衡。主要设计挑战是对如何在每个 MC 周期内调度命令施加约束，从而简化调度逻辑，减少逻辑级数，最终提高工作频率。</li><li>v 1: 工作在最低频率，但是在命令仲裁方面提供了最高的自由度，因此具有最佳性能</li><li>v 2: 与 v 1 相比，在关闭内存访问模式下的性能差异非常小。V 1 允许每个周期发出最多 4 个 PRE 命令，而 V 2 限制为两个 PRE 命令。其次，与 v 1 不同，ACT 不再允许在任何槽中发出；而是强制在槽 1 和槽 3 中选取。分别通过推迟 PRE 或 ACT 来延迟关闭或行打开，并不总是导致性能损失。相反，在某些情况下是有益的</li><li>v 3 增加了 tRRD_L 的值，这可能会延迟 ACT 命令的发出。</li><li>v 4 中增加了 tRTP 和 tWTR_S，可能分别延迟读命令后的预充电以及写后的读。</li><li>v 5 与 v 4 相比，没有对调度逻辑施加额外的约束，因此不会直接降低 MC 性能。</li></ul><h4 id="版本-1-v-1"><a href="#版本-1-v-1" class="headerlink" title="版本 1 (v 1)"></a>版本 1 (v 1)</h4><p><img src="/assets/IMG_0071.jpeg" alt="alt text"><br>提供了最高的调度粒度，但是工作在较低的工作频率。包含 4 个链式的组合逻辑块，每个块基于计数器值和循环轮询指针为一个槽选择一个命令，更新相关计数器和循环轮询指针以供下一个周期使用。</p><p>图 7 中每个槽使用三个块：一个比较器（&lt;&#x3D;0）、一个基于槽点循环轮询仲裁器 (arb)和一个约束跟踪器 (const_trck)。<br>过程从槽 0 开始：</p><ul><li>比较检查命令队列前端的命令，并根据计数器找到准备发出的命令，输出就绪标志 (rf_0)</li><li>arb_0 使用这些基于存储体的标志为槽 0 选择一个命令。选中的命令然后传递给 const_trck_0，后者根据时序约束更新计数器。</li><li>这个过程依次对剩余槽重复</li></ul><h4 id="版本-2-V2"><a href="#版本-2-V2" class="headerlink" title="版本 2 (V2)"></a>版本 2 (V2)</h4><ul><li><strong>V1 的局限：</strong> V1 在每个时钟槽（Slot）使用一个通用的仲裁器来处理所有类型的命令，导致效率低下。<br><img src="/assets/IMG_00721.jpeg" alt="alt text"></li><li><strong>V2 的核心改进：</strong><br><img src="/assets/IMG_00741.jpeg" alt="alt text"><ul><li><strong>独立仲裁机制：</strong> 利用 PRE（预充电）命令不影响其他 Bank 时序的特性，V2 将仲裁器拆分为<strong>四个专用仲裁器</strong>（2个用于 ACT，2个用于 CAS），实现并行选择。</li><li><strong>槽位分配与防争用：</strong><ul><li>由于 PHY 层限制 CAS 命令只能在<strong>槽 0 和 2</strong> 发出，为避免争用，设计将 ACT 命令分配给<strong>槽 1 或 3</strong>。</li><li>剩余的空闲槽位留给 PRE 命令。PRE 由两个<strong>优先级编码器</strong>选择：一个优先选 Bank 0，另一个优先选高位 Bank，这种固定优先级因 PRE 命令时间间隔大而不会造成不公。</li></ul></li><li><strong>工作流程：</strong><ol><li><strong>就绪检测：</strong> 比较器检查各 Bank 命令是否就绪（例如：&lt;&#x3D;0 标志表示命令可发）。它会生成如 cas_rf_0（槽 0 的 CAS 就绪）和 pre_rf_0 等标志。</li><li><strong>并行仲裁：</strong> 所有仲裁器和 PRE 编码器同时运行。PRE 的就绪性仅由比较器判断，不依赖后续分配的特定槽位。</li><li><strong>Resolve 逻辑：</strong> 最终决定阶段。先分配获胜的 ACT 和 CAS 到其固定槽位，再将 PRE 填入剩余槽位，最后发送给 const_trck 和 PHY。</li></ol></li><li><strong>约束跟踪与例外情况（图 9）：</strong><ul><li>通常 ACT 和 CAS 计数器并行更新。但在处理 <strong>ACT (Bank 0) -&gt; WR (Bank 1) -&gt; RD (Bank 0)</strong> 这种序列时，存在一个时序“角落情况”：虽然 ACT 对 RD 的片内约束(tRCD)允许在周期 16 发出 RD，但中间插入的 WR 命令带来的片间约束要求 RD 必须等到周期 27。</li><li>设计通过监控发出的命令序列，强制对 RD 应用更长的片间约束来解决此问题。</li></ul></li></ul></li></ul><h4 id="版本-3-V3"><a href="#版本-3-V3" class="headerlink" title="版本 3 (V3)"></a>版本 3 (V3)</h4><ul><li><strong>Resolve 逻辑的简化（图 10）：</strong><ul><li>V2 允许 ACT&#x2F;CAS 在其两个专属槽中自由选择，但这增加了逻辑复杂度。</li><li><strong>V3 策略：</strong> 强制固定 <strong>CAS 发往槽 2</strong>，<strong>ACT 发往槽 3</strong>，槽 0 和 1 专门留给两个 PRE。</li><li><strong>收益：</strong> 循环轮询仲裁器只需要针对 1 个 ACT 和 1 个 CAS 进行，减少了查找表（LUT）的使用，降低了 FPGA 布线延迟。<br><img src="/assets/IMG_0075.jpeg" alt="alt text"></li></ul></li><li><strong>移除 tFAW计数器（图 11）</strong><ul><li><strong>问题：</strong> tFAW（四激活窗口）通常需要一套复杂的计数器和移位寄存器来跟踪最近 4 次 ACT。</li><li><strong>解决方案：</strong> 通过修改 ACT 到 ACT 的短时序约束 tRRD，使其满足<br>$$<br>t_{RRD}&#x3D;[t_{FAW}&#x2F;4]<br>$$</li><li><strong>效果：</strong> 如图 11 所示，通过数学上增大 tRRD，使得每 4 个 ACT 命令的自然间隔总和自动满足 tFAW。这允许完全<strong>移除 tFAW 专用计数器及其比较逻辑</strong>，减少了逻辑级数。<br><img src="/assets/IMG_0076.jpeg" alt="alt text"></li></ul></li></ul><h4 id="版本-4-v-4"><a href="#版本-4-v-4" class="headerlink" title="版本 4 (v 4)"></a>版本 4 (v 4)</h4><ul><li><strong>核心架构修改（图 12）：</strong><ul><li>将约束跟踪器中的时序表拆分为<strong>两组独立表</strong>：一组存片内约束，一组存片间约束。</li><li><strong>目的：</strong> 确保新计算的约束值总是大于表中的当前值，从而<strong>直接覆盖</strong>而无需先进行“新值 vs 旧值”的比较。这在 FPGA (LUT 6) 中节省了至少两级逻辑。<br><img src="/assets/IMG_0078.jpeg" alt="alt text"></li></ul></li><li><strong>例外情况的参数修正（无需比较的保证）：</strong><br>  为了确保“直接覆盖”总是安全的，必须处理计算值可能小于表值的特殊情况：<br><img src="/assets/IMG_0080.jpeg" alt="alt text"><ol><li><strong>ACT-RD-PRE 序列（图 13）：</strong><ul><li><strong>冲突：</strong> RD 发出后更新 PRE 的计数器值为 tRTP。但若 ACT 到 PRE 的约束 tRAS 更长，直接用 tRTP 覆盖会导致违反 tRAS</li><li><strong>修正：</strong> 强行增加 tRTP 的值，令$$t_{RTP}&#x3D;t_{RAS}-t_{RCD}$$这样无需比较即可确保持续满足 tRAS</li></ul></li><li><strong>WR-RD-RD 序列（图 14）：</strong><ul><li><strong>冲突：</strong> 中间的 RD（不同 Bank Group）会用较短的 tCCD_S 更新约束，可能导致后续同组 RD 违反由 WR 引起的 tWTR_L 约束。</li><li><strong>修正：</strong> 增加 tCCD_S 的值，令$$t_{WTR_S}&#x3D;t_{WTR_L}-t_{CCD_s}$$</li><li><strong>代价：</strong> 这些修改虽然简化了逻辑（移除了比较器），但可能会轻微延迟关闭请求（Close Request）的处理。</li></ul></li></ol></li></ul><p><img src="/assets/IMG_0082.jpeg" alt="alt text"></p><h4 id="版本-5-V5"><a href="#版本-5-V5" class="headerlink" title="版本 5 (V5)"></a>版本 5 (V5)</h4><ul><li><strong>两级循环轮询仲裁：</strong><ul><li><strong>原问题：</strong> 之前的版本在 8 个 Bank 间直接进行循环轮询（8位向量），旋转和编码至少需要 4 级 LUT 逻辑</li><li><strong>V5 改进：</strong> 引入<strong>层级化仲裁</strong>。    <ul><li><strong>第一级：</strong> 每个 Bank Group 内部（4选1）并行仲裁。由于只处理 4 个输入，单个 LUT6 即可实现。</li><li><strong>第二级：</strong> 在 Bank Group 之间进行仲裁（最多 4 个组），同样只需单个 LUT。</li><li><strong>结果：</strong> 总逻辑深度减半，大幅提升频率。</li></ul></li></ul></li><li><strong>计数器位宽压缩（6位 -&gt; 3位）：</strong><ul><li><strong>修改：</strong> const_trck 不再以 DRAM 周期为单位，而是改用 <strong>MC 周期</strong>（1 MC 周期 &#x3D; 4 DRAM 周期）来跟踪约束。  </li><li><strong>收益：</strong> 计数器位宽从 6 位减少到 3 位。</li><li><strong>逻辑优化：</strong> 比较器现在只需比较 3 位数值与槽位号（0-3）。在 FPGA 中，两个 6 位数的比较需要多级 LUT，而 <strong>3 位数的比较仅需一个 LUT6 即可完成</strong>。这不仅减少了逻辑级数，还减少了寄存器使用，改善了布线延迟。</li></ul></li></ul><h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><h3 id="行为-RTL-仿真"><a href="#行为-RTL-仿真" class="headerlink" title="行为 RTL 仿真"></a>行为 RTL 仿真</h3><p>使用一个仿真基础设施来生成不同模式的读写请求以验证控制器的功能。该基础设施类似于多个 PE 向内存控制器发出内存流量。由 PE 派生的每个流量模式由一个跟踪文件描述，包括地址、操作类型（RD 或 WR）和发出部分写请求，随后对相同地址发出读请求，以确保数据正确性。</p><h3 id="1-性能对比"><a href="#1-性能对比" class="headerlink" title="1. 性能对比"></a>1. 性能对比</h3><p>OpenDRAM 在大多数测试场景下，吞吐量均显著优于工业界标杆（AMD MIG）和学术界开源项目（OPRECOMP）。</p><ul><li><strong>对比 AMD MIG (工业标准)：</strong><ul><li><strong>总体提升：</strong> OpenDRAM 的平均性能比 AMD MIG <strong>高出 62%</strong>，在特定场景下提升高达 <strong>157%</strong>。</li><li><strong>合成测试（Synthetic）：</strong><ul><li>在纯读或纯写模式下，两者性能相近。</li><li>在<strong>混合读写（Random Read&#x2F;Write）</strong> 模式下，OpenDRAM V1&#x2F;V2 吞吐量比 MIG 高出约 <strong>40%</strong>，V3-V5 高出约 30%。这归功于 OpenDRAM 更好的读写切换最小化策略。</li></ul></li><li><strong>加速器内核测试（Real-world workloads）：</strong><ul><li>在使用 <strong>DDR4-2400-x16</strong> 内存时，OpenDRAM 在所有测试内核上的表现均优于 MIG（提升 77% - 107%）。</li><li><strong>原因分析：</strong> OpenDRAM 采用了 <strong>FR-FCFS（先就绪先服务）</strong> 调度策略和<strong>Bank 级并行</strong>，能够对请求进行重排序以优先命中行缓冲区（Row Hit）。例如在流式内核（如 dot, dscal）中，OpenDRAM 实现了约 50% 的行命中率，而 MIG 仅为 0%。</li></ul></li></ul></li><li><strong>对比 OPRECOMP (开源竞品)：</strong><ul><li>OpenDRAM 的平均吞吐量比 OPRECOMP <strong>高出 37%</strong>。</li><li>在读写切换频繁的内核（如 dscal）中，OpenDRAM 的优势最大（提升 <strong>267%</strong>），因为 OPRECOMP 的读写切换率极高（61%），而 OpenDRAM 优化至 40%。</li></ul></li></ul><h3 id="2-内部对比"><a href="#2-内部对比" class="headerlink" title="2. 内部对比"></a>2. 内部对比</h3><p>实验展示了<strong>调度灵活性（性能）<strong>与</strong>工作频率</strong>之间的权衡。</p><ul><li><strong>V1 (基准)：</strong> 拥有最高的调度自由度，通常性能最好，但在 FPGA 上能达到的频率最低。</li><li><strong>V2 (并行仲裁)：</strong><ul><li>性能与 V1 几乎持平（差异 &lt; 1%）。</li><li>在某些存在行复用（Row Reuse）的场景（如 trmm）中，由于 V2 延迟了预充电（PRE），性能反而略优于 V1。</li><li>在写密集型流式应用（如 dscal）中，性能略有下降（约 20%）。</li></ul></li><li><strong>V3 &amp; V4 (时序与逻辑优化)：</strong><ul><li>为了提高频率，引入了更严格的槽位限制和时序参数（如增大 tRRD 、tRTP</li><li><strong>性能代价：</strong> 相比 V2，V3 平均性能下降约 <strong>9%</strong>；V4 相比 V3 平均下降约 <strong>6%</strong>。这主要是因为必须等待更长的时序约束才能关闭行或发出激活命令。</li></ul></li><li><strong>V5 (两级仲裁 &amp; 高频优化)：</strong><ul><li>这是最终的高频版本。虽然在某些对 Bank Group 敏感的内核（如 mvt）上吞吐量有波动（相比 V4 有增有减），但它能够支持最高的时钟频率，从而在物理层面弥补逻辑上的调度限制。</li></ul></li></ul><h3 id="3-FPGA-资源占用与频率支持"><a href="#3-FPGA-资源占用与频率支持" class="headerlink" title="3. FPGA 资源占用与频率支持"></a>3. FPGA 资源占用与频率支持</h3><ul><li><strong>资源占用：</strong><ul><li>OpenDRAM 的资源占用（LUTs 和 Registers）与 AMD MIG 相当，甚至在 V5 版本中略低于 MIG。</li><li>相比 OPRECOMP，OpenDRAM 占用资源较多，因为 OPRECOMP 是非性能优化的极简设计。</li><li><strong>主要消耗：</strong> 大部分逻辑资源消耗在<strong>请求调度器（Request Scheduler）</strong> 中，主要用于实现 FR-FCFS 重排序逻辑。</li></ul></li><li><strong>频率支持：</strong><ul><li>通过 V1 到 V5 的演进，支持的 DDR4 频率逐渐提升。</li><li><strong>V5 版本</strong>在测试的 FPGA 上可支持高达 <strong>1200 MHz</strong> 的内存频率，而 OPRECOMP 仅支持到 1066 MHz。</li></ul></li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>*开源仓库： <a href="https://github.com/FanosResearch/OpenDRAM">https://github.com/FanosResearch/OpenDRAM</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> Papers </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>(FPT2025)Fusion SoC Workshop</title>
      <link href="/2025/12/10/FPT2025-Fusion-SoC-Workshop/"/>
      <url>/2025/12/10/FPT2025-Fusion-SoC-Workshop/</url>
      
        <content type="html"><![CDATA[<h2 id="The-Front-End-Tools"><a href="#The-Front-End-Tools" class="headerlink" title="The Front-End Tools"></a>The Front-End Tools</h2><h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>在异构计算领域，传统的编译器流程（如 GCC&#x2F;Clang）主要负责将高级语言转换为线性的机器指令流。</p><p>然而，对于 CGRA 这种空间架构而言，编译器面临着完全不同的挑战：它不仅需要生成指令，更需要从源码中提取<strong>数据流图</strong>（DFG）或<strong>控制数据流图</strong>（CDFG），以便映射到二维的处理单元（PE）阵列上<br><img src="/assets/Pastedimage20251209200435.png" alt="alt text"><br><img src="/assets/Pastedimage20251209200450.png" alt="alt text"><br>传统编译流程与 CGRA 编译流程的对比，后者需要生成 DFG&#x2F;CDFG 并进行空间映射</p><p><strong>Fusion CGRA SoC</strong> 是一个典型的异构系统，包含 RISC-V 主控核、DMA 控制器、多库 Scratchpad Memory (SPM) 以及核心的 CGRA 阵列。为了充分利用这一硬件的性能，需要解决三大问题：</p><ol><li><strong>控制流的复杂性</strong>：如何将高级语言中的嵌套循环和条件分支高效映射到硬件？</li><li><strong>算子的专用性</strong>：如何自动提取并利用硬件提供的特殊功能单元（如自动地址生成、累加器）？</li><li><strong>优化的全局性</strong>：如何从单纯的内核加速扩展到整个 SoC 的系统级流水线优化？<br><img src="/assets/Pastedimage20251209200654.png" alt="alt text"><br>Fusion SoC 的硬件架构概览，展示了 RISC-V Host 与 CGRA Array 的交互关系</li></ol><h3 id="第一阶段：CO-Compiler-——-基于-LLVM-的通用性突破"><a href="#第一阶段：CO-Compiler-——-基于-LLVM-的通用性突破" class="headerlink" title="第一阶段：CO-Compiler —— 基于 LLVM 的通用性突破"></a>第一阶段：CO-Compiler —— 基于 LLVM 的通用性突破</h3><p><strong>CO-Compiler (ASP-DAC 2024)</strong> 选择构建在成熟的 LLVM 生态之上。LLVM 的中间表示（IR）虽然通过静态单赋值（SSA）形式很好地表达了数据依赖，但其控制流表示（如 <code>Phi</code> 节点）并不直接兼容 CGRA 的空间映射。<br><img src="/assets/Pastedimage20251209201310.png" alt="alt text"></p><h4 id="从-LLVM-IR-到-CDFG：控制流的硬件化重构"><a href="#从-LLVM-IR-到-CDFG：控制流的硬件化重构" class="headerlink" title="从 LLVM IR 到 CDFG：控制流的硬件化重构"></a>从 LLVM IR 到 CDFG：控制流的硬件化重构</h4><p>LLVM IR 使用 <code>br</code>（分支跳转）和 <code>Phi</code> 指令来管理控制流，这在冯·诺依曼架构上是最高效的。但在 CGRA 上，我们需要将这些控制流转换为数据通路上的选择逻辑。</p><p>CO-Compiler 引入了一套基于<strong>支配树</strong>（Dominator Tree）的分析算法。编译器遍历基本块（Basic Block），分析数据在不同路径下的汇聚情况，将软件层面的 <code>Phi</code> 指令转换为硬件可执行的 <strong>SELECT（多路选择器）节点</strong>。<br><img src="/assets/Pastedimage20251209201347.png" alt="alt text"><br><img src="/assets/Pastedimage20251209201811.png" alt="alt text"><br>该图展示如何从 LLVM 的 Basic Blocks 和 Phi 节点推导出带有 SELECT 节点的 CDFG<br>更进一步，为了处理循环中的状态更新，将 Phi 节点细分为两类：</p><ul><li><strong>General Phi</strong>：用于普通的<code> if-else</code> 条件选择，映射为由条件信号控制的 MUX。</li><li><strong>Cumulative Phi</strong>：用于循环迭代中变量的自我更新（如 <code> i++</code> 或 <code>sum += a[i]</code>）。这类 <code>Phi</code> 节点依赖于回边（Back-edge），在硬件上被转换为由 <code>LoopStart</code> 信号控制的初始值选择逻辑，从而支持任意层级的嵌套循环</li></ul><h4 id="GEP-节点解析与线性访存模式提取"><a href="#GEP-节点解析与线性访存模式提取" class="headerlink" title="GEP 节点解析与线性访存模式提取"></a>GEP 节点解析与线性访存模式提取</h4><h5 id="1-基于-LLVM-IR-的-GEP-指令解析"><a href="#1-基于-LLVM-IR-的-GEP-指令解析" class="headerlink" title="1. 基于 LLVM IR 的 GEP 指令解析"></a>1. 基于 LLVM IR 的 GEP 指令解析</h5><p>在 LLVM IR 中，数组访问通常通过 <code>GetElementPtr</code> (GEP) 指令完成。如果直接将 GEP 指令映射为 PE 上的加法和乘法运算，将会消耗大量的计算资源。GEP 指令通过基地址（Base Pointer）和一系列索引（Indices）来计算目标元素的内存地址。</p><p>CO-Compiler 的前端分析 Pass 首先扫描循环体内的所有 GEP 指令，解析其操作数结构。根据 C&#x2F;C++ 的多维数组内存布局，一个典型的地址计算公式可以表示为<br><img src="/assets/Pastedimage20251209203518.png" alt="alt text"><br>其中，N 为数组维度，DimScale_i 为第 i 维的跨度（由数组类型决定），Index_i 为该维度的下标。</p><p>CO-Compiler 实现了一套<strong>线性访存分析</strong>（Linear Memory Access Analysis）机制。它检查 GEP 指令是否满足关于循环归纳变量的仿射变换关系。</p><p><img src="/assets/Pastedimage20251209202207.png" alt="alt text"><br>该图展示编译器对 LLVM IR 中的 <code>getelementptr</code> 指令进行解析，识别基地址、数组维度形状（Array Shape）以及各维度的偏移量。</p><h5 id="2-仿射变换与线性性验证"><a href="#2-仿射变换与线性性验证" class="headerlink" title="2. 仿射变换与线性性验证"></a>2. 仿射变换与线性性验证</h5><p>为了确定该访存操作是否能被硬件专用的地址生成单元（AGU）支持，编译器需要验证地址表达式是否关于循环归纳变量（Induction Variable）构成<strong>仿射变换（Affine Transformation）</strong>。<br>判定为“线性访存”需满足以下三个严格条件：</p><ol><li><strong>计算封闭性</strong>：地址表达式完全由常数、循环不变量（Loop-invariant）和循环归纳变量构成。</li><li><strong>线性步进</strong>：循环归纳变量在迭代过程中呈线性变化（如<code> i++</code> 或 <code>i += c</code>）。</li><li><strong>仿射映射</strong>：从归纳变量到最终内存地址的映射关系是线性的。<br>当满足上述条件时，复杂的地址计算逻辑可以被简化为一个线性方程：<br><img src="/assets/Pastedimage20251209204735.png" alt="alt text"><br>其中 $M$ 是循环嵌套层级，$Coeff_j$ 是第 $j$ 层循环变量 $Var_j$ 对应的线性系数<br><img src="/assets/Pastedimage20251209204949.png" alt="alt text"><br>该图展示多层嵌套循环中，循环变量与最终物理地址之间的数学映射关系</li></ol><h5 id="3-硬件参数提取与-AGU-配置"><a href="#3-硬件参数提取与-AGU-配置" class="headerlink" title="3. 硬件参数提取与 AGU 配置"></a>3. 硬件参数提取与 AGU 配置</h5><p>一旦确认为线性访存模式，CO-Compiler 将不再生成用于计算地址的计算节点（Add&#x2F;Mul Nodes），而是直接提取描述该访存模式的三组关键参数，用于配置 CGRA 的输入&#x2F;输出单元（IO Unit）或地址生成单元：</p><ul><li><strong>起始地址（Start Address）</strong>：由基地址和归纳变量的初始值确定的首个访问地址。</li><li><strong>步长（Stride）</strong>：对应每一层循环迭代时，物理地址的跳变值。对于多层嵌套循环，编译器会提取出一组 Stride 值（如 Stride1, Stride2…），分别对应内层和外层循环。</li><li><strong>计数值（Count）</strong>：对应每一层循环的迭代次数。<br><img src="/assets/Pastedimage20251209205141.png" alt="alt text"></li></ul><h5 id="4-资源优化的收益与回退机制"><a href="#4-资源优化的收益与回退机制" class="headerlink" title="4. 资源优化的收益与回退机制"></a>4. 资源优化的收益与回退机制</h5><p>通过上述转换，原本需要由多个 PE 级联完成的乘加树（Mul-Add Tree）运算，被转化为静态的配置参数。</p><ul><li><strong>资源释放</strong>：实验表明，这一优化显著减少了 PE 的占用率，使得更多 PE 可用于核心的数据处理（如卷积、矩阵乘法），从而提升了算力的有效利用率。</li><li><strong>回退机制</strong>：对于无法通过线性分析的<strong>不规则访存</strong>（Irregular Memory Access），例如间接寻址 <code>A[B[i]]</code> 或非线性下标 <code> A[i*i]</code>，编译器会自动回退到保守策略，生成完整的乘加运算数据流图，并映射到 PE 阵列执行，以确保程序的正确性。<br><img src="/assets/Pastedimage20251209205329.png" alt="alt text"><br>对比图，左侧是未优化前占用大量 PE 的地址计算树，右侧是优化后仅需配置参数的 Load 节点</li></ul><h4 id="专用算子提取"><a href="#专用算子提取" class="headerlink" title="专用算子提取"></a>专用算子提取</h4><p>为了进一步降低 Initiation Interval (II)，CO-Compiler 能够自动识别高级语言中的特定模式并映射到专用硬件算子：</p><ul><li><strong>累加器序列（Accumulation Series）</strong>：识别带有反馈路径的加法链，映射为硬件累加器。如图所示将通用的加法循环逻辑转换为专用 Accumulator 硬件算子的过程。<br><img src="/assets/Pastedimage20251209205604.png" alt="alt text"></li><li><strong>条件访存（Conditional Memory Access）</strong>：将受控的 Load&#x2F;Store 转换为 CLOAD&#x2F;CSTORE，利用 Predicate 信号直接控制内存读写使能，避免了复杂的控制流分歧。如图展示如何将 if-else 控制下的内存访问转换为带使能端的 CStore&#x2F;CLoad 操作。<br><img src="/assets/Pastedimage20251209205646.png" alt="alt text"></li></ul><h3 id="第二阶段：Adora-Compiler-——-基于-MLIR-的端到端全栈优化"><a href="#第二阶段：Adora-Compiler-——-基于-MLIR-的端到端全栈优化" class="headerlink" title="第二阶段：Adora Compiler —— 基于 MLIR 的端到端全栈优化"></a>第二阶段：Adora Compiler —— 基于 MLIR 的端到端全栈优化</h3><p>随着 AI 和张量计算需求的增加，LLVM 底层 IR 在进行高层循环变换（如 Tiling, Fusion）时显得力不从心。为此，开发了 <strong>Adora Compiler (DAC 2025)</strong>，利用 <strong>MLIR</strong> 的多层抽象能力，实现了从算子级到系统级的全栈优化。这是MLIR 工具链流程<br><img src="/assets/Pastedimage20251209210047.png" alt="alt text">该图对比 LLVM 与 MLIR 在抽象层级、可扩展性及优化能力上的差异。<br><img src="/assets/Pastedimage20251209205816.png" alt="alt text"></p><h4 id="基于多面体模型的数据流层级优化"><a href="#基于多面体模型的数据流层级优化" class="headerlink" title="基于多面体模型的数据流层级优化"></a>基于多面体模型的数据流层级优化</h4><p>Adora 充分利用 MLIR 的 <strong>Affine Dialect</strong>，在多面体模型（Polyhedral Model）的理论框架下进行激进的循环变换。</p><ul><li><strong>智能循环分块（Loop Tiling）</strong>：针对 CGRA 有限的 SPM 容量，Adora 自动计算最优分块大小，确保数据局部性，大幅减少 DRAM 访问。</li><li><strong>展开与压缩（Unroll-and-Jam）</strong>：为了提升并行度，Adora 对循环进行展开。更重要的是，它通过依赖多面体分析（Dependency Polyhedron）检测潜在的存储体冲突（Bank Conflict），智能选择展开策略。</li><li><strong>循环重排（Loop Reordering）</strong>：自动搜索最优的循环嵌套顺序，最大化数据复用。<br>该图展示经过 MLIR 优化后生成的复杂 CDFG 实例（以 MatMul 为例）。<br><img src="/assets/Pastedimage20251209210302.png" alt="alt text"></li></ul><h4 id="任务流层级优化：超越内核"><a href="#任务流层级优化：超越内核" class="headerlink" title="任务流层级优化：超越内核"></a>任务流层级优化：超越内核</h4><p>Adora 还通过<strong>任务流优化</strong>（Task-Flow Optimization）来提升整个 SoC 的运行效率。</p><ul><li><strong>软件流水线与乒乓缓存（Ping-Pong Buffering）</strong>：编译器生成双缓冲机制，利用 SoC 的乱序执行能力，在计算当前数据块的同时，通过 DMA 预取下一块数据。这种细粒度的流水线设计有效掩盖了数据传输延迟。</li><li><strong>指令去重</strong>：通过分析任务间的依赖关系，Adora 能够剔除冗余的配置指令和数据搬运请求。</li></ul><h4 id="AI-部署流程与自动化探索"><a href="#AI-部署流程与自动化探索" class="headerlink" title="AI 部署流程与自动化探索"></a>AI 部署流程与自动化探索</h4><p>Adora 提供了从 PyTorch&#x2F;ONNX 到 CGRA 的完整自动化路径。对于循环变换带来的巨大设计空间（分块大小 x 展开因子 x 重排顺序），Adora 摒弃了传统的遗传算法，设计了一套基于<strong>帕累托最优</strong>（Pareto-optimal）的快速搜索算法，以资源利用率和通信量为双重指标，实现了 6 倍以上的搜索速度提升。<br>该图展示 ResNet18 的层级拆解、计算核提取以及在 CGRA 上的流水线执行过程。<br><img src="/assets/Pastedimage20251209211335.png" alt="alt text"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul><li><strong>LLVM 工具链</strong>证明了 CGRA 可以像通用处理器一样，处理复杂的 C&#x2F;C++ 嵌套循环与不规则控制流，为通用计算卸载提供了可能。</li><li><strong>MLIR 工具链</strong>则展示了在 AI 与张量计算领域，通过高层语义分析与系统级流水线编排，软硬件协同设计可以达到媲美甚至超越 FPGA 的能效比。<br>该图详细对比总结两个工具链的优势、共同点与适用场景<br><img src="/assets/Pastedimage20251209211503.png" alt="alt text"></li></ul><h2 id="Architecture-and-Software-Optimizations"><a href="#Architecture-and-Software-Optimizations" class="headerlink" title="Architecture and Software Optimizations"></a>Architecture and Software Optimizations</h2><h3 id="CGRA-的核心痛点"><a href="#CGRA-的核心痛点" class="headerlink" title="CGRA 的核心痛点"></a>CGRA 的核心痛点</h3><p>传统的 CGRA 主要由许多的粗粒度的 PE (处理单元)组成，每个 PE 里有一个 ALU（算数逻辑单元）做加减乘除。它们比较适合做规整的矩阵运算。</p><p><img src="/assets/IMG_0033.jpeg" alt="alt text"></p><p>但是在实际的程序中，很多循环是不规则的，包含：</p><ul><li><ol><li>动态边界循环：循环次数编译时不知道 (例如 <code>while(i&lt;N)</code>，N 时变量)</li></ol></li><li><ol start="2"><li><code>if-then-else(ITE)</code>：循环体中有复杂的条件分支</li></ol></li><li>复杂的内存依赖：比如 <code>A[B[i]]</code> 这种间接寻址</li></ul><div class="tip">问题在于处理这些不规则控制流 （如计算 if 条件、跳转信号）需要大量的 `1-bit` 位运算 (`AND,OR,NOT`)。如果用一个宽 32-bit 的 ALU 去算一个 1-bit 的结果，不仅浪费资源，而且产生大量的控制信号连线，导致性能和能效的暴跌</div><div class="tip">对于传统的 CGRA 并不是很熟悉，但是在设计的时候就应该考虑控制流的问题，保证在 PE 单元计算的时候只是计算矩阵，这样不会出现上述的问题，一些加速器以及 NPU 都是这么设计</div><h3 id="COFFA-解决方案：软硬兼施"><a href="#COFFA-解决方案：软硬兼施" class="headerlink" title="COFFA 解决方案：软硬兼施"></a>COFFA 解决方案：软硬兼施</h3><p>COFFA 提出了“Fused-Grained”（融合粒度）的概念</p><h4 id="硬件架构：FGRA"><a href="#硬件架构：FGRA" class="headerlink" title="硬件架构：FGRA"></a>硬件架构：FGRA</h4><p>COFFA 设计了一种特殊的加速器，集成在 RISC-V SoC 中</p><p><img src="/assets/IMG_0035.jpeg" alt="alt text"></p><ul><li>FPE (Fused-Grained PE): <ul><li>传统部分：包含一个 ALU (做加法、乘法)</li><li>创新部分：嵌入了一个 LUT </li><li>融合设计：ALU 和 LUT 之间有本地直连线。LUT 专门处理负责 <code>if-else</code> 的条件判断和控制逻辑，ALU 负责真正的数据计算，这样既不浪费 ALU ，又能快速处理控制流</li></ul></li></ul><p><img src="/assets/IMG_0034.jpeg" alt="alt text"><br>图中展示了处理 <code>if-else</code> 的四种传统方式（a-d）和 COFFA 方法 (e)，虽然 Partial Predication 并行度高，但是需要额外的选择节点 (Select Node)，而 COFFA 把“计算条件”的逻辑 (LUT)和“选择结果”的逻辑 (Mux&#x2F;ALU)融合到一个 PE 里了，只需要一个周期就能出结果，并不需要其他方法那样等。</p><ul><li>FGIB：互联网络也能同时传输粗粒度数据和细粒度控制信号</li><li>IOB: 智能的存储控制器，支持简单的线性访问模式，也支持由 LUT 控制的复杂访问模式<br><img src="/assets/IMG_0037.jpeg" alt="alt text"></li></ul><h4 id="软件编译器：业界首个引入布尔代数优化的-CGRA-编译器"><a href="#软件编译器：业界首个引入布尔代数优化的-CGRA-编译器" class="headerlink" title="软件编译器：业界首个引入布尔代数优化的 CGRA 编译器"></a>软件编译器：业界首个引入布尔代数优化的 CGRA 编译器</h4><p>这是 COFFA 的优点，以前的编译器只管把运算映射到 PE 上，不管逻辑优化<br><img src="/assets/IMG_0039.jpeg" alt="alt text"></p><ul><li>前端（LLVM-based）:<ul><li>把 <code>if-else</code> 分支转换成数据选择操作 (partial predication)</li><li>识别出哪些是控制流逻辑，（比如 <code>condition = (a &gt; b) &amp;&amp; (c &lt; d)</code>）</li></ul></li><li>后端优化<ul><li>引入 Yosys: COFFA 把提取出来的控制逻辑喂给 yosys</li><li>布尔优化：yosys 会自动化简逻辑门（比如把多层逻辑合并），然后映射到 FPE 里的 LUT 上。这大大减少了需要的 PE 数量和连线长度</li><li>映射 (Mapping): 使用模拟退火算法，将优化后的计算图（CDFG）映射到硬件阵列上</li></ul></li></ul><div class="tip">在参加完 EDA 比赛完之后，老师也是想要提出将起前端设计与后端优化结合起来，实现一个前端设计+专用于设计优化的 eda 算法->实现更好的硬件电路效果，<mark style="background: #ADCCFFA6;">属于软硬件协同优化中的编译器-架构协同设计范畴，通过使用“跨层优化”的方式实现性能提升</mark><ul><li>传统分层：算法-&gt;高级语言-&gt;编译器-&gt;指令集-&gt;微架构-&gt;电路</li></ul><p>这应该算是这种优化算法的实例，这部分可以做的还有很多</p></div><h3 id="代码阅读"><a href="#代码阅读" class="headerlink" title="代码阅读"></a>代码阅读</h3><h4 id="硬件实现"><a href="#硬件实现" class="headerlink" title="硬件实现"></a>硬件实现</h4><ul><li>FPE 代码逻辑：<ul><li>在代码中的 FPE 类。实例化了 ALU 和 LUT 模块</li><li>ALU 的输入不仅可以来自邻居 PE，还可以直接来自内部的 LUT 输出（用于控制信号）。ALU 的比较结果 (如 <code>GreatThan</code>)也也可以直接喂给 LUT。这种“内部短路”设计大大减少了全局布线压力</li></ul></li><li>SoC 集成：<ul><li>代码利用 <code>Chipyard</code> 框架，将 FGRA 挂载到 RISC-V (Rocket Core)总线上（TileLink）。这在代码称为 <code>LazyModule</code> 的配置，使得 CPU 可以通过简单的指令配置 FGRA<br><img src="/assets/IMG_0036.jpeg" alt="alt text"></li></ul></li></ul><h4 id="编译器实现"><a href="#编译器实现" class="headerlink" title="编译器实现"></a>编译器实现</h4><ul><li>前端 Pass<ul><li>代码会遍历 LLVM IR。当遇到 <code>Phi</code> 节点（LLVM 中表示分支汇合的节点）时，编译器会将起转换为 <code>Select</code> 节点</li><li>动态边界处理：这是一个难点。代中会有专门的 Pass 去分析循环索引 (Induction Variables)。如果是动态边界，它会插入预计算指令（Pre-generation logic），提前算出下一层循环是否结束，从而避免流水线停顿</li></ul></li><li>后端映射与 Yosys 接口<ul><li>代码中会有一个步骤将提取出的子图 (Subgraph)转换为 verilog 或 BLIF 格式</li><li>调用 yosys 库进行逻辑化简</li><li>Mapper: 这是一个图匹配算法，使用模拟退火来寻找将 CDFG 节点放置到 6 x 6 或 8 x 8 阵列上最优解。代码会尽量把 LUT 节点和依赖它的 ALU 节点放在同一个 FPE 或相邻 FPE 中</li></ul></li></ul><h2 id="Fusion-DSE-flow"><a href="#Fusion-DSE-flow" class="headerlink" title="Fusion DSE flow"></a>Fusion DSE flow</h2><h3 id="为什么-Fusion-需要-DSE？"><a href="#为什么-Fusion-需要-DSE？" class="headerlink" title="为什么 Fusion 需要 DSE？"></a>为什么 Fusion 需要 DSE？</h3><p>Fusion SoC 架构（如下图所示）包含 Rocket Core、FGRA 阵列、多库 Scratchpad 存储器等多个组件。</p><p>为了适应不同的应用场景，设计者需要调整大量的硬件参数，例如：</p><ul><li><strong>架构层级：</strong> CGRA 的行&#x2F;列数、数据位宽。</li><li><strong>存储层级：</strong> Scratchpad 的深度、Buffer 大小。</li><li><strong>互连层级：</strong> 输入&#x2F;输出端口数量、路由连接方式。</li></ul><p>这些参数组合构成了一个<strong>极其庞大且复杂的设计空间</strong>。每一个参数组合（Input）都需要经过耗时的综合与仿真（Expensive Experiment）才能得到面积和吞吐量等指标（Objective Function）。</p><p><strong>核心痛点：</strong></p><ul><li><strong>穷举法（Exhaustive Search）：</strong> 不可能完成，空间太大。</li><li><strong>试错法（Trial and Error）：</strong> 效率太低，极其依赖人工经验。</li></ul><p>因此，我们需要一种智能算法，用最少的实验次数，找到性能最好的配置。</p><h3 id="贝叶斯优化（Bayesian-Optimization）"><a href="#贝叶斯优化（Bayesian-Optimization）" class="headerlink" title="贝叶斯优化（Bayesian Optimization）"></a>贝叶斯优化（Bayesian Optimization）</h3><p>解决昂贵黑盒函数优化问题的最佳工具之一是 <strong>贝叶斯优化（BO）</strong>。<br>贝叶斯优化不直接去跑昂贵的仿真，而是建立一个“代理模型”（Surrogate Model）来模拟硬件评估过程。它的工作流程包含三个关键要素：</p><ol><li><strong>统计模型（Statistical Model）：</strong> 通常使用<strong>高斯过程（Gaussian Process, GP）</strong>。它不仅预测某个配置的性能（均值），还能告诉我们要这一预测的“不确定性”（方差）。</li><li><strong>采集函数（Acquisition Function）：</strong> 用来决定“下一步测哪个点”。它需要在<strong>探索</strong>（Exploration，去不确定的地方看看）和<strong>利用</strong>（Exploitation，去已知表现好的地方深挖）之间通过 UCB 或 EI 等策略寻找平衡。</li><li><strong>优化器：</strong> 在代理模型上寻找采集函数的最大值。<br>通过这种“预测-采样-更新”的循环，BO 能够快速收敛到全局最优解</li></ol><h3 id="进阶方案：MoDAF-框架"><a href="#进阶方案：MoDAF-框架" class="headerlink" title="进阶方案：MoDAF 框架"></a>进阶方案：MoDAF 框架</h3><p>虽然传统的 BO 很强大，但在面对 Fusion 这种非凸、多模态的高维设计空间时，仍显吃力。于是提出了一种名为 <strong>MoDAF</strong> 的多目标分治参数调优框架。</p><h3 id="MoDAF-的创新点"><a href="#MoDAF-的创新点" class="headerlink" title="MoDAF 的创新点"></a>MoDAF 的创新点</h3><p><strong>1. 动态空间划分（Divide-and-Conquer Strategy）</strong><br>这是该框架的杀手锏。它不再在整个庞大的空间里盲目搜索，而是采用“分而治之”的策略：</p><ul><li><strong>SVM 划分：</strong> 使用支持向量机（SVM）将设计空间切割为“好”的子空间和“坏”的子空间。</li><li><strong>MCTS 搜索：</strong> 利用蒙特卡洛树搜索（MCTS）算法，基于 UCT 指标评估每个子空间的潜力，优先在最有希望的区域（高超体积 Hypervolume）进行采样。</li></ul><p><strong>2. 混合代理模型（Hybrid Surrogate Modeling）</strong><br>单一的高斯过程模型在处理复杂数据时可能受限。MoDAF 结合了多种模型（如随机森林、深度集成模型等），以提高预测的准确性。</p><p><strong>3. 双重采样策略（Dual-Sampling）</strong><br>同时利用 qEHVI（期望超体积改进）和 qUCB 策略，平衡全局搜索与局部挖掘，加速帕累托前沿（Pareto Frontier）的发现。</p><h3 id="实验成果"><a href="#实验成果" class="headerlink" title="实验成果"></a>实验成果</h3><p>在与 NSGA-II、MOTPE 等经典算法的对比实验中，MoDAF 展现了显著的优势：</p><ul><li><strong>收敛速度更快：</strong> 在相同的迭代次数下，MoDAF 能更快地提升超体积（Hypervolume）指标。</li><li><strong>解的质量更高：</strong> 能够找到面积更小、吞吐量更高的 Pareto 最优解组合。</li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>*PPT 以及图示来自 Fusion SoC Workshop：<a href="https://fpt-2025.lin.pub/#schedule">Fusion SoC: A Fused-Grained Reconfigurable Architecture for Efficient Edge Computing Acceleration</a><br>*开源仓库：<a href="https://github.com/Dai-dirk/COFFA">GitHub - Dai-dirk&#x2F;COFFA： COFFA：融合粒度可重构架构的共设计框架</a> </p>]]></content>
      
      
      
        <tags>
            
            <tag> Turtorial </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>(FPT2025)AMD Turtorial</title>
      <link href="/2025/12/10/FPT2025-AMD-Turtorial/"/>
      <url>/2025/12/10/FPT2025-AMD-Turtorial/</url>
      
        <content type="html"><![CDATA[<h2 id="Vitis-工具链的底层重构与系统设计创新"><a href="#Vitis-工具链的底层重构与系统设计创新" class="headerlink" title="Vitis 工具链的底层重构与系统设计创新"></a>Vitis 工具链的底层重构与系统设计创新</h2><h3 id="Vitis-Unified-IDE-的架构重构"><a href="#Vitis-Unified-IDE-的架构重构" class="headerlink" title="Vitis Unified IDE 的架构重构"></a>Vitis Unified IDE 的架构重构</h3><ul><li>框架迁移：从旧版专有框架迁移到 Eclipse Theia (前端)+ Electron。这意味着 Vitis 现在是一个基于现代 Web 技术的轻量级 IDE, 与 VS Code 的体验类似</li><li>数据驱动：所有的组件原数据从二进制 JSON&#x2F;YAML 格式，极大地友好了版本控制（git）</li><li>现代化 CLI：命令行接口全面采取 python 语言，便于脚本化和自动化</li></ul><h3 id="硬件描述的新标准——System-device-Tree-SDT"><a href="#硬件描述的新标准——System-device-Tree-SDT" class="headerlink" title="硬件描述的新标准——System device Tree (SDT)"></a>硬件描述的新标准——System device Tree (SDT)</h3><ul><li>创新点：废弃了使用了十几年的 <code>.xsa</code> (Xilinx Shell Archive)硬件描述文件</li><li>贡献：引入了 SDT（<code>.dts/dtsi</code>）。这是嵌入式 Linux 的标准，现在被 AMD 用来描述整个 FPGA&#x2F;SoC 硬件（包括内存映射、处理器集群）</li><li>工具链支持：引入“Lopper”工具，专门用于读取 SDT 并自动生成驱动配置和 BSP，实现了真正的“系统感知（System Aware)”</li></ul><h3 id="异构系统设计的关键突破：分段配置（Segmented-Cofiguration）"><a href="#异构系统设计的关键突破：分段配置（Segmented-Cofiguration）" class="headerlink" title="异构系统设计的关键突破：分段配置（Segmented Cofiguration）"></a>异构系统设计的关键突破：分段配置（Segmented Cofiguration）</h3><p>以前在 Versal 等平台上，如果想修改 AI 引擎（AIE）或 PL(可编程逻辑)部分，往往需要重新打包整个系统镜像并重启 Linux</p><ul><li>创新： 实现了 PS 与 PL&#x2F;AIE 的解耦<ul><li>Flat Flow vs. Segmented Configuration: 传统的 Flat Flow 是一次性加载所有内容。新的分段配置允许 PS 和 DDR NoC 先启动（运行 Linux），然后将 PL 和 AI 引擎的数据作为“独立荷载”加载</li><li>技术实现：Host App 可以直接读取 <code>xclbin</code> 中元数据，并通过 <code>fpga_util</code> 等工具在 Linux 运行时动态加载 <code>pl.pdi</code></li></ul></li></ul><h2 id="Vitis-HLS-等“性能驱动”开发方法论"><a href="#Vitis-HLS-等“性能驱动”开发方法论" class="headerlink" title="Vitis HLS 等“性能驱动”开发方法论"></a>Vitis HLS 等“性能驱动”开发方法论</h2><h3 id="Performance-Pragma-性能编译指令）"><a href="#Performance-Pragma-性能编译指令）" class="headerlink" title="Performance Pragma (性能编译指令）"></a>Performance Pragma (性能编译指令）</h3><ul><li>开发者需要手动组合 PIPELINE，UNROLL. ARRAY_PARTITION (数组分区)等数十种 Pragma。这需要深厚的硬件知识、一旦更换芯片，所有的 Pragma 可能都需要重写</li><li>引入 <code>pragma HLS performance target_ti=…</code> (Target Transcation Interval)<ul><li>自动化推导：用户只需要告诉编译器：“我想在 300 MHz”下每秒处理 140 帧图像（即 TI&#x3D;2142857 周期）。编译器会自动计算并插入底层的 pipeline&#x2F;unroll 指令来满足这个目标</li><li>反向注解：工具自动生成的优化指令可以被导出，反写回用户的源码或配置文件中，供专家级用户进行二次微调</li></ul></li></ul><h3 id="自动化的循环分析"><a href="#自动化的循环分析" class="headerlink" title="自动化的循环分析"></a>自动化的循环分析</h3><ul><li>创新点：C-sim Profilling with Loop Trip Counts</li><li>细节：以前处理动态循环，用户必须手动告诉工具循环次数。现在，Vitis 可以在 C 仿真阶段自动捕获循环的运行次数，并将其作为性能估算的依据，无需人工干预</li></ul><h3 id="性能成果"><a href="#性能成果" class="headerlink" title="性能成果"></a>性能成果</h3><p>53 个设计可以成功达到 500MHZ</p><h2 id="LLM-辅助-EDA-设计"><a href="#LLM-辅助-EDA-设计" class="headerlink" title="LLM 辅助 EDA 设计"></a>LLM 辅助 EDA 设计</h2><p>直接问 LLM 写 HLS 代码行不通，必须采用“元提示”(Meta Prompting)策略，并发布了基于 AI 的新工具链</p><h3 id="LLM-在-HLS-中的局限与突破"><a href="#LLM-在-HLS-中的局限与突破" class="headerlink" title="LLM 在 HLS 中的局限与突破"></a>LLM 在 HLS 中的局限与突破</h3><ul><li><strong>实验背景：</strong> 基于中国 FPGA 竞赛（HLS 赛道），154 份有效提交，学生使用 GPT-4&#x2F;DeepSeek 优化 SHA256, LZ4, Cholesky 等算法。</li><li><strong>关键发现：</strong><ul><li><strong>Zero-Shot (直接提问) 失败率高：</strong> LLM 对 HLS 这种“类 C 但非 C”的语法理解很差，经常生成不仅无法综合，甚至破坏数据依赖（Data Dependency）的代码。</li><li><strong>创新——Meta Prompting (元提示)</strong>：仅仅把 LLM 当编码器是不够的，必须把它当作“架构师”<ul><li>Task-Level Prompt: 强制 LLM 采用 Load-Compute-Store（LCS）架构模式，将顺序代码重构为数据流（Dataflow）形式<ul><li>Data-Level Prompt: 注入知识库，在 Prompt 中包含 Vitis HLS 官方文档的精简版（例如：解释 <code>cyclic</code> 分区和 <code>clock</code> 分区的区别）让 LLM 基于规则写代码</li></ul></li></ul></li><li><strong>成果：</strong> 采用 Meta Prompting 的学生，其设计性能比基线提升了 <strong>6.5 倍</strong>。</li></ul></li></ul><h3 id="Vitis-IDE-的-AI-路线图-CRAI"><a href="#Vitis-IDE-的-AI-路线图-CRAI" class="headerlink" title="Vitis IDE 的 AI 路线图 (CRAI)"></a><strong>Vitis IDE 的 AI 路线图 (CRAI)</strong></h3><ul><li><strong>2025.2 (Early Access)：</strong> <strong>BYOK (Bring Your Own Key)</strong> 模式。允许用户在 Vitis IDE 内直接挂载自己的 OpenAI&#x2F;Local LLM API key，实现代码解释和辅助。</li><li><strong>2026.1 (Future)：</strong><ul><li><strong>AI Performance Budgeter：</strong> AI 自动分析性能瓶颈并分配时序预算。</li><li><strong>RAG Chatbot：</strong> 基于 AMD 官方文档训练的专用问答机器人（解决通用大模型幻觉问题）。</li></ul></li></ul><h2 id="端侧-AI-Edge-AI-与具身智能-Robotics"><a href="#端侧-AI-Edge-AI-与具身智能-Robotics" class="headerlink" title="端侧 AI (Edge AI) 与具身智能 (Robotics)"></a>端侧 AI (Edge AI) 与具身智能 (Robotics)</h2><p><strong>创新主旨：</strong> 利用 AMD 独有的“大统一内存”架构，打通从云端训练到边缘部署的完整链路，解决机器人领域的 Sim2Real 难题。</p><h3 id="1-硬件创新：Ryzen-AI-Max-Strix-Halo-的架构优势"><a href="#1-硬件创新：Ryzen-AI-Max-Strix-Halo-的架构优势" class="headerlink" title="1.硬件创新：Ryzen AI Max (Strix Halo) 的架构优势"></a>1.硬件创新：Ryzen AI Max (Strix Halo) 的架构优势</h3><ul><li><strong>核心参数：</strong> 40 CU GPU + 50 TOPS NPU。</li><li><strong>杀手级特性：128GB 统一内存 (Unified Memory)</strong>。<ul><li><strong>对比竞品：</strong> 传统的 CPU+独立显卡架构，数据需要在内存和显存之间通过 PCIe 搬运，不仅慢而且受限于显存大小（通常仅 16GB-24GB）。</li><li><strong>贡献：</strong> Ryzen AI 允许 CPU、GPU 和 NPU 共享这 128GB 内存。这意味着可以在<strong>笔记本&#x2F;Mini PC 这种边缘设备上，直接加载运行 70B（700亿参数）级别的超大模型</strong>，无需量化或剪枝。</li></ul></li></ul><h3 id="2-具身智能全栈工作流-The-Embodied-AI-Pipeline"><a href="#2-具身智能全栈工作流-The-Embodied-AI-Pipeline" class="headerlink" title="2.具身智能全栈工作流 (The Embodied AI Pipeline)"></a>2.具身智能全栈工作流 (The Embodied AI Pipeline)</h3><p>AMD 展示了一套完整的机器人开发闭环：</p><ul><li><strong>Step 1 云端训练：</strong> 使用 Instinct MI300 集群训练 <strong>OpenVLA</strong> (Vision-Language-Action) 模型。</li><li><strong>Step 2 物理仿真：</strong> 使用开源仿真器 <strong>Genesis</strong>。<ul><li><strong>创新：</strong> 该仿真器支持 AMD GPU 加速，可以在虚拟环境中并行训练数千个机器人代理（Agent），例如训练机器狗走过崎岖地形。</li></ul></li><li><strong>Step 3 Sim2Real (仿真到现实)：</strong><ul><li><strong>难点：</strong> 仿真图像与真实世界有色差和纹理差异（Domain Gap）。</li><li><strong>解决方案：</strong> 使用 Ryzen AI 收集少量真实数据，进行<strong>域适应 (Domain Adaptation)</strong> 微调。</li></ul></li><li><strong>Step 4 边缘部署：</strong> 将微调后的 VLA 模型部署在搭载 Ryzen AI 的机械臂控制柜中，实现对动态物体的抓取和操作。</li></ul><h3 id="3-学术生态支持-Ryzers-AIPC-Cluster"><a href="#3-学术生态支持-Ryzers-AIPC-Cluster" class="headerlink" title="3. 学术生态支持 (Ryzers &amp; AIPC Cluster)"></a>3. 学术生态支持 (Ryzers &amp; AIPC Cluster)</h3><ul><li><strong>AIPC Cluster：</strong> 演示了一种低成本方案，用 20+ 个 Mini PC 组成集群，功耗低、噪音小，但总显存极大，适合实验室环境。</li><li><strong>Ryzers：</strong> 这是一个开源项目，提供了预配置好的 Docker 容器，包含 ROS2、PyTorch、Triton 等全套环境，解决环境配置难的问题</li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>*PPT 及其图示来自 FPT 2025 AMD Turtorial</p>]]></content>
      
      
      
        <tags>
            
            <tag> Turtorial </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>(FPT2025)可重构机器学习处理器：基本概念、应用与未来趋势——尹首一教授（清华大学）</title>
      <link href="/2025/12/10/FPT2025-Shouyi_Yin/"/>
      <url>/2025/12/10/FPT2025-Shouyi_Yin/</url>
      
        <content type="html"><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><h3 id="可重构计算-技术路径"><a href="#可重构计算-技术路径" class="headerlink" title="可重构计算-技术路径"></a>可重构计算-技术路径</h3><p><img src="/assets/8e31e6dce543781774c413944a4829b8.jpeg" alt="alt text"><br>主要将其计算架构分为两大类：</p><ul><li>程序中心型（Program-Centric）：性能和组件由设计者决定。</li><li>数据中心型（Data-Centric）：性能和&#x2F;或组件受通过系统的数据影响。</li></ul><h4 id="程序中心型细分"><a href="#程序中心型细分" class="headerlink" title="程序中心型细分"></a>程序中心型细分</h4><p><strong>传统冯·诺依曼架构（Good old-fashioned Von Neumann）</strong></p><ul><li>存储器（Memory)<ul><li>COMS 技术：SRAM、DRAM、Flash</li><li>非 COMS 技术：NVM crossbars or S-SCM, M-SCM</li><li>其他：TCAM</li></ul></li><li>处理器（Processor)<ul><li>COMS 技术：GPUs</li><li>非 COMS 技术：“Next Switch”</li><li>其他：NV computing</li></ul></li></ul><p><strong>非冯·诺依曼架构（Non-Von Neumann）</strong></p><ul><li>处理器（Non-Von Neumann Processor）<ul><li>COMS 技术：FPGA、粗粒度可重构架构（Coarse-Grained Reconfigurable Architecture）、模拟计算（Analog Computing）、加速器（Accelerators (multi-die)）</li><li>非 COMS 技术：Active interconnect、Coupled oscillators, NVM-based FPGA、量子计算（Quantum computing）(不确定)</li></ul><ul><li>其他：逻辑内存(Logic in Memory)、概率统计计算 (Probabilistic computing)（不确定）、近似计算（Approximate computing）（不确定）</li></ul></li></ul><h4 id="数据中心型细分"><a href="#数据中心型细分" class="headerlink" title="数据中心型细分"></a>数据中心型细分</h4><p><strong>离线训练（Trained off-line)</strong></p><ul><li>执行预训练ANN：如True North、Omic Weave等。</li><li>关联计算</li><li>ML加速器（卷积、SVM、ML）等。</li></ul><p><strong>在线训练（Trained in-line）</strong></p><ul><li>新学习算法：如无监督学习、强化学习等。</li><li>监督ANN学习：如交叉点用于反向传播等。</li><li>概率学习：如贝叶斯RBM等。</li></ul><h3 id="可重构计算-实现机制"><a href="#可重构计算-实现机制" class="headerlink" title="可重构计算-实现机制"></a>可重构计算-实现机制</h3><p><img src="/assets/d5e54128da0722f66db85a4220fd2ccd.jpeg" alt="alt text"></p><h4 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h4><p>构建运行时可重构的硬件和软件，使数据密集型算法在保持编程灵活性的同时，达到 ASIC 的性能</p><ul><li>SDH (Software-Defined-Hardware)，即软件定义硬件，使实现这一目标的核心技术</li></ul><h4 id="技术架构"><a href="#技术架构" class="headerlink" title="技术架构"></a>技术架构</h4><p><strong>高层抽象程序，即通过动态的硬件&#x2F;软件编译器（TA 2）生成最优配置和代码</strong></p><ol><li>基于静态分析代码生成最优配置</li><li>生成最优代码</li><li>根据运行时数据重新优化机器代码和处理器配置</li></ol><p><strong>可重构的处理器（TA 1）</strong></p><ol><li>重构时间在 300 ns-100 ns</li><li>可重新分配计算资源（如 ALU 用于地址计算或数学运算）</li><li>可重新分配内存资源（如缓存&#x2F;寄存器配置以匹配数据）</li><li>可塑性外部内存访问（如可重构内存控制器）</li></ol><p>高层抽象的程序通过编译器生成多个代码段 (Code_1,Code_2,…,Code_n)每个代码段对应一个特定的配置 (Config_1, Config_2,Config_n)。这些配置随时间变化，以适应不同的运行时需求，体现了系统的动态性和灵活性。</p><h3 id="SDH（Software-defined-Hardware）"><a href="#SDH（Software-defined-Hardware）" class="headerlink" title="SDH（Software defined Hardware）"></a>SDH（Software defined Hardware）</h3><p><img src="/assets/3d6a2e2450a51aac1d9143a0a1fe6480.jpeg" alt="alt text"><br>从图中可以看出不同的计算硬件在能效和编程灵活性之间的权衡关系，强调了 SDH 在这平衡中的重要。</p><h3 id="可重构计算：概念"><a href="#可重构计算：概念" class="headerlink" title="可重构计算：概念"></a>可重构计算：概念</h3><ul><li>可重构架构：利用可编程资源（处理单元与互连网络）动态配置最适合软件任务的计算架构，实现接近 ASIC 的性能</li><li>关键特性：<ul><li>数据驱动计算，无指令</li><li>多重重构层次</li><li>时空与串并行调度</li><li>兼具灵活性与高能效</li></ul></li><li>计算任务（软件）-&gt; 数据流图-&gt; 数据通路（硬件）</li></ul><h3 id="早期应用"><a href="#早期应用" class="headerlink" title="早期应用"></a>早期应用</h3><p>可重构计算并非全新概念，其早期应用主要集中在信号处理和通信领域。这些应用场景通常包含<strong>算法多样性、实时性约束、数学密集型操作和规整的数据模式等</strong>特点。例如，在视频处理中需要运行多种编解码算法，在软件无线电中需要实时处理通信协议，这些都对硬件提出了既要高效又要灵活的要求。因此，像 FIR 滤波器、FFT、OFDM 调制解调等任务，成为了早期验证可重构计算优势的典型负载。</p><p>还有一些期可重构处理器在商业应用中的具体实例。例如，三星公司利用可重构处理平台为其8K 超高清电视开发了灵活的视频后处理解决方案，以支持不断演进的新标准。同时，瑞萨电子的 DRP 和 IPFlex 的 DAPDNA-2架构也是可重构技术在通信和信号处理领域成功商业化的代表，它们通过可编程的处理单元阵列和互连网络，为特定领域提供了高效而灵活的计算能力。</p><h3 id="为什么要采用可重构计算"><a href="#为什么要采用可重构计算" class="headerlink" title="为什么要采用可重构计算"></a>为什么要采用可重构计算</h3><p><img src="/assets/fd966305ecc4f52f1ef06b29fbeb56d3.jpeg" alt="alt text"></p><ul><li>提供“领域特定的灵活性”，同一个硬件可以高效支持同一应用领域内的多种算法</li><li>通过“空间计算”架构，它可以实现高吞吐量和实时处理能力</li><li>通过“时空计算”调度，它可以灵活地组合不同计算内核</li><li>“数据流驱动执行”模型消除了指令开销，提升了效率</li></ul><h3 id="挑战"><a href="#挑战" class="headerlink" title="挑战"></a>挑战</h3><p>从手势识别、人脸检测到 ChatGPT 等大语言模型，人工智能应用层出不穷。图中曲线清晰地展示了从2012年 AlexNet 开始，深度学习模型在 ImageNet 数据集上的识别准确率急剧提升，同时模型的计算复杂度和参数量也呈爆炸式增长。这预示着到2033年，我们将面临计算需求远超万倍于今天的巨型模型，这对底层计算硬件提出了前所未有的挑战。</p><p>与传统的、算法固定且精度单一的信号处理不同，现代神经网络模型展现出高度多样性。一个 Transformer 解码层内部就包含了多种类型的计算（如注意力、全连接），其连接方式（稀疏或全连接）、数据精度 （如 INT 8、FP 16）和拓扑结构都可能不相同。</p><p>这种“多样性”是神经网络强大表征能力的来源，但也使得为其设计通用高效硬件变得异常困难。</p><p>网络拓扑的多样化是神经网络发展的显著趋势。图中时间轴展示了从早期的简单序列模型（Seq 2 Seq）和卷积网络（AlexNet, VGG，到引入残差连接到 ResNet、自注意力机制 Transformer，再到如今参数庞大的 GPT、PaLM 等大模型。拓扑结构日趋复杂，从单一模态处理发展到多模态融合。这种复杂性要求硬件能够灵活适应从卷积、全连接到注意力等多种计算模式。</p><h4 id="硬件要求——灵活的数据流"><a href="#硬件要求——灵活的数据流" class="headerlink" title="硬件要求——灵活的数据流"></a>硬件要求——灵活的数据流</h4><p>不同的网络拓扑导致了不同的数据复用模式，进而对硬件数据流提出了灵活性的要求。</p><p><img src="/assets/bfb33003bba6ddcc0339974e07c2a280.png" alt="alt text"><br>图示对比了“输出重用”和“输入重用”两种典型数据流。</p><ul><li>例如对于某些层，重用输出特征图能最大化减少数据访问；</li><li>对于另外一些层，重用输入数据或权重可能更有效</li></ul><p>硬件需要能够动态配置数据流，以匹配计算过程中的数据复用特性，从而最小化能耗最高的片外内存访问。</p><h4 id="硬件要求——多维稀疏性"><a href="#硬件要求——多维稀疏性" class="headerlink" title="硬件要求——多维稀疏性"></a>硬件要求——多维稀疏性</h4><p>稀疏性意味着张量中存在大量零值。如图所示，稀疏可能会出现在输入、权重或输出等多个维度。这些零值在计算中是无效的，如果硬件仍对其进行计算，将造成巨大的资源浪费。<br><img src="/assets/79b5f56ad00d60c95d5c78006ba15794.png" alt="alt text"><br>图中展示了两种处理方式：</p><ul><li>对于输入和权重的稀疏，可以进行“逐元素跳过”，只将非零的操作数对送入处理单元队列（PE）进行乘加运算。</li><li>对于输出的稀疏，则可以进行“向量级跳过”，避免对整个输出向量的无效计算<br><img src="/assets/3c279ed5af600df9fa555e73a14dbbbf.png" alt="alt text"></li></ul><h4 id="硬件要求——精度"><a href="#硬件要求——精度" class="headerlink" title="硬件要求——精度"></a>硬件要求——精度</h4><p>数据精度（位宽）的选择是精度、功耗和面积之间的权衡。如图所示，不同的 AI 应用场景对精度的需求个不相同，从低精度的 INT 4 到较高精度 FP 16 等。</p><ul><li>采用固定精度处理单元会带来非预期的功耗和面积开销</li><li>采用可配置精度的处理单元，则可以根据任务需求动态调整，在保证精度的同时实现最优的能效和面积效率<br><img src="/assets/bdf0deb8abf7189d5be14802e832e5ce.png" alt="alt text"></li></ul><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p><img src="/assets/aace45cb317c3fe0e4ef582017795d06.png" alt="alt text"><br>综上所述，面向 AI 的可重构处理器，其核心设计目标是实现是三个维度的“灵活性”</p><ul><li>适应不同拓扑的功能编程性</li><li>跳过无效计算的稀疏性处理</li><li>以及支持混合精度运算的可配置处理单元</li></ul><p>这些灵活性的目的都是为了最大化一个核心指标：<strong>能效</strong><br>能效由硬件利用率、吞吐量、实际有效操作数与功耗共同决定</p><h3 id="软件编程-VS-硬件重构"><a href="#软件编程-VS-硬件重构" class="headerlink" title="软件编程 VS 硬件重构"></a>软件编程 VS 硬件重构</h3><p><img src="/assets/8befd887e260ec8261badaf8f9e2f4a0.jpeg" alt="alt text"></p><h4 id="软件编程"><a href="#软件编程" class="headerlink" title="软件编程"></a>软件编程</h4><ul><li>变量拓扑：通过插入分支指令来处理所有的节点，但这种方法在处理元素级稀疏性时存在局限</li><li>特定稀疏性：无法有效处理元素级稀疏性</li><li>混合精度：无法选择计算精度，通常固定为 INT 8</li></ul><h4 id="硬件重构"><a href="#硬件重构" class="headerlink" title="硬件重构"></a>硬件重构</h4><ul><li>变量拓扑：通过配置连接来实现，能够灵活应对不同的拓扑结构</li><li>硬件重构：在拓扑、稀疏性和精度三个方面均具有较高的灵活性</li></ul><h3 id="重构抽象"><a href="#重构抽象" class="headerlink" title="重构抽象"></a>重构抽象</h3><p>为了实现上述的灵活性，我们可以将重构抽象为三个层次。</p><ul><li>芯片级重构关注全局，例如动态适应不同的稀疏模式以提升整体硬件利用率</li><li>处理单元阵列（PEA）重构关注数据如何在处理单元（PE）流动，通过配置数据流来最大化数据复用</li><li>处理单元级重构 (PE)则关注最基本的计算单元，通过位级别的重组来支持从低到高的不同运算精度。<br>这三个层次共同构成了可重构 AI 处理器的设计框架</li></ul><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><h3 id="PE-level-重构"><a href="#PE-level-重构" class="headerlink" title="PE-level 重构"></a>PE-level 重构</h3><p>让最基本的处理单元支持多样的数据精度。主要有三种技术路径：</p><ul><li>位串行方法在时间上逐位处理数据，功耗低但吞吐量也低</li><li>位融合方法则在空间上组合多个低精度处理单元来形成更高精度的单元，能实现高吞吐量</li><li>浮点融合方法，这对云端 AI 训练服务器至关重要<br><img src="/assets/f15c03eb6696d130e56969f76c6666ec.png" alt="alt text"></li></ul><h4 id="位串行方法"><a href="#位串行方法" class="headerlink" title="位串行方法"></a>位串行方法</h4><p><img src="/assets/80f1be2af48fc174c0cd41d4e7209349.jpeg" alt="alt text"><br><img src="/assets/0eb338f802a881d66798753868d08daa.jpeg" alt="alt text"></p><p>该设计主要用于动态调整数据处理的位宽，通过计数器和比较器控制多路选择器的选择，实现灵活的数据处理能力。</p><p>使用&amp;门进行位与操作，生成部分积。使用加法器累加部分积，使用多路选择器根据当前位宽选择合适的部分积进行累加。最后再难过结果通过 SUM 模块输出，表示两个输入数的乘积。在每个周期内，电路处理一位输入数据，逐步累加部分积。根据 S 0, S 1, S 2 的值确定当前操作的位宽，从而控制循环次数。</p><p><img src="/assets/c2c846e56c69fcda63d493e685958138.jpeg" alt="alt text"></p><h4 id="位融合方法"><a href="#位融合方法" class="headerlink" title="位融合方法"></a>位融合方法</h4><p><img src="/assets/1ae52154a1ce67cc4a312afade3e2270.jpeg" alt="alt text"></p><p>通过分解和映射的方式实现 4 位二进制的乘法运算。</p><ul><li>4 位乘法（a）：展示了两个 4 位二进制数（13 和 6）相乘的过程，结果为 78。通过逐位相乘和移位相加得到最终结果。</li><li>分解为 4 个 2 位乘法（b）：将 4 位乘法分解为 4 个 2 位乘法操作。将每个 2 位乘法的结果通过移位（左移 2 位或 4 位）后相加，得到最终的乘积</li><li>映射到 Bit-brick 单元 (c)：将分解后到 2 位乘法操作映射到 Bit-Brick (BB)。每个 Bit-Brick 单元执行一个 2 位乘法，并根据移位操作，最后将所有结果相加得到最终乘积<br><img src="/assets/bb0b2658104178155684040d2e6d2b17.png" alt="alt text"><br>比如这三种不同的乘法器架构设计分别适用于不同规模的计算需求。选择合适的架构可以优化计算效率和资源利用率</li></ul><p><img src="/assets/604bd9e8e22ba84783024553053edb4a.png" alt="alt text"></p><h4 id="FP-融合方法"><a href="#FP-融合方法" class="headerlink" title="FP 融合方法"></a>FP 融合方法</h4><p><img src="/assets/2e4802092ba0c4ea158647920ed6518d.jpeg" alt="alt text"><br>该图描述了在 PE 级重构中，如何通过共享逻辑实现 FP 8 模式下的高效计算。FP 8 模式利用 1 位符号、4 位指数和 3 位尾数的格式，在每个周期内完成 2 个 MAC 操作，从而提升计算效率。</p><p>在 DL Core 中包含多个处理单元 (PE)，每个 PE 都可以进行 2 x 8 b 的操作。Coloumn Buffer 用于存储和传输数据</p><p>在 FP 8 模式下，每个周期都可以执行 2 个 FP 8 MAC（乘加运算）操作。FP 单元共享乘法器、对齐器、加法器和归一化逻辑以实现重构。</p><p>FP 8 操作流程: 指数相加-&gt;乘法运算-&gt;对齐操作-&gt;加法运算-&gt;归一化-&gt;舍入</p><h3 id="PEA-level-重构"><a href="#PEA-level-重构" class="headerlink" title="PEA-level 重构"></a>PEA-level 重构</h3><h4 id="面向最小数据访问的数据流重构"><a href="#面向最小数据访问的数据流重构" class="headerlink" title="面向最小数据访问的数据流重构"></a>面向最小数据访问的数据流重构</h4><p>三种典型的数据流范式，分别对应于不同的数据复用策略</p><ul><li>输入静态：在 NxHxL 维度上保持输入数据不懂，适用于输入数据复用率高的场景</li><li>输出静态：在 RxCxM 维度上保持输出数据不动，减少中间结果的移动</li><li>权重静态；在 KxKxN 维度上保持权重数据不动，适用于权重复用率高的计算</li></ul><p>两种 PEA（处理单元阵列）级重构方式：</p><ul><li>单体式重构：支持权重静态、输入静态、输出静态和行静态四种独立数据流模式</li><li>交错式重构：可同时支持输入+权重静态、权重+输出静态等混合数据流模式<br>这种灵活的数据流配置能力使得 AI 处理器能够更好地适配不同的神经网络结构的数据访问模式</li></ul><h4 id="可重构数据流-交错式重构"><a href="#可重构数据流-交错式重构" class="headerlink" title="可重构数据流-交错式重构"></a>可重构数据流-交错式重构</h4><p>以生成对抗网络为例，说明在 GAN 等复杂模型中，生成器和判别器两种网络拓扑可能同时存在，对数据流提出不同要求<br><img src="/assets/23e224b62e048df593ee930616e6e6d5.png" alt="alt text"></p><p>从输入照片到判别器输出“狗&#x2F;猫”概率的过程，以及生成器与判别器之间的“极大极小博弈”</p><p>这种多拓扑共存的情况要求 AI 处理器具备在同一时间内处理不同数据流模式的能力。<br><img src="/assets/e529ed622bc63369a19a6bab25c461ca.png" alt="alt text"><br>有三种多路复用策略来说明如何支持多神经网络拓扑：</p><ul><li>时分复用：在不同时间片执行不同 DNN</li><li>空分复用：嫁给你硬件资源分区并行执行不同 DNN</li><li>自适用时空复用：动态结合时分与空分，以最大硬件利用率。通过在 PEDA 级别实现混合数据流，可以有效地在同一硬件上灵活调度多种神经网络任务</li></ul><h3 id="面向多种稀疏性的芯片级重构"><a href="#面向多种稀疏性的芯片级重构" class="headerlink" title="面向多种稀疏性的芯片级重构"></a>面向多种稀疏性的芯片级重构</h3><p>该部分从三个层次介绍了如何通过芯片级重构来高效处理神经网络中的稀疏性：</p><ul><li>元素级：对稀疏矩阵进行压缩，仅计算非零元素</li><li>向量级：支持乱序计算，跳过全零箱向量的运算</li><li>向量间跳过：在向量点积中，若某一向量为零则跳过整个计算。<br><img src="/assets/afd2236ea8a4617a932b847d04c36a05.jpeg" alt="alt text"><br>这些方法可以显著减少不必要的计算与数据移动</li><li>在缓存中对稀疏的输入和权重进行压缩与编码</li><li>生成计算掩码，仅对非零元素对执行计算</li><li>在 PEA 中完成计算后，通过位置恢复逻辑重建输出的稠密格式。</li></ul><h4 id="BENES-网络"><a href="#BENES-网络" class="headerlink" title="BENES 网络"></a>BENES 网络</h4><p>这是一种利用非对称 BENES 网络实现芯片级操作数路由的重构技术。</p><p>图示了一个 8 输入到 4 输出点 BENES 网络，它能够将 8 个输入到 4 个非零操作数动态路由到 4 个 PE 中进行计算。如果非零操作数超过 4 个，则将其拆分到两个周期完成。这种设计能够根据输入与权重的实时稀疏模式，灵活分配计算资源，最大化利用率<br><img src="/assets/bc225ec0e6d14cae7a7b75d3bfde3d0a.png" alt="alt text"></p><h4 id="输入与权重稀疏性"><a href="#输入与权重稀疏性" class="headerlink" title="输入与权重稀疏性"></a>输入与权重稀疏性</h4><p>通过一个简单数据流图示，说明当神经网络中输入和权重都具有稀疏性时，芯片级重构如何工作：稀疏的输入与权重相乘后产生输出，再经过 ReLU 激活函数可能进一步引入稀疏性。</p><h4 id="输出稀疏性"><a href="#输出稀疏性" class="headerlink" title="输出稀疏性"></a>输出稀疏性</h4><p>即是输入和权重时稠密的，经过 Relu 等激活函数后，输出也可能变得稀疏。需要能能够识别并跳过对后续计算无贡献的零值输出，从而避免无效的数据移动与计算</p><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><ul><li>芯片级重构：如 BENES 网络，处理操作数路由与稀疏计算</li><li>PEA 级重构：包括单体式与交错式数据流重构，适配不同网络拓扑</li><li>PE 级重构：涵盖位串行、位融合与浮点融合等技术，实现计算精度的灵活配置。</li></ul><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>重点介绍三家代表性企业的处理器：</p><ul><li>SambaNova 的 RDA 处理器</li><li>Groq 张量流处理器</li><li>TsingMicro 的 RPU</li></ul><h3 id="SambaNova-RDA-处理器"><a href="#SambaNova-RDA-处理器" class="headerlink" title="SambaNova RDA 处理器"></a>SambaNova RDA 处理器</h3><p>Kunle Olukotun 指出，数据流架构使计算能够围绕模型灵活组织，而非受限于固定指令流水线。</p><p>SambaNova 从硬件到软件均采用协同设计实现了从底层开始的可重构性。图中列出了其 SN-40 L 服务器的关键特性，如芯片级和 PEA 级重构、对稀疏计算的支持、多数据流处理能力及混合算子功能</p><h3 id="Groq-张量流处理器"><a href="#Groq-张量流处理器" class="headerlink" title="Groq 张量流处理器"></a>Groq 张量流处理器</h3><p>Groq 芯片的可重构性体现在两个层面：</p><ul><li>在 PEA 级，通过软件定义计算资源分配，并灵活配置水平和垂直的数据与指令流</li><li>在芯片级，支持输出和权重的稀疏性处理，并能实现跨芯片的数据流协调</li></ul><h3 id="TsingMicro-RPU"><a href="#TsingMicro-RPU" class="headerlink" title="TsingMicro RPU"></a>TsingMicro RPU</h3><p>该产品线主要面向边缘计算场景<br><img src="/assets/1e38a894e9ab4182ba8d3ad2f4a3de79.jpeg" alt="alt text"></p><h2 id="趋势"><a href="#趋势" class="headerlink" title="趋势"></a>趋势</h2><p>3 D 集成重构、多芯片重构、微观重构</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>AI 模型的三大多样性特征：</p><ul><li>多样的网络拓扑</li><li>多样的输入&#x2F;权重&#x2F;输出稀疏性</li><li>推理&#x2F;训练所需的不同数值精度</li></ul><p>为了适配这些多样化的需求，硬件需要相应地在是那个层面进行重构</p><ul><li>在芯片级，进行稀疏处理重构，动态适应稀疏模式，提高处理单元利用率</li><li>在 PEA 级，进行数据流重构，匹配不同神经网络拓扑，减少昂贵的内存访问</li><li>在 PE 级，进行 MAC 运算单元重构，支持混合精度计算，从而最大化能效</li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>*PPT 及其图示来自 FPT 2025 讲座——可重构机器学习处理器：基本概念、应用与未来趋势（尹首一教授）</p>]]></content>
      
      
      
        <tags>
            
            <tag> Lecture </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>(FPT2025)简化FPGA开发：敏捷设计流程带来的挑战和机遇——张薇教授（香港科技大学）</title>
      <link href="/2025/12/10/FPT2025-Wei_Zhang/"/>
      <url>/2025/12/10/FPT2025-Wei_Zhang/</url>
      
        <content type="html"><![CDATA[<h2 id="HLS-编译流程与设计空间爆炸"><a href="#HLS-编译流程与设计空间爆炸" class="headerlink" title="HLS 编译流程与设计空间爆炸"></a>HLS 编译流程与设计空间爆炸</h2><p><img src="/assets/5195998540c45ea6b8039eda79ba3146.jpg" alt="alt text"><br>这张图展示了 HLS 生成 RTL 代码的流程并给出了一个示例，展示了增加 HLS pragma 之后代码的区别</p><ul><li>gemm（矩阵乘法）的原始代码（gemm.cpp）和优化代码（gemm_opt.cpp）</li><li>原始代码使用三重嵌套循环实现矩阵乘法</li><li>通过添加<code>#pragma HLS UNROLL factor=2</code>指令，HLS工具会将循环展开，让多个计算同时进行，从而大幅提高速度。<br>可以看到生成的 verilog 的不同</li></ul><p><img src="/assets/84861a947b1c100bb2c96737079d2c00.jpg" alt="alt text"><br>但问题在于：HLS 有26个常用指令，每个指令有多个参数，组合起来有500万种可能的配置。想象一下，如果每个配置都需要人工尝试，开发人员需要尝试500万次才能找到最佳方案，这显然是不现实的。</p><p>所以，HLS 工具需要自动优化能力，帮助开发人员从500万种可能性中快速找到最佳配置。优化后，性能可以提升100倍，这说明了 HLS 指令优化的巨大价值。</p><p>图中指出了一些性能优化模型结合 DSE 将原始 HLS 迭代生成调优后的 HLS 代码</p><h2 id="分析式性能建模的整体框架"><a href="#分析式性能建模的整体框架" class="headerlink" title="分析式性能建模的整体框架"></a>分析式性能建模的整体框架</h2><p>性能建模通常从 C&#x2F;C++代码开始，通过一个特征化库（Characterized Library）进行分析，最终构建出分析模型 (Analytical Model)。该模型可用于对硬件设计的性能、功耗和面积（PPA）进行早期评估，以 COMBA (ICCAD’17)为例，展示了一段带有函数调用的循环的代码以及对应的控制流图，说明如何通过将结构化分析将逻辑转化为可量化的模型</p><p><strong>从代码分析出发，通过建立精确的循环流水线、循环展开、数据流 II 和内存资源等模型，能够高精度地预测硬件行为的性能与资源消耗</strong><br><img src="/assets/844beaa355d27eb2d1e34ec320887ffc.jpg" alt="alt text"></p><h3 id="核心延迟建模的方法"><a href="#核心延迟建模的方法" class="headerlink" title="核心延迟建模的方法"></a>核心延迟建模的方法</h3><p>性能建模的关键在于确预测程序（尤其是循环结构）的执行延迟。图中重点阐述了两种主流的延迟模型</p><ol><li>循环流水线延迟模型（Loop Pipelining Latency Model）: 该模型通过公式计算循环在流水线执行的总周期数，综合考虑了单次迭代的延迟（D_i）、迭代间隔 (II_i)、循环带宽 (B_i)和实际利用率 (U_i) 等因素。反映了在现代硬件（如 FPGA、ASIC）中，循环并非简单串行执行，而是通过流水线重叠不同迭代来提升性能<br>$$<br>Cycle_{L_k}&#x3D;D_i+II_i\cdot (\frac{B_i}{U_i}\cdot B_{i-1}B_{i-2}\cdot\cdot\cdot B_k-1)<br>$$</li><li>循环展开延迟模型（Loop Unrolling Latency Model）: 当采用循环展开优化时，延迟计算变得更为复杂。该模型通过递推公式，将外层循环与内层展开后的循环延迟结合起来计算，考虑了不同层级的带宽利用和展开因子 (U_k)，用于评估展开策略对整体延迟的影响<br>$$<br>C_{L_k}^{U_k}&#x3D;C_{L_k+1}^{U_{k+1}}\cdot \frac{B_{k+1}}{U_{k+1}}\cdot U_k+C_{L_k/ L_{k+1}}^{U_k}<br>$$</li></ol><h3 id="迭代间隔与资源约束建模"><a href="#迭代间隔与资源约束建模" class="headerlink" title="迭代间隔与资源约束建模"></a>迭代间隔与资源约束建模</h3><p>除了延迟、性能建模还需考虑资源限制对并行度的约束</p><ul><li>数据流 II 模型（Dataflow IOI Model）: 迭代间隔 (II)是流水线中启动连续两次迭代所需的最小周期数。该模型指出，整体 II 取决于所有子模块中最大的 II, 这通常是由最慢的资源或数据依赖决定的<br>$$<br>II&#x3D;II_{max}^{sub}&#x3D;max_{i}(II_i^{sub})<br>$$</li><li>内存资源模型 (Memory Resource Model)：该模型公式用于估算实现特定数据结构（如数组）所需的资源存储量。它考虑了数据位宽、存储深度、分区数量等多个维度，确保设计在满足性能目标的同时不超出可用的片上存储资源<br>$$<br>R_{bom}&#x3D;[\frac{\#bits}{width}]\cdot [\frac{\#element}{depth}]\cdot \#partition \cdot d<br>$$</li></ul><h3 id="优化技术：链接（Chaining）"><a href="#优化技术：链接（Chaining）" class="headerlink" title="优化技术：链接（Chaining）"></a>优化技术：链接（Chaining）</h3><p>图示对比了链接 (Chaining)与非链接 (No Chaining)的操作流程。链接允许将多个逻辑操作在同一个时钟周期内组合执行，从而减少总延迟。</p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p>最后，图片通过基准测试展示了该性能建模方法的<strong>准确性和实用性</strong>：</p><ul><li>在<strong>JPEG、Seidel、Rician</strong>等测试用例中，模型预测的延迟与实际硬件实现的误差非常小（<strong>1.54%、0.91%、1.12%</strong>），证明了其高精度。</li><li>在<strong>运行时间</strong>方面，对于 Polybench 测试集，模型生成仅需<strong>秒级</strong>；而对于更复杂的应用（如 JPEG、Seidel、Rician），也只需<strong>分钟级</strong>，体现了该方法在实际工程中的高效性。</li></ul><h2 id="GNN-性能预测"><a href="#GNN-性能预测" class="headerlink" title="GNN 性能预测"></a>GNN 性能预测</h2><p>用图神经网络 (GNN)破解传统高性能计算系统设计中的性能预测难题。其核心思想是将<strong>硬件设计转化为图结构</strong>，让 GNN 学习从设计特征到最终功耗、性能和面积 (PPA 的复杂映射关系，从而实现快速、准确的早期评估，对比传统方法与基于 GNN 的性能预测：</p><table><thead><tr><th>特性维度</th><th>传统 HLS 性能评估方法</th><th>基于 GNN 的性能预测方法</th></tr></thead><tbody><tr><td><strong>核心建模方式</strong></td><td>基于分析模型、规则或耗时仿真</td><td><strong>数据驱动</strong>，从历史设计数据中学习复杂模式</td></tr><tr><td><strong>输入表示</strong></td><td>代码、中间表示（IR）或网表</td><td><strong>控制数据流图（CDFG）</strong>，将操作和依赖关系转化为图结构</td></tr><tr><td><strong>关键预测维度</strong></td><td>通常较为单一或分离</td><td><strong>端到端的PPA联合预测</strong>（功耗、性能、面积）</td></tr><tr><td><strong>主要优势</strong></td><td>原理清晰，对已知模式有效</td><td>能捕获<strong>非线性关系</strong>和<strong>复杂 pragma 指令交互</strong>，预测速度快（毫秒级）</td></tr><tr><td><strong>核心挑战</strong></td><td>设计空间巨大导致探索不完备；工具早期估计不准确<a href="https://espace2.etsmtl.ca/id/eprint/30389/"></a></td><td><strong>数据需求大</strong>；模型可解释性如“黑盒”；<strong>泛化能力</strong>面临挑战</td></tr></tbody></table><h3 id="GNN-实现性能预测"><a href="#GNN-实现性能预测" class="headerlink" title="GNN 实现性能预测"></a>GNN 实现性能预测</h3><p>GNN 解决了传统方式难以处理的两个问题：设计空间的指数级复杂性和高级优化指令 (pragma)带来的非线性影响</p><p><img src="/assets/37445b3b491947d941f8b764d9264231.jpg" alt="alt text"></p><ol><li><p><strong>图构建</strong>：将设计转化为 CDFG<br> 如图所示，GNN 的输入不是原始代码，而是从 C&#x2F;C++代码经过中间表示 (IR)转换得到的控制数据流图。图中的节点表示运算符（如加法、乘法、访存），边则代表数据控制依赖关系。这种表示方法保留了程序的结构和并行性信息</p></li><li><p><strong>层次化建模</strong><br> 层次化图结构是实现复杂设计的关键。它通过<strong>内存（循环子图）和外层（模块间连接）的分层抽象</strong>，让 GNN 能够理解局部计算模式（如一个流水线循环），再整合全局互连和优化（如循环展开、数组分割）的影响，融合不同来源和抽象级别的设计特征</p></li><li><p><strong>消息传递与预测</strong><br> GNN 通过“消息传递”机制再图结构中迭代聚合邻域信息。在这个过程中，模型能学习到特定操作（比如一个乘法器）再特定上下文（如处于一个深度流水线中）下对资源和时序的真实影响，最终聚合全图信息，输出对延迟 (Latency)、查找表 (LUT）、触发器 (FF)、数字信号处理器（DSP）等关键指标的预测</p></li></ol><h2 id="DSE-算法比较"><a href="#DSE-算法比较" class="headerlink" title="DSE 算法比较"></a>DSE 算法比较</h2><table><thead><tr><th>特性维度</th><th><strong>迭代搜索 (启发式&#x2F;ML)</strong></th><th><strong>数学规划 (MILP&#x2F;NLP)</strong></th><th><strong>LLM 驱动的 DSE (新趋势)</strong></th></tr></thead><tbody><tr><td><strong>核心思想</strong></td><td>模拟自然或学习过程进行<strong>启发式探索</strong></td><td>将设计空间转化为<strong>数学优化问题</strong>并精确求解</td><td>利用大语言模型的<strong>常识与代码能力</strong>生成设计</td></tr><tr><td><strong>优化目标</strong></td><td>通用目标，大规模近似<strong>帕累托前沿</strong></td><td>特定领域，追求<strong>理论最优解</strong>或高质量可行解</td><td>将自然语言描述直接转化为<strong>优化设计点</strong></td></tr><tr><td><strong>关键优点</strong></td><td><strong>灵活性高</strong>，适用于黑盒模型；<strong>全局探索</strong>能力强</td><td><strong>最优性有保证</strong>，提供整体视角；可严格建模复杂约束</td><td><strong>样本效率极高</strong>（零样本&#x2F;少样本）；<strong>端到端</strong>自动化；<strong>交互直观</strong></td></tr><tr><td><strong>主要挑战</strong></td><td><strong>样本效率低</strong>；对超参数<strong>敏感</strong>；易陷局部最优</td><td><strong>建模复杂</strong>；<strong>求解耗时</strong>；问题规模扩大时<strong>复杂度爆炸</strong></td><td><strong>结果不可靠</strong>（幻觉、不一致）；缺乏<strong>理论保证</strong>；领域知识依赖强</td></tr><tr><td><strong>典型应用</strong></td><td>早期、大规模设计空间初筛；HLS PPA 预测模型优化</td><td>脉动阵列、Stencil 计算等<strong>规则结构化硬件</strong>的精细优化</td><td>快速原型设计；基于高层描述探索架构灵感；自动化设计脚本生成</td></tr></tbody></table><p>未来的 DSE 趋势并非只能采用一种方法，而是<strong>多种方法的融合</strong>：利用 LLM 快速生成高质量起点，通过数学规划在局部进行精细调优，再借助基于 ML 的迭代搜索在全局范围内验证鲁棒性，从而构建出更强大、更智能的下一代 EDA 工具链</p><h2 id="HLS-编译流程的演变"><a href="#HLS-编译流程的演变" class="headerlink" title="HLS 编译流程的演变"></a>HLS 编译流程的演变</h2><p>传统的 HLS 编译流程<br><img src="/assets/d83e000451fd10027d5e47c6aecf98d6.jpg" alt="alt text"><br>传统的 HLS 采用单一 IR (LLVM IR)，缺乏清晰的循环结构，不利于高级优化。而新的 MLIR 支持多级 IR，可以保留结构信息，允许不同级别进行优化<br><img src="/assets/3e69ddce2796e7017672870ee879ab79.jpg" alt="alt text"></p><table><thead><tr><th>特性维度</th><th><strong>LLVM IR (传统单级表示)</strong></th><th><strong>MLIR (现代多级表示)</strong></th></tr></thead><tbody><tr><td><strong>核心哲学</strong></td><td>“万能”的<strong>单一、稳定、底层</strong>的编译器IR</td><td><strong>可扩展、多层次</strong>的编译器基础设施框架</td></tr><tr><td><strong>抽象级别</strong></td><td>主要集中在低层，接近机器指令</td><td><strong>贯穿高级算法到低级硬件</strong>的多层抽象</td></tr><tr><td><strong>结构信息保留</strong></td><td><strong>丢失大量高级语义</strong>（如循环、数据流结构）</td><td><strong>原生保留并显式表达</strong>高级结构（循环、任务、数据流）</td></tr><tr><td><strong>优化方式</strong></td><td>主要在固定层级进行通用优化</td><td><strong>渐进式降低抽象级别</strong>，在每一级进行<strong>领域特定优化</strong></td></tr><tr><td><strong>领域适配性</strong></td><td>通用性强，但领域特定扩展困难</td><td><strong>通过“方言”机制，原生支持领域特定扩展</strong></td></tr></tbody></table><h3 id="通用编译到硬件设计的核心需求"><a href="#通用编译到硬件设计的核心需求" class="headerlink" title="通用编译到硬件设计的核心需求"></a>通用编译到硬件设计的核心需求</h3><p>传统 LLVM IR 在 CPU&#x2F;软件编译上非常成功，但在面对 HLS 时却显露出根本性局限：</p><ol><li><p><strong>语义鸿沟</strong>：LLVM IR在设计上<strong>剥离了高级语义</strong>（如循环的并行性、数组的分块方式、流水线约束等），而这些恰恰是HLS进行高质量硬件综合所必须的信息。这导致许多本可在高层进行的优化（如循环变换、内存层级映射）无法实施或效果不佳。</p></li><li><p><strong>优化僵化</strong>：其优化流程相对固定，难以灵活插入<strong>领域特定优化</strong>（如为 FPGA 定制循环流水线策略、为 AI 加速器定制数据流映射）。优化过早降低到低层，丧失了在高抽象级别探索不同实现策略的机会。</p></li></ol><h3 id="MLIR-的核心创新：方言与多层次-IR"><a href="#MLIR-的核心创新：方言与多层次-IR" class="headerlink" title="MLIR 的核心创新：方言与多层次 IR"></a>MLIR 的核心创新：方言与多层次 IR</h3><p>MLIR 通过两大核心设计解决了上述问题：</p><ul><li><p><strong>方言机制</strong>：这是MLIR的基石。不同抽象级别的操作（如高层的 <code>linalg.matmul</code> 表示矩阵乘法，中层的 <code>affine.for</code> 表示循环，低层的 <code>llvm.load</code> 表示访存）可以共存于同一模块中。这允许HLS工具定义自己的方言（如表示硬件流水线的 <code>pipeline</code> 操作或表示硬件资源的 <code>resource</code> 约束），<strong>将设计意图直接编码在IR中</strong>。</p></li><li><p><strong>渐进式 lowering</strong>：MLIR的编译流程不是一个“断崖式”的下降。如图所示，优化可以分层次、分阶段进行：</p><ul><li>在<strong>图形级</strong>，可进行算法级任务划分和粗粒度流水。</li><li>在<strong>内核级</strong>，可进行内存布局优化和内核融合。</li><li>在<strong>循环级</strong>，可进行展开、流水线、数据流变换。</li><li>在<strong>指令级</strong>，最终生成目标 RTL 或 IP 核。<strong>每一级的优化都在最适合的抽象层级上进行，且信息可向下一级传递</strong>。</li></ul></li></ul><p>MLIR 的实践项目</p><ul><li><strong>CIRCT项目</strong>：这是基于MLIR构建开源硬件编译工具链的核心项目。它提供了从高级语言（如Chisel、FIRRTL）到低级硬件描述（如Verilog）的一系列MLIR方言和转换通道，成为了连接算法与硬件的“编译器中间层”</li><li><strong>厂商工具革新</strong>：主流FPGA厂商（如Xilinx&#x2F;Xilinx Vitis）和EDA公司正在将MLIR集成到其下一代工具中。例如，通过定义专属方言，工具可以更智能地理解AI模型中的算子，并自动映射到最优的DSP阵列或存储架构上</li><li><strong>与 DSE 结合</strong>：结合上一张幻灯片提到的<strong>设计空间探索（DSE）</strong>，MLIR 因其结构化的 IR，使得自动化工具能更容易地分析和施加不同的优化策略（如尝试不同的循环展开因子或流水线启动间隔），并快速评估其效果，从而极大加速了优化决策过程</li></ul><h2 id="MLIR-带来的新机遇"><a href="#MLIR-带来的新机遇" class="headerlink" title="MLIR 带来的新机遇"></a>MLIR 带来的新机遇</h2><h3 id="算法-硬件解耦-Algorithm-Hardware-Decoupling"><a href="#算法-硬件解耦-Algorithm-Hardware-Decoupling" class="headerlink" title="算法-硬件解耦 (Algorithm-Hardware Decoupling)"></a>算法-硬件解耦 (Algorithm-Hardware Decoupling)</h3><p>传统 HLS 中，算法代码和硬件优化指令混在一起，MLIR 允许将算法和硬件优化分开，开发者只需专注于算法，硬件优化由编译器自动完成。<br><img src="/assets/67b237b749d86d64c766625554817517.jpg" alt="alt text"></p><ul><li>将算法描述和硬件特定指令分离</li><li>使用 DSL 描述算法，通过调度构造器指定硬件特性</li></ul><h3 id="异构-FPGA-的统一编译栈（Unified-Compilation-Stack）"><a href="#异构-FPGA-的统一编译栈（Unified-Compilation-Stack）" class="headerlink" title="异构 FPGA 的统一编译栈（Unified Compilation Stack）"></a>异构 FPGA 的统一编译栈（Unified Compilation Stack）</h3><p>现代 FPGA 包含多种计算单元（CPU、PL、AIE），传统 HLS 需要为每种设备单独优化，但是 MLIR 提供统一的编译接口，可以自动适配不同的计算单元。<br><img src="/assets/3b000a84be3025391d449452c170cef8.jpg" alt="alt text"></p><ul><li>将 CPU、PL、AIE 等不同计算单元统一编译</li></ul><h3 id="动态调度与静态调度比较"><a href="#动态调度与静态调度比较" class="headerlink" title="动态调度与静态调度比较"></a>动态调度与静态调度比较</h3><p><img src="/assets/2f7bcd65e9f7ce6e860b11fbbe76ee89.jpg" alt="alt text"><br>调度是 HLS 优化的关键环节——决定任务如何在硬件上执行。该图比较了两种调度方式：</p><ul><li><strong>静态调度</strong>：就像固定时间表，无论任务如何变化，都按固定顺序执行。传统 HLS 使用静态调度，虽然简单，但无法充分利用硬件并行性。</li><li><strong>动态调度</strong>：Dynamatic 项目使用动态调度，能根据程序运行时的特性自适应调整，提取更多并行性，尤其适合处理”不规则循环”（如条件判断导致的执行路径变化）</li></ul><p>数据显示，Dynamatic 可以将延迟减少3.5倍，但会增加2.11倍的资源消耗。对于某些应用，这种权衡是值得的，因为延迟减少带来的性能提升远超过资源增加。</p><h3 id="动态调度方法实例"><a href="#动态调度方法实例" class="headerlink" title="动态调度方法实例"></a>动态调度方法实例</h3><p>HLS 正从<strong>静态、确定性的编译时调度</strong>，转向<strong>动态、弹性、运行时管理的硬件生成</strong>。本质上是将现代 CPU 中<strong>乱序执行</strong>的智能与灵活性引入到定制硬件中，以应对日益复杂的计算需求。<br><img src="/assets/398b6e08af25ca2de3600f7262706a54.jpg" alt="alt text"></p><table><thead><tr><th>特性维度</th><th><strong>传统静态调度 HLS (如 Vitis HLS)</strong></th><th><strong>动态调度 HLS (弹性数据流架构)</strong></th></tr></thead><tbody><tr><td><strong>调度决策时机</strong></td><td><strong>编译时</strong>完全确定</td><td><strong>运行时</strong>动态决定</td></tr><tr><td><strong>电路特性</strong></td><td><strong>刚性、同步</strong>的时序电路</td><td><strong>弹性、延迟不敏感</strong>的握手协议电路</td></tr><tr><td><strong>并行性挖掘</strong></td><td>依赖编译分析，限于<strong>规则、可预测</strong>的模式</td><td>可挖掘<strong>不规则、数据依赖</strong>的潜在并行</td></tr><tr><td><strong>内存依赖处理</strong></td><td>需静态分析，对不确定访问保守</td><td>可动态解析，支持<strong>非确定性</strong>内存访问</td></tr><tr><td><strong>核心优势</strong></td><td>硬件开销小，时序可控，工具链成熟</td><td>性能潜力高，对复杂控制流&#x2F;变量延迟适应性强</td></tr><tr><td><strong>主要代价</strong></td><td>对不规则算法性能受限</td><td><strong>面积开销大</strong>（增加控制逻辑），时序更难优化</td></tr></tbody></table><h4 id="刚性流水线到弹性数据流"><a href="#刚性流水线到弹性数据流" class="headerlink" title="刚性流水线到弹性数据流"></a>刚性流水线到弹性数据流</h4><p>传统 HLS 将 C 代码综合成类似同步数据流的硬件：每个操作在固定的时钟周期发生。这要求所有循环边界、内存延迟和分支路径都必须在编译时确定，极大限制了不规则算法（如图处理、稀疏计算）的优化能力</p><p>动态调度 HLS (也是弹性数据流 HLS)则采用不用范式：</p><ul><li><strong>延迟不敏感设计</strong>：模块间通过握手协议通信，而非全局时钟同步。一个模块只有在数据到达且下游就绪时才会执行。这自然消除了对固定组合逻辑延迟的担忧，使电路对工艺变化、电压频率缩放更鲁棒性</li><li><strong>动态调度</strong>：图中展示的 Merge、Branch、Select 等组件时关键。例如：Merge 单元动态选择最先到达的数据流；Branch 单元根据运行时条件将数据分发到不同路径。实现数据驱动执行</li></ul><h4 id="核心组件"><a href="#核心组件" class="headerlink" title="核心组件"></a>核心组件</h4><ol><li><strong>控制组件</strong>：<ul><li><strong>Merge</strong>：动态仲裁多个输入通道，将数据汇入单一流。</li><li><strong>Branch</strong>：根据条件将数据流分发至不同路径。</li><li><strong>Select</strong>：从多个数据源中选择一个输出。</li></ul></li><li><strong>存储与同步组件</strong>：<ul><li><strong>Buffer&#x2F;FIFO</strong>：解耦生产者与消费者，是构建弹性流水线的核心，允许前后级以不同速率执行。</li><li><strong>Fork&#x2F;Join</strong>：复制数据流并同步多条路径。</li></ul></li><li><strong>计算组件</strong>：<ul><li><strong>Func(…)</strong>：封装实际计算功能（如加法器、乘法器）的单元，其前后均有握手接口。<br>![alt text](&#x2F;assets&#x2F;Pasted image 20251209154935.png)<br>右侧的示例流程清晰展示了动态性：<code>read A[i]</code> 和 <code>read B[i]</code> 两个操作可以<strong>异步、并行地</strong>访问内存，谁先完成谁就先行进入加法器。加法完成后，结果被动态送入分支单元进行判断，后续路径的选择完全由运行时数据决定。</li></ul></li></ol><h2 id="HLS-优化"><a href="#HLS-优化" class="headerlink" title="HLS 优化"></a>HLS 优化</h2><p>现在的 HLS 设计流程<br><img src="/assets/c6a6ac8d02d1eaeb6d21ca3903efc9a5.jpg" alt="alt text"></p><h3 id="基于模板的设计流程"><a href="#基于模板的设计流程" class="headerlink" title="基于模板的设计流程"></a>基于模板的设计流程</h3><p><img src="/assets/3e987c0f974a402d723df7474c588089.jpg" alt="alt text"><br>现在芯片设计逐渐从<strong>手写静态的、固定的 RTL 代码</strong>，转向<strong>编写能够动态生成定制化硬件的“生成器”程序</strong>。其核心在于，通过<strong>元编程（Meta-Programming）</strong> 将硬件设计提升到一个更高、更参数化的抽象层次，以应对复杂片上系统（SoC）的敏捷开发需求。</p><table><thead><tr><th>特性维度</th><th><strong>传统 RTL 设计流程</strong></th><th><strong>基于模板&#x2F;生成器的设计流程</strong></th></tr></thead><tbody><tr><td><strong>设计载体</strong></td><td>手写&#x2F;编辑<strong>静态的Verilog&#x2F;VHDL文件</strong></td><td>编写<strong>高级语言（如Scala&#x2F;Chisel）的生成器代码</strong></td></tr><tr><td><strong>核心产出</strong></td><td>针对单一配置的、固定的<strong>网表&#x2F;RTL</strong></td><td>一个可根据参数<strong>实例化无数种设计</strong>的<strong>生成器程序</strong></td></tr><tr><td><strong>复用与定制</strong></td><td>通过复制粘贴、手动修改模块实现，易出错</td><td>通过<strong>参数化、继承、组合</strong>在架构层面实现类型安全的复用</td></tr><tr><td><strong>设计探索</strong></td><td>修改配置需重新编写代码，迭代慢</td><td>调整参数重新生成，<strong>快速进行设计空间探索</strong></td></tr><tr><td><strong>验证重点</strong></td><td>验证特定实现的正确性</td><td>验证<strong>生成器逻辑</strong>的正确性，确保其所有合法输出均正确</td></tr><tr><td><strong>核心优势</strong></td><td>直观，对最终电路有完全控制，工具链成熟</td><td><strong>生产力爆炸性提升</strong>，架构一致性极强，利于IP复用与系统集成</td></tr><tr><td><strong>主要挑战</strong></td><td>难以管理大规模复杂性，设计空间探索成本高</td><td><strong>调试抽象鸿沟</strong>，生成代码的可读性，以及<strong>结构刚性</strong></td></tr></tbody></table><h4 id="元编程与生成器引擎"><a href="#元编程与生成器引擎" class="headerlink" title="元编程与生成器引擎"></a>元编程与生成器引擎</h4><p>以 Chisel 为例简述“<strong>元编程 → 细化 → RTL 实例</strong>”流程</p><ol><li><strong>元编程</strong>：设计师使用 Scala 等高级语言，编写的是<strong>描述硬件结构和行为的代码</strong>，而非最终的硬件描述本身。这些代码是<strong>参数化</strong>的，可以是一个处理器核的配置（如寄存器位数、缓存大小），也可以是一个互联网络的拓扑结构。</li><li><strong>细化</strong>：当给定一组具体参数后，<strong>生成器引擎</strong>（如 Chisel 编译器）会执行这些 Scala 代码。执行过程并非计算数值，而是<strong>构建一个内部的硬件组件对象图</strong>，即“逻辑图”或“RTL 模板”。这个过程是类型安全的，并允许复杂的编译时逻辑。</li><li><strong>RTL 实例</strong>：最终，这个内部对象图被<strong>翻译</strong>成标准的 Verilog RTL 代码。这就是“零 RTL 开销”的含义：设计师<strong>从不直接编写或维护最终的 Verilog</strong>，所有 Verilog 都是无错的、由工具从高级描述生成的。</li></ol><h4 id="优势与局限"><a href="#优势与局限" class="headerlink" title="优势与局限"></a>优势与局限</h4><p><strong>生成器封装了领域专家的最优设计知识</strong></p><ul><li>例如，一个矩阵乘法脉动阵列的生成器，内部已经固化了对数据流、内存层级和计算阵列的最优组织方式。用户通过调整阵列尺寸、数据位宽等参数，即可在<strong>保证架构最优的前提下</strong>，获得一个针对新需求的高性能实例。</li></ul><p><strong>调试复杂与结构刚性</strong></p><ul><li>当生成的 Verilog 出现问题时，设计师需要逆向追溯回生成它的 Scala 代码逻辑。这要求调试者同时理解硬件行为和复杂的软件生成逻辑。</li><li>生成器通常预设了<strong>固定的微架构模板</strong>。例如，一个缓存生成器可能允许你设置大小和相联度，但很难将其底层结构从组相联改为全相联。这要求生成器在<strong>灵活性与复杂性</strong>之间做出权衡，过度追求灵活性会使生成器代码本身变得难以维护。</li></ul><h4 id="典型案例：Rocket-Chip-系统"><a href="#典型案例：Rocket-Chip-系统" class="headerlink" title="典型案例：Rocket Chip 系统"></a>典型案例：Rocket Chip 系统</h4><p>整个复杂 SoC（包含 Rocket CPU 核、TileLink 总线、L2缓存、外设等）<strong>不是一个固定设计</strong>，而是一个由 Chisel 编写的、高度模块化的<strong>生成器框架</strong></p><ul><li><strong>可组合性</strong>：<code>RocketTile</code>、<code>SystemBus</code>、<code>PeripheryBus</code> 等都是可配置、可替换的组件。用户可以通过混合匹配，快速生成从嵌入式微控制器到多核应用处理器的不同变体。</li><li><strong>一致性接口</strong>：所有模块通过标准化的TileLink总线协议互联，这由生成器在架构层面保证，确保了系统集成的正确性。</li><li><strong>Chipyard 项目</strong>：正是构建在此基础上的完整<strong>SoC 设计、仿真与流片平台</strong>。</li></ul><h3 id="混合设计流程-Hybird-Design-Flow"><a href="#混合设计流程-Hybird-Design-Flow" class="headerlink" title="混合设计流程 (Hybird Design Flow)"></a>混合设计流程 (Hybird Design Flow)</h3><p>现代异构计算系统（特别是 CPU+FPGA）设计复杂性的一个系统级解决方案。它并非是单一工具，而是一个集成框架，核心目标是将软件开发的敏捷性与硬件优化的极致性能相结合，实现从算法到可部署加速系统的全栈加速。</p><p>![alt text](&#x2F;assets&#x2F;Pasted image 20251209172650.png)<br>该流程将软件与硬件设计分开设计，并通过标准化接口进行协作</p><ul><li>将高层次算法、控制流、数据准备与任务调度交给主机端 (CPU)，使用 C&#x2F;C++等高级语言开发，利用 CPU 的通用性和丰富的软件生态</li><li>将计算密集型、可并行的核心计算内核交给 FPGA 端，通过 HLS 或 RTL 生成实现极致加速，发挥 FPGA 的并行能力和能效优势</li><li>通过 OpenCL 异构编程框架和 Xilinx 运行时（XRT）作为接口，自动处理主机与 FPGA 之间的内存分配、数据迁移、内核启动与同步等复杂且易错的底层细节</li></ul><p>GraFlex——一种基于 FPGA 的灵活散集式（scatter-gather）图处理框架，配备可扩展的互连网络。</p><ul><li>GraFlex 采用整体同步并行（Bulk-Synchronous Parallel, BSP）模型进行全局控制与同步，通过基于高层次综合（HLS）的设计流程，实现高性能图处理系统的快速部署。</li><li>GraFlex 通过软硬件协同优化提升系统性能：它配置了紧凑的<strong>图数据格式、图划分策略以及内存通道分配机制</strong>，以支持可扩展设计</li><li>同时，采用资源高效的多级蝶形互连网络，实现片上数据通信并促进吞吐量匹配</li><li>为应对碎片化的内存访问请求，提出了合并式内存访问引擎，以提高带宽利用率</li><li>实验结果表明，与当前最先进的工作相比，GraFlex 在遍历吞吐量上平均提升高达 2.09 倍，同时显著降低了功耗和资源消耗。以广度优先搜索（BFS）为例的案例研究表明，借助所实现的散集机制及合理的实现选择，其平均算法吞吐量提升了6.58倍。</li></ul><h4 id="流程解析"><a href="#流程解析" class="headerlink" title="流程解析"></a>流程解析</h4><p><img src="/assets/deepseek_mermaid_20251209_56e607.svg" alt="alt text"></p><ol><li><strong>设计入口</strong>：对应不同的设计风格和优化目标可采用<ul><li><strong>基于 Chisel 的元编程</strong>：用于生成高度定制化、架构复杂的<strong>控制与数据路径</strong>（如图中的 Scatter&#x2F;Gather PE）。它适合构建底层基础设施和需要精细控制微架构的模块。</li><li><strong>基于 C&#x2F;C++的 HLS</strong>：用于快速将算法循环或函数转换为硬件加速器。它适合算法工程师快速进行原型验证和性能探索。</li></ul></li><li><strong>自动化内核封装与系统集成</strong>：生成的 RTL 内核会被自动封装成<strong>OpenCL 内核接口</strong>。这是关键一步，它为标准化的主机-设备交互提供了硬件抽象。随后，通过<strong>参数化实例化</strong>，该内核与来自<strong>基础设施 IP 库</strong>的必备组件（如总线接口 AXI、片上存储 BRAM&#x2F;URAM、DMA 控制器等）集成，形成一个完整的<strong>系统块设计</strong>。</li><li><strong>全栈编译与部署</strong>：主机端程序与 FPGA 比特流分别编译。最终，通过<strong>Xilinx 运行时（XRT）</strong> 和 Vitis 工具链实现自动集成，形成一个可部署的应用程序。主机程序通过 OpenCL API 调用 FPGA 加速内核，XRT 则透明地管理所有底层硬件操作。</li></ol><h3 id="LLM-驱动的设计流程"><a href="#LLM-驱动的设计流程" class="headerlink" title="LLM 驱动的设计流程"></a>LLM 驱动的设计流程</h3><p>传统设计流程中，工程师必须将自己对系统的构思，通过严格遵循语法的硬件描述语言（如 Verilog）或工具命令（如 TCL）进行设计。这要求极高的专业性和精准度，任何语法或语义错误都可能导致设计失败。<br>![alt text](&#x2F;assets&#x2F;5911b5aae9153219d3047929705b3484 1.jpg)<br>LLM 驱动的流程彻底改变了这一动态：</p><ul><li><strong>输入</strong>：设计师用自然语言描述功能、性能目标或架构想法（如“设计一个支持AXI4总线的32位RISC-V CPU核，主频目标500MHz”）。</li><li><strong>核心</strong>：LLM充当一位<strong>精通硬件设计、编程语言和工具链的“全能助理”</strong>，将模糊的意图转化为精确的可执行步骤。</li><li><strong>输出</strong>：它生成的不是单一代码，而是一个<strong>可工作的工具链输入集合</strong>（HDL、Testbench、约束文件、TCL 脚本），从而直接启动一个标准化的实现流程。</li></ul><h4 id="构建可靠的-LLM-驱动"><a href="#构建可靠的-LLM-驱动" class="headerlink" title="构建可靠的 LLM 驱动"></a>构建可靠的 LLM 驱动</h4><p><img src="/assets/be9c7d94b5f30b3ca4008f86975f1f65.jpg" alt="alt text"></p><ul><li><strong>检索增强生成（RAG）</strong> 来解决 LLM“幻觉”和知识过时问题。它会从<strong>公司内部的设计库、IP 数据手册、最佳实践文档和过往错误案例库</strong>中实时检索相关信息，并作为上下文提供给 LLM。这确保了生成的代码符合内部规范、正确调用现有 IP，并规避已知陷阱。</li><li><strong>反馈机制</strong>。当生成的代码经过综合、布局布线或仿真后，<strong>时序违规报告、功能覆盖率数据、功耗分析结果</strong>等都会被结构化地反馈给 LLM。LLM 可以据此自动分析问题根源（例如：“关键路径在某个多周期乘法器中，建议插入流水线寄存器”），并生成修正后的代码。这形成了一个<strong>自动化的调试迭代环</strong>，极大地压缩了手动调试的时间。</li><li>设计专用领域模型<ul><li><strong>微调</strong> 使用高质量的硬件设计代码和对话数据对基础 LLM 进行训练，使其深刻理解硬件设计模式、资源-时序权衡和 EDA 工具语义。</li><li><strong>多智能体</strong> 系统可以扮演不同角色：一个“架构师”负责顶层模块划分，一个“验证工程师”负责编写测试用例，一个“后端专家”负责生成物理约束。它们相互协作与校验，共同完成复杂任务。</li><li><strong>符号解释</strong> 则是对生成代码进行形式化分析，在仿真前就从数学逻辑上保证某些属性的正确性，提升初始代码质量。</li></ul></li></ul><h4 id="实验结果-1"><a href="#实验结果-1" class="headerlink" title="实验结果"></a>实验结果</h4><p><img src="/assets/7cb31e38babf55b723827d4141b54975.jpg" alt="alt text"><br>该图展示了 LLM 在 HDL（硬件描述语言）生成中的最新进展。VerilogEval 数据集是评估 LLM 生成 HDL 代码质量的基准，包含156个案例。</p><ul><li>GPT-4o：能正确生成60.1%的HDL代码（人类评估），67.7%的代码（机器评估）</li><li>Claude 3.7 Sonnet：75.4%和85.3%</li><li>MAGE（专为HDL设计的LLM）：94.8%和95.7%</li><li>HAVEN：61.1%和77.3%<br>这些数据表明，经过专门训练的 LLM（如 MAGE）能生成高质量的 HDL 代码，准确率接近96%。这意味着，未来开发人员可能只需要用自然语言描述硬件需求，LLM 就能自动生成符合要求的 HDL 代码，就像用自然语言写软件一样简单。</li></ul><h2 id="未来方向"><a href="#未来方向" class="headerlink" title="未来方向"></a>未来方向</h2><p>如何融合编译器的可靠性、模板设计的性能以及 LLM 的灵活性-&gt;如何充分利用所有优势<br><img src="/assets/6ffde9f602f996cbe21a1d0d6f16ea02.jpg" alt="alt text"></p><h3 id="端到端的自主设计平台"><a href="#端到端的自主设计平台" class="headerlink" title="端到端的自主设计平台"></a>端到端的自主设计平台</h3><p>SODA Synthesizer 是一个<strong>开源、模块化、端到端</strong>的硬件编译器框架，旨在自动化地从高级框架描述生成优化的硬件设计。<br><img src="/assets/Pastedimage20251209170921.png" alt="alt text"></p><h4 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a>系统架构</h4><p>SODA 采用两级编译架构，强调模块化与可扩展性</p><p><strong>在前端设计了 SODA-OPT：</strong></p><ul><li>基于 MLIR 构建，自动分析 MLIR 代码，识别适合硬件加速的代码区域（内核）并将其提取。</li><li>利用 MLIR 方言（如 linalg, affine）的语义信息，进行架构无关的循环变换等高级优化，而<strong>无需手动代码标注</strong>。</li><li>通过自定义的 <code>soda</code> 方言，自动将应用划分为<strong>主机程序</strong>（负责协调）和<strong>硬件加速器内核</strong>。<br>生成两类 LLVM IR——优化后的内核 IR（供后端 HLS 使用）和主机代码 IR（供 CPU 编译执行）</li></ul><p><strong>在后端采用 PandA-Bambu 开源的 HLS 工具</strong></p><ul><li>接收前端生成的 LLVM IR，执行低位宽分析、调度、绑定等标准 HLS 步骤，生成 Verilog&#x2F;VHDL RTL 代码及测试平台。</li></ul><p>前后端协同，支持通过不同的编译 pass 序列和参数进行自动化设计空间探索。SODA Synthesizer 通过其创新的<strong>MLIR-based 前端</strong>与强大的<strong>开源 HLS 后端</strong>相结合，提供了一个切实可行的端到端解决方案</p><h2 id="跨层"><a href="#跨层" class="headerlink" title="跨层"></a>跨层</h2><h3 id="背景与问题"><a href="#背景与问题" class="headerlink" title="背景与问题"></a>背景与问题</h3><ul><li><strong>多芯片FPGA的挑战：</strong> 为了容纳大规模加速器，多芯片（由多个SLR组成）FPGA被广泛使用。然而，跨越芯片边界的连线（SLL）会带来显著的延迟（约1ns），导致时序问题。</li><li><strong>现有方法的局限：</strong>   <ul><li>传统的HLS指令优化通常只关注单一芯片的资源约束，忽略了多芯片间的跨芯片延迟和特定区域的资源限制。</li><li>全局布局规划（Floorplanning）算法（如基于 ILP 的方法）虽然能解决布局问题，但计算复杂度高，运行时间极长，难以与迭代式的指令搜索过程高效结合。</li></ul></li></ul><h3 id="FADO-框架"><a href="#FADO-框架" class="headerlink" title="FADO 框架"></a>FADO 框架</h3><p>作者提出了一种<strong>指令与布局规划协同优化（Co-optimization）的方法</strong>，将该问题建模为多维装箱问题（Bin-packing variants）。FADO 包含两个版本的迭代优化流程：</p><h4 id="FADO-1-0：基于综合（Synthesis-based）的流"><a href="#FADO-1-0：基于综合（Synthesis-based）的流" class="headerlink" title="FADO 1.0：基于综合（Synthesis-based）的流"></a>FADO 1.0：基于综合（Synthesis-based）的流</h4><ul><li><strong>方法：</strong><ul><li><strong>QoR 库：</strong> 预先运行HLS工具生成函数级别的质量结果（QoR）库（包含延迟和资源消耗）。</li><li><strong>贪婪搜索：</strong> 基于延迟瓶颈（Latency bottleneck）引导的指令搜索。</li><li><strong>增量式布局合法化：</strong> 替代全局布局算法。使用在线“最差适应”（Worst-Fit）算法平衡资源，以及离线“最佳适应递减”（Best-Fit Decreasing）算法重排布局。</li><li><strong>流水线插入：</strong> 在跨芯片边界的长连线上增量添加流水线寄存器。</li></ul></li><li><strong>缺点：</strong> 构建 QoR 库需要极长的预处理时间（数小时）</li></ul><h4 id="FADO-2-0：基于解析模型（Analytical-Model）的流程（本文扩展重点）"><a href="#FADO-2-0：基于解析模型（Analytical-Model）的流程（本文扩展重点）" class="headerlink" title="FADO 2.0：基于解析模型（Analytical Model）的流程（本文扩展重点）"></a>FADO 2.0：基于解析模型（Analytical Model）的流程（本文扩展重点）</h4><ul><li><strong>改进点：</strong> 旨在消除耗时的QoR库生成过程，并探索更广阔的设计空间。</li><li><strong>解析 QoR 模型：</strong> 基于COMBA模型开发并校准，支持任意数据类型和位宽。它能快速估算给定指令配置下的延迟和资源，无需运行HLS综合。</li><li><strong>智能搜索策略：</strong> 重新设计了指令搜索算法，通过分析循环层级结构（单循环与多循环搜索），不仅收敛速度更快，还能平衡 BRAM、URAM 和 LUTRAM 的使用，从而提升频率</li></ul><h3 id="关键技术细节"><a href="#关键技术细节" class="headerlink" title="关键技术细节"></a>关键技术细节</h3><ul><li><strong>问题建模：</strong> 将问题公式化为最小化总延迟，同时满足每个 SLR 的资源约束、跨芯片连接约束（SLL 数量）以及特定模块（如通过 RAM 连接的模块）的分组约束。</li><li><strong>增量布局规划（Incremental Floorplanning）：</strong> 这是FADO的核心。当指令改变导致模块资源变化时，FADO不进行全局重排，而是通过在线和离线算法微调模块位置，极大地减少了搜索时间。</li><li><strong>Look-ahead&#x2F;Look-back 机制：</strong> 为了应对非单调的设计空间（即资源增加不一定带来延迟减少），FADO 1.0 引入了向前&#x2F;向后搜索采样策略；FADO 2.0 则通过改进的搜索顺序自然地解决了这一问题。</li></ul><h3 id="实验结果-2"><a href="#实验结果-2" class="headerlink" title="实验结果"></a>实验结果</h3><p>在 AMD Alveo U250 FPGA 上，使用混合了数据流（Dataflow）和非数据流内核的大规模基准测试进行了评估：</p><ul><li><strong>与全局布局规划相比：</strong><ul><li><strong>速度：</strong> FADO 1.0 的搜索时间缩短了 <strong>693倍到4925倍</strong>。</li><li><strong>性能：</strong> 设计性能（以执行时间衡量）提升了 <strong>1.16倍到8.78倍</strong>。</li></ul></li><li><strong>FADO 2.0 vs. FADO 1.0：</strong><ul><li>FADO 2.0 通过解析模型消除了预处理时间。</li><li>得益于更广阔的搜索空间和存储资源平衡策略，FADO 2.0 优化后的设计性能比 FADO 1.0 平均进一步提升了 <strong>1.40倍</strong>（排除一个极端特例）。</li><li>FADO 2.0 相比基于解析模型的全局布局规划基线，性能平均提升了 <strong>2.66倍</strong>。</li></ul></li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>*PPT 及其图示来自 FPT 2025 讲座——简化 FPGA 开发：敏捷设计流程带来的挑战和机遇（张薇教授）</p>]]></content>
      
      
      
        <tags>
            
            <tag> Lecture </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>(FPT2025)超摩尔与深度学习时代的的空间架构——Vaughn Betz 教授(多伦多大学&amp; Cerebras Systems)</title>
      <link href="/2025/12/10/FPT2025-vaughn_betz/"/>
      <url>/2025/12/10/FPT2025-vaughn_betz/</url>
      
        <content type="html"><![CDATA[<h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p>以电动汽车 Chevy Bolt (6 kw) 与 Nvidia Drive AGX Pegasus (750 W) 为例，说明在自动驾驶等安全关键场景中，低推理延迟至关重要。</p><ul><li>评价指标“性能&#x2F;功耗&#x2F;成本”，其中功耗约占总成本的 30%</li></ul><p>FPGA 具有的可定制化与操作数精简的特点，通过重构实现网络所需的精确硬件，无需指令流，直接进行必要计算。其可编程路由与逻辑允许数据直连，并支持最小位宽操作，从而大幅降低能耗。</p><h3 id="空间计算在数据局部性方面的优势"><a href="#空间计算在数据局部性方面的优势" class="headerlink" title="空间计算在数据局部性方面的优势"></a>空间计算在数据局部性方面的优势</h3><p>下图展示从片外 HBM2 到 SRAM (416kB、60kB、16kB 锁存阵列)数据流动，体现了不同存储层级的带宽与能耗差异。<br><img src="/assets/a06bc1934279351c450ef82dd070a057.jpg" alt="alt text"></p><p><strong>FPGA 在空间计算的优势：</strong></p><ul><li>可通过可编程逻辑与路由灵活存储，将数据贴近计算单元，显著减少数据搬运能耗。但是随着网络规模增大，依赖片外存储会削弱这一优势。</li><li>具备极高片上带宽 (~Pb&#x2F;s，可划分为上万个独立存储块，支持按需定制存储大小与位置，并能与逻辑结合实现稀疏计算等优化。但超大规模网络仍需片外存储。</li><li>支持可编程串行 I&#x2F;O（如 PCIe）、存储接口 （如 DDR）以及嵌入式低延迟定制 I&#x2F;O，使其能够集成预处理、特征提取与深度学习推理，形成完整低延迟系统。</li></ul><p>但可编程逻辑单元与路由比专用电路面积更大、速度更慢。因此，提出研究方向：是否可通过硬化关键功能（如 DSP 块）或改进软硬件结构，提升 FPGA 在深度学习中的效率</p><h2 id="设计前端"><a href="#设计前端" class="headerlink" title="设计前端"></a>设计前端</h2><h3 id="HPIPE"><a href="#HPIPE" class="headerlink" title="HPIPE"></a>HPIPE</h3><p>HPIPE 数据流架构，其专为高效 CNN 推理设计，体现了如何通过空间映射提升计算效率。传统时序映射使用通过处理单元逐层处理 (PE)，效率较低,如下图所示。<br><img src="/assets/ca94b4923aef556ac513dc26016d894a.jpeg" alt="alt text"><br>HPIPE 则为每层定制硬件单元，层间通过延迟不敏感接口连接，充分利用流水线并行提升效率与吞吐量<br><img src="/assets/940a6ee3090e3fe82fe13438fc9e2b77.jpeg" alt="alt text"><br>下图可以看出专用硬件与本地数据移动的优势；无指令译码开销、数据局部性高、但需为不同网络设计不同硬件，因此需要领域专用编译器的支持。<br>图来自，M.Hall et al,“From TensorFlow Graphs to LUTs and Wires: Automated Sparse and Physically Aware CNN Hardware Generation”, FPT 2020.<br><img src="/assets/76da1ec3ede79e96ac583dfc2469f439.jpeg" alt="alt text"><br>该图展示了 HPIPE 自动生成 CNN 硬件的流程：从 TensorFlow 模型出发，经过图优化、资源分配、RTL 生成、布局感知流水线与存储映射，最终生成 FPGA bitstream。该方法通过层融合、流水线平衡与本地化通信优化，提升整体效率。<br><img src="/assets/1bd108410e31017fa913422afbe490b5.png" alt="alt text"><br>HPIPE 通过将超大规模 CNN 的权重选择性卸载的策略，将部分权重移至片外 HBM, 释放片上存储，使更大网络能在单 FPGA 上运行。虽然会损失一定性能，但仍优于先前方案，体现了成本与性能的权衡。</p><h3 id="Overlay-NPU"><a href="#Overlay-NPU" class="headerlink" title="Overlay NPU"></a>Overlay NPU</h3><p>传统流程需要应用专家编写 RTL, 设计时间周期长；而 Overlay 方案则由硬件专家定义 ISA 与工具链，应用专家通过软件编程快速部署，实现“软件可编程的推理加速”。<br><img src="/assets/2b5711212aaba907aa605478f68ecaff.jpeg" alt="alt text"></p><p>NPU 主要针对多层感知机 (MLPs)、循环神经网络 (RNNs)、门控循环单元 (GRUs)、长短期记忆网络 (LSTMs)和图神经网络 (GNNs)等神经网络模型</p><p><strong>NPU 架构特点</strong>：</p><ul><li>超长指令字 (VLIW)软处理器：采用 5 个粗粒度阶段的 VLIW 架构，单条指令可执行 45000 次操作</li><li>Amortize control：优化指令执行效率</li><li>定制内存子系统：利用片上内存带宽、提升数据处理速度</li><li>数据级联：数据从一个阶段级联到下一个阶段，实现空间局部性优化</li></ul><p><strong>NPU 的组成结构</strong>:</p><ul><li>包括多个功能单元 (MVU、eVRF、MFU 0、MFU 1) 及其连接方式</li><li>指令解码与分发单元：负责指令的解码和分发，确保各功能单元协同工作</li></ul><p><strong>NPU的开发流程</strong>:</p><ul><li>使用领域特定语言 DSL 编写 NPU 程序</li><li>将 DSL 编写的程序编译为可在 NPU 上运行的代码</li><li>通过性能仿真工具评估 NPU 程序的执行效果</li></ul><p>图片引用了A. Boutros等人在FPT 2020会议上发表的研究《Beyond Peak Performance: Comparing the Real Performance of AI-Optimized FPGAs and GPUs》，该研究比较了AI优化的FPGA和GPU的实际性能。</p><p><img src="/assets/974fae770557e1415973d000aa1d4652.jpeg" alt="alt text"></p><h3 id="支持算术的逻辑结构优化"><a href="#支持算术的逻辑结构优化" class="headerlink" title="支持算术的逻辑结构优化"></a>支持算术的逻辑结构优化</h3><p><img src="/assets/7e124e5f5d22e45200cc471efd4e3b0e.jpeg" alt="alt text"></p><ul><li>通过改进 LUT 与加法器结构，可在面积增加不足 4%的情况下，提升 MAC 密度 25%~50%</li></ul><p><img src="/assets/74203a333b6903d830b995f200592b34.jpeg" alt="alt text"><br>虽然可编程逻辑相比 ASIC 在面积上与速度上存在劣势，但针对常用计算模式（如 FIR 滤波器）硬化 DSP 块，仍能在面积与速度间取得较好平衡，需要综合考虑路由与使用范围。</p><h3 id="Inter-Stratix-10-NX-张量块的设计演变"><a href="#Inter-Stratix-10-NX-张量块的设计演变" class="headerlink" title="Inter Stratix 10 NX 张量块的设计演变"></a>Inter Stratix 10 NX 张量块的设计演变</h3><p>传统 DSP 块支持 2 个 int 18 乘法器，而张量块则集成 30 个 int 8 乘法器，通过组织为 3 个 dot-10 引擎、输入广播与乒乓复用链，在相近面积内实现 15 倍 int 8 算力提升，适用于密集型低精度矩阵计算</p><p><strong>输入输出配置：</strong><br><img src="/assets/55eebdba43af2b2f28c5a54ac1052e1b.png" alt="alt text"></p><ul><li>480 输入&#x2F;480 输出：初始配置下，Tensor Block int 8 支持 480 输入和 480 个输出<br><img src="/assets/cffee54af1a0c37ad1dc8123a419e50d.png" alt="alt text"></li><li>480 输入&#x2F;72 输出：通过限制输出，将乘法器排列为 3 个 dot-10 引擎累加器，实现 480 输入和 72 输出<br><img src="/assets/0600dc5d2113650d97ecc470a3ae6256.png" alt="alt text"></li><li>320 输入&#x2F;72 输出：进一步限制输入，通过广播一组到所有 dot-10 引擎，实现 320 个输入和 72 输出<br><img src="/assets/79149dc5f3e8b0d3bd2b8f7535016557.png" alt="alt text"></li><li>80 输入&#x2F;72 输出：最终配置下，通过乒乓重用链从上一个块加载数据，实现 80 个输入和 72 个输出。</li></ul><p>在于 DSP 块相似的面积内。Tensor Block int 8 能够实现 15 倍峰值的 int 8 TOPS（每秒万亿次操作）</p><h2 id="设计后端"><a href="#设计后端" class="headerlink" title="设计后端"></a>设计后端</h2><p>FPGA 架构研究的挑战核心内容：FPGA 架构创新需要解决两大挑战</p><ul><li>缺乏代表性应用设计</li><li>底层电路（面积&#x2F;功耗&#x2F;延迟）的精确描述</li></ul><p>但是新架构需应用验证，但是应用开发又依赖成熟架构。</p><p>例如，AI 加速器设计需特定算子支持，但现有基准测试集（如 MiBench）难以覆盖新兴场景。同时，7 nm 工艺下，互联延迟占比超 60%，传统 SPICE 仿真耗时过长，需要数据驱动的快速评估模型</p><p>VTR (veruling-to-Routing)开源框架的出现，通过参数化架构描述文件 (如. Vtr 格式)实现“一次建模，多次验证”的敏捷开发范式</p><h3 id="VTR-开源工具链"><a href="#VTR-开源工具链" class="headerlink" title="VTR 开源工具链"></a>VTR 开源工具链</h3><p><img src="/assets/24417b93162bac23907ba12061e822e6.jpeg" alt="alt text"><br>VTR 9 (2025) 通过模块化设计实现架构无关性</p><ul><li><strong>前端兼容</strong>：Yosys 处理复杂 RTL, Odin-II 专攻简单逻辑，混合模式提升 40%综合效率</li><li><strong>后端创新</strong>：VPR 的“Pack-Place-Route”流程引入机器学习驱动的拥塞预测器，布线失败率降低 28%</li><li><strong>数据驱动</strong>：架构描述文件 (Arch XML)支持自定义 LUT 配置 (如 6-LUT+4-LUT 混合)、DSP 精度 fp 32&#x2F;fp 16)等参数，为 FPGA 定制化提供基础</li></ul><h3 id="架构灵活性-Blocks-Block-Arrangement-Routing"><a href="#架构灵活性-Blocks-Block-Arrangement-Routing" class="headerlink" title="架构灵活性-Blocks, Block Arrangement, Routing"></a>架构灵活性-Blocks, Block Arrangement, Routing</h3><h4 id="Architecture-Flexibility-Blocks"><a href="#Architecture-Flexibility-Blocks" class="headerlink" title="Architecture Flexibility: Blocks"></a>Architecture Flexibility: Blocks</h4><p><img src="/assets/dc777878cd9b600735210f3c4c7e567d.jpeg" alt="alt text"></p><ul><li>逻辑原语（Logic Primitive）: 最基础的构建单元，如 6-LUT 和 4-LUT, 用于实现基本的逻辑功能</li><li>逻辑单元 (Logic Element): 由多个逻辑原语组合而成，具备更复杂的逻辑处理能力</li><li>逻辑块大小 (Logic Block Size)：不同规模的逻辑块，体现模块的可扩展性</li><li>模块间连接性 (Inter-Element-Connectivity)：不同逻辑单元之间的连接方式</li><li>完整模块 (Full Blocks)：包括 DSP 块和 2 D 系统张量块等专用功能模块，这些模块集成了特定的计算功能，如乘法、加法等</li></ul><p>只要善用这些元素就可以设计出各种各样的电路，可扩展性极高</p><h4 id="Architecture-Flexibility-Block-Arrangement"><a href="#Architecture-Flexibility-Block-Arrangement" class="headerlink" title="Architecture Flexibility: Block Arrangement"></a>Architecture Flexibility: Block Arrangement</h4><p><img src="/assets/f2c53d6d18d760b46db8d4c754ce1619.jpeg" alt="alt text"></p><ul><li>I&#x2F;Os: 输入输出接口，位于芯片边缘，负责与外部设备通信</li><li>逻辑块：主要的逻辑处理单元，分布在芯片内部</li><li>DSP: 数字信号处理模块，用于高效执行数学运算</li><li>Block RAM: 块存储器，提供高速数据存储功能</li><li>NoC Router: 片上网络路由器，用于模块间的高效数据传输</li><li>Hard Block: 硬核模块，如 PCI-E 接口，提供特定的硬件功能</li></ul><h4 id="Architecture-Flexibility-Routing"><a href="#Architecture-Flexibility-Routing" class="headerlink" title="Architecture Flexibility: Routing"></a>Architecture Flexibility: Routing</h4><p><img src="/assets/a5d31e13083dc13f13dc941b464da636.jpeg" alt="alt text"></p><ul><li>直接块间连接 (Direct Block-Block Connection): 模块之间的直接连线，用于快速数据传输</li><li>线间连接 (Wire-Wire Connection)(switch-block): 通过开关块实现的灵活布线，允许任意连个点之间的连接</li><li>布线线 (Routing Wires): 遍布芯片的布线资源，支持复杂的数据路径设计</li><li>块输入&#x2F;输出连接（Block input&#x2F;Output Connection）：模块与布线资源的接口，确保数据的正确输入和输出</li></ul><div class="tip">模块构成定义了芯片的基本功能单元及其组合方式，模块布局规划了各功能模块在芯片上的空间分布，布线连接实现了模块间的灵活高效通信</div><h3 id="NoC-与-3D-集成技术"><a href="#NoC-与-3D-集成技术" class="headerlink" title="NoC 与 3D 集成技术"></a>NoC 与 3D 集成技术</h3><h4 id="芯片强化网络"><a href="#芯片强化网络" class="headerlink" title="芯片强化网络"></a>芯片强化网络</h4><p>Srinivasan 团队 (Adaptive Wormhole)提出“Placement Co-Optimization”，将 NoC 路由器与可编程逻辑布线延迟联合建模，关键路径延迟减少 35%<br><img src="/assets/1c08b68fd4be66b9553cbae025ab336b.jpeg" alt="alt text"></p><h4 id="3D-异构"><a href="#3D-异构" class="headerlink" title="3D 异构"></a>3D 异构</h4><p>通过硅通孔 (TSV)与微凸块 (ubumps)实现计算-存储堆叠，如 Samsung HBM3-PIM3 将 GDDR6 堆叠与 FPGA 逻辑层，能效提升 4.2 倍<br><img src="/assets/40260c24e88e5ff001f19de1e0de43a3.jpeg" alt="alt text"></p><h3 id="定制化-FPGA-实现"><a href="#定制化-FPGA-实现" class="headerlink" title="定制化 FPGA 实现"></a>定制化 FPGA 实现</h3><ul><li>开源工具：OpenFPGA 支持从 VTR 架构文件直接生成标准单元布局，NRE (非重复工程成本)降低 90%</li><li>软核 (Soft Fabric)比全定制方案面积增加 60%，延迟上升 20%，但开发周期从 18 周缩短至 2 周</li><li>Google Edge TPU 的 FP 4 矩阵乘法器，通过专用 LUT 配置实现 8 TOPS&#x2F;W 的能效突破</li></ul><h2 id="吞吐量导向的时空架构-Throughput-Focused-Spatio-Temporal-Arch"><a href="#吞吐量导向的时空架构-Throughput-Focused-Spatio-Temporal-Arch" class="headerlink" title="吞吐量导向的时空架构 (Throughput-Focused Spatio-Temporal Arch)"></a>吞吐量导向的时空架构 (Throughput-Focused Spatio-Temporal Arch)</h2><h3 id="晶圆级集成与-Cerebras"><a href="#晶圆级集成与-Cerebras" class="headerlink" title="晶圆级集成与 Cerebras"></a>晶圆级集成与 Cerebras</h3><p>传统的 HPC 架构，计算节点集群通过外部网络高延迟互联，众多独立的小芯片通过 PCB 板与片外高延迟内存通信。而 Celebras 晶圆级架构，使十万核心平铺于晶圆，通过片上高带宽 Mesh 网络直接、快速互联，使用单一晶圆巨芯片让计算核心与海量片上 SRAM 集成在一起，访存延时极低。</p><p><strong>WSE-3 core架构特点</strong></p><ul><li>最小化指令和控制开销：采用顺序核心 (In-order core)，支持 SIMD (fp 16 和 fp 8)，CISC 指令可处理高达 4 D 张量操作数，类似于 DSP 处理器，每个处理器发出一条指令即可保持所有执行单元的忙碌</li><li>时间灵活性：主线程与 8 个微线程，当主线程等待数据时，可逐周期切换到微线程</li><li>空间特性：近内存计算，核心的一半是 SRAM，实现数据与计算的紧密集成</li></ul><p><img src="/assets/9eed269bd647be172b4a2d8540289d46.jpeg" alt="alt text"></p><h4 id="近内存计算"><a href="#近内存计算" class="headerlink" title="近内存计算"></a>近内存计算</h4><p>Cerebras 的晶圆级引擎是一个单片集成的巨型系统，其核心思路是让计算和存储尽可能近。</p><ul><li>Cerebras WSE-3 (46225 mm^2)集成 2.6 万亿晶体管，相当于 84 颗 GPU 裸片；片上 SRAM 达 44 GB</li><li>超高的带宽互联：所有核心通过一个二维网格网络网格晶圆上直接互联，实现了极高的带宽 21 PB&#x2F;s，超越 HBM3 的 0.008 PB&#x2F;s</li></ul><h4 id="解耦计算与存储"><a href="#解耦计算与存储" class="headerlink" title="解耦计算与存储"></a>解耦计算与存储</h4><ul><li>Weight Streaming (权重流)：模型参数（权重）存储在专用的外部内存系统 MmeroyX 中，可按需“流式”传输到晶圆芯片上进行计算。</li><li>StreamX 互联架构：将芯片内部的高速 Mesh 网络扩展到多台 CS-2 系统之间，集群规模可达 1.63 亿核心<br><img src="/assets/6bc5a5ec85d85c2c9ba306628e185c1e.jpeg" alt="alt text"></li></ul><h4 id="芯片制造"><a href="#芯片制造" class="headerlink" title="芯片制造"></a>芯片制造</h4><p>解决良品率、供电、散热三大问题，Cerebras 的解决方案为：</p><ul><li>冗余设计应对良品率：类似于 Altera FPGA 设计理念，但是细节设计不同，通过冗余链接绕过故障的处理单元 (PE)。在软件上，可以假设一个稍小的完美阵列，无需关心具体的冗余机制</li><li>垂直供电与水冷散热：采用从晶圆背面垂直分层供电的方式，避免因为距离导致的电压不均。同时，为芯片定制了覆盖了每个计算单元的精密水冷系统，确保散热均匀散热</li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>*PPT 及其图示来自 FPT2025讲座——超摩尔与深度学习时代的的空间架构 (Vaughn Betz 教授)</p>]]></content>
      
      
      
        <tags>
            
            <tag> Lecture </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>设置NixOS服务器-vnc</title>
      <link href="/2025/11/25/Nixos-vnc/"/>
      <url>/2025/11/25/Nixos-vnc/</url>
      
        <content type="html"><![CDATA[<h2 id="安装必要的依赖"><a href="#安装必要的依赖" class="headerlink" title="安装必要的依赖"></a>安装必要的依赖</h2><p>在 <code>NixOS</code> 配置添加这三个包</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">environment.systemPackages = [</span><br><span class="line">  pkgs.tigervnc</span><br><span class="line">  pkgs.xorg.xinit</span><br><span class="line">  pkgs.icewm</span><br><span class="line">  pkgs.x11vnc</span><br><span class="line">];</span><br></pre></td></tr></table></figure><ul><li><code>pkgs.tigervnc&amp;pkgs.x11vnc</code> ：<code>tigervnc </code> 和 <code>x11vnc</code> 都是可以开启 <code>NixOS vncserver</code> 服务的包，安装了之后 <code>NixOS</code> 就可以使用 <code>vncserver</code> 命令。</li><li><code>pkgs.xorg.xinit</code>：<code>vncserver</code> 脚本在启动虚拟桌面的时依赖 <code>xinit</code>，需要将其加入到系统包中。不然会报错。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; vncserver :0 -gemoetry 1920x1080 -depth 24</span><br><span class="line">&gt; .vncserver-wrapped: couldn<span class="string">&#x27;t find &quot;xinit&quot; on your PATH</span></span><br></pre></td></tr></table></figure><ul><li><code>pkgs.icewm</code>：在 <code>vncserver</code> 中运行完整的 GNOME 会非常卡顿且容易出错（因为 3 D 加速问题）。需要安装一个轻量级的窗口管理器。建议安装 <code>icewm</code> 和 <code>xfce</code> 用于 VNC 连接。在 Nixos 中建议安装 <code>icewm</code>。</li></ul><h3 id="为什么安装了-tigervnc-还要安装-x11vnc"><a href="#为什么安装了-tigervnc-还要安装-x11vnc" class="headerlink" title="为什么安装了 tigervnc 还要安装 x11vnc"></a>为什么安装了 <code>tigervnc</code> 还要安装 <code>x11vnc</code></h3><p>因为我的 <code>NixOS</code> 使用的是 <code>GNOME</code> 桌面，并启用 <code>Wayland</code> 显示服务。如果使用 <code>x11vnc</code> 会出现下述报错。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">~ › x11vnc -usepw  </span><br><span class="line">Enter VNC password:  </span><br><span class="line">Verify password:  </span><br><span class="line">Write password to /home/qiqi49/.vnc/passwd? [y]/n y  </span><br><span class="line">Password written to: /home/qiqi49/.vnc/passwd  </span><br><span class="line">25/11/2025 14:40:52 x11vnc version: 0.9.17 lastmod: 2025-04-11 pid: 591848  </span><br><span class="line">25/11/2025 14:40:52 Wayland display server detected.  </span><br><span class="line">25/11/2025 14:40:52 Wayland sessions are as of now only supported via -rawfb and the bundled deskshot utility. Exiting</span><br></pre></td></tr></table></figure><p>如果要使用 <code>Wayland</code> 支持的可以使用 <code>tigervnc</code> 。<u>也有可能是我的操作失误</u>，如果只安装 <code>tigervnc</code> 使用命令 <code>vncpasswd</code> 创建密码时候不会在 <code>~/.vnc/passwd</code> 创建，这导致我后续使用命令启动 <code>VNC</code> 服务的时候传入不了密码。</p><p>但是我可以使用 <code>x11vnc</code> 使用命令 <code>x11vnc -usepw</code> 创建密码，它会帮你自动创建 <code>~/.vnc/passwd</code> 文件</p><div class="tip">vncpasswd 创建的是加密文件，不能使用编辑器 (nano/vim) 直接编辑 ~/.vnc/passwd 文件。直接写入文本会导致 VNC 无法识别密码</div><h2 id="更改-NixOS-配置"><a href="#更改-NixOS-配置" class="headerlink" title="更改 NixOS 配置"></a>更改 NixOS 配置</h2><p>要确保 NixOS 配置允许 VNC 端口。在你的 <code>/etc/nixos/configuration.nix</code> 中，必须确保防火墙打开了 <strong>5900, 5901, 5902</strong> 端口。<strong>5902</strong>用于开启虚拟端口。</p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123; config, pkgs, ... &#125;:</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  services.gnome.gnome-remote-desktop.<span class="attr">enable</span> = <span class="literal">true</span>;</span><br><span class="line">  </span><br><span class="line">  networking.firewall.<span class="attr">allowedTCPPorts</span> = [ <span class="number">5900</span> <span class="number">5901</span> <span class="number">5902</span>]; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="配置启动脚本-xstartup"><a href="#配置启动脚本-xstartup" class="headerlink" title="配置启动脚本 (xstartup)"></a>配置启动脚本 (xstartup)</h2><p>NixOS 默认不知道你想在 VNC 里启动什么桌面。你必须配置 <code>~/.vnc/xstartup</code>，否则连进去是一片灰屏。</p><ol><li>创建&#x2F;编辑文件：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.vnc/xstartup</span><br></pre></td></tr></table></figure><ol start="2"><li>写入以下内容 (使用 IceWM):</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修复剪贴板和一些环境变量</span></span><br><span class="line"><span class="built_in">unset</span> SESSION_MANAGER</span><br><span class="line"><span class="built_in">unset</span> DBUS_SESSION_BUS_ADDRESS</span><br><span class="line"></span><br><span class="line"><span class="comment"># 屏蔽 Wayland</span></span><br><span class="line"><span class="built_in">unset</span> WAYLAND_DISPLAY</span><br><span class="line"><span class="built_in">export</span> MOZ_ENABLE_WAYLAND=0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 让GTK/QT使用x11</span></span><br><span class="line"><span class="built_in">export</span> GDK_BACKEND=x11</span><br><span class="line"><span class="built_in">export</span> QT_QPA_PLATFORM=xcb</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动 D-Bus 会话总线</span></span><br><span class="line"><span class="keyword">if</span> [ -x <span class="string">&quot;<span class="subst">$(command -v dbus-launch)</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">  <span class="built_in">eval</span> <span class="string">&quot;<span class="subst">$(dbus-launch --sh-syntax --exit-with-session)</span>&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动窗口管理器</span></span><br><span class="line"><span class="built_in">exec</span> icewm-session</span><br><span class="line"></span><br></pre></td></tr></table></figure><ol start="3"><li>保存退出 (<code>:wq</code>)</li><li>赋值执行权限</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">chmod</span> +x ~/.vnc/xstartup</span><br></pre></td></tr></table></figure><h2 id="启动服务器"><a href="#启动服务器" class="headerlink" title="启动服务器"></a>启动服务器</h2><h3 id="使用命令运行"><a href="#使用命令运行" class="headerlink" title="使用命令运行"></a>使用命令运行</h3><p>直接运行命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xinit ~/.vnc/xstartup -- $(<span class="built_in">which</span> Xvnc) :2 -rfbauth ~/.vnc/passwd -geometry 1920x1080 -depth 24</span><br></pre></td></tr></table></figure><p>出现一些 warning 可以不用管，出现这些信息说明服务开启成功</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Xvnc TigerVNC 1.14.0 - built Jan  1 1980 00:00:00</span><br><span class="line">Copyright (C) 1999-2024 TigerVNC Team and many others (see README.rst)</span><br><span class="line">See https://www.tigervnc.org <span class="keyword">for</span> information on TigerVNC.</span><br><span class="line">Underlying X server release 12101018</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Tue Nov 25 18:45:16 2025</span><br><span class="line"> vncext:      VNC extension running!</span><br><span class="line"> vncext:      Listening <span class="keyword">for</span> VNC connections on all interface(s), port 5902</span><br><span class="line"> vncext:      created VNC server <span class="keyword">for</span> screen 0</span><br><span class="line">The XKEYBOARD keymap compiler (xkbcomp) reports:</span><br><span class="line">&gt; Warning:          Could not resolve keysym XF86RefreshRateToggle</span><br><span class="line">&gt; Warning:          Could not resolve keysym XF86Accessibility</span><br><span class="line">&gt; Warning:          Could not resolve keysym XF86DoNotDisturb</span><br><span class="line">Errors from xkbcomp are not fatal to the X server</span><br><span class="line">[mi] mieq: warning: overriding existing handler (nil) with 0x5d8990 <span class="keyword">for</span> event 2</span><br><span class="line">[mi] mieq: warning: overriding existing handler (nil) with 0x5d8990 <span class="keyword">for</span> event 3</span><br><span class="line">xinit: XFree86_VT property unexpectedly has 0 items instead of 1</span><br></pre></td></tr></table></figure><p>使用非本地主机连接 vnc 的时候一定要确保 NixOS 中端口 5902 开启 </p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">networking.firewall.<span class="attr">allowedTCPPorts=[5902];</span></span><br></pre></td></tr></table></figure><h3 id="在-NixOS-配置-systemd-服务"><a href="#在-NixOS-配置-systemd-服务" class="headerlink" title="在 NixOS 配置 systemd 服务"></a>在 NixOS 配置 systemd 服务</h3><p>在 NixOS 配置中添加以下代码：</p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">&#123; pkgs, ... &#125;:&#123;</span><br><span class="line">  networking.firewall.<span class="attr">allowedTCPPorts=[</span> <span class="number">5900</span> <span class="number">5901</span> <span class="number">5902</span>];</span><br><span class="line"></span><br><span class="line">  systemd.services.<span class="attr">myserver-vnc</span> = &#123;</span><br><span class="line">    <span class="attr">description</span> = <span class="string">&quot;VNC Server for User qiqi49&quot;</span>;</span><br><span class="line">    <span class="attr">after</span> = [<span class="string">&quot;network.target&quot;</span>];</span><br><span class="line">    <span class="attr">wantedBy</span> = [<span class="string">&quot;multi-user.target&quot;</span>];</span><br><span class="line"></span><br><span class="line">    <span class="attr">serviceConfig</span> = &#123;</span><br><span class="line">      <span class="attr">User</span> = <span class="string">&quot;qiqi49&quot;</span>;</span><br><span class="line">      <span class="attr">PAMname</span> = <span class="string">&quot;login&quot;</span>;</span><br><span class="line">      <span class="attr">Type</span> = <span class="string">&quot;simple&quot;</span>;</span><br><span class="line"></span><br><span class="line">      <span class="attr">ExecStart</span> = <span class="keyword">let</span></span><br><span class="line">        <span class="attr">startScript</span> = pkgs.writeShellScript <span class="string">&quot;vnc-start-script&quot;</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="string">          #!/bin/sh</span></span><br><span class="line"><span class="string">  export PATH=$PATH:/run/current-system/sw/bin</span></span><br><span class="line"><span class="string">          unset DBUS_SESSION_BUS_ADDRESS</span></span><br><span class="line"><span class="string">          unset SESSION_MANAGE</span></span><br><span class="line"><span class="string">          unset WAYLAND_DISPLAY</span></span><br><span class="line"><span class="string">          export MOZ_ENABLE_WAYLAND=0</span></span><br><span class="line"><span class="string">          export GDK_BACKEND=x11</span></span><br><span class="line"><span class="string">          export QT_QPA_PLATFORM=xcb</span></span><br><span class="line"><span class="string">          if [ -x &quot;$(command -v dbus-launch)&quot; ]; then</span></span><br><span class="line"><span class="string">            eval &quot;$(dbus-launch --sh-syntax --exit-with-session)&quot;</span></span><br><span class="line"><span class="string">          fi</span></span><br><span class="line"><span class="string">          <span class="subst">$&#123;pkgs.icewm&#125;</span>/bin/icewm-session</span></span><br><span class="line"><span class="string">        &#x27;&#x27;</span>;</span><br><span class="line">        <span class="keyword">in</span> <span class="string">&quot;<span class="subst">$&#123;pkgs.xorg.xinit&#125;</span>/bin/xinit <span class="subst">$&#123;startScript&#125;</span> -- <span class="subst">$&#123;pkgs.tigervnc&#125;</span>/bin/Xvnc :2 -rfbauth /home/qiqi49/.vnc/passwd -geometry 1920x1080 -depth 24&quot;</span>;</span><br><span class="line">    &#125;;</span><br><span class="line">  &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="NixOS-不能运行使用-vncserver-命令运行"><a href="#NixOS-不能运行使用-vncserver-命令运行" class="headerlink" title="NixOS 不能运行使用 vncserver 命令运行"></a>NixOS 不能运行使用 vncserver 命令运行</h3><p>使用 <code>vncserver</code> 运行会出现以下报错：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; vncserver :1 -geometry 1920x1080 -depth 24 -xstartup ~/.vnc/xstartup  </span><br><span class="line">&gt; .vncserver-wrapped: Couldn<span class="string">&#x27;t find suitable Xsession</span></span><br></pre></td></tr></table></figure><p>因为 <code>vncserver</code> 是一个 Perl 脚本，它是按照传统 Linux（如 Ubuntu&#x2F;CentOS）的文件结构编写的。它在启动时会通过硬编码的路径（例如 <code>/etc/X11/Xsession</code>）来寻找系统的启动会话文件。</p><p>而在 NixOS 中，这些标准路径是不存在的（NixOS 的文件都在 <code>/nix/store/...</code> 里），所以 <code>vncserver</code> 脚本找不到它需要的基础文件，直接报错退出。</p><p>在 NixOS 上，我们不能直接运行 <code>vncserver</code> 命令。你有两个解决方案：一个是用 <code>xinit</code> 命令手动启动（临时测试用），另一个是配置 Systemd 服务（长期稳定用）。</p><h3 id="使用-systemd-服务不能启动终端，但是命令行启动无问题"><a href="#使用-systemd-服务不能启动终端，但是命令行启动无问题" class="headerlink" title="使用 systemd 服务不能启动终端，但是命令行启动无问题"></a>使用 systemd 服务不能启动终端，但是命令行启动无问题</h3><ul><li><p>使用命令行启动时：<br>  你是一个登录用户。Shell（终端）会自动加载 <code>/etc/profile</code> 和用户配置，因此你的 <code>PATH</code> 环境变量里包含了 <code>/run/current-system/sw/bin</code>（这是 NixOS 存放 xterm, firefox 等常用命令的地方）。IceWM 继承了这个 PATH，所以它能找到 <code>xterm</code>。</p></li><li><p>当你使用 Systemd 启动时：<br> Systemd 是一个后台服务管理器，它运行在一个非常精简、隔离的环境中。默认情况下，它的 PATH 通常只包含 <code>/nix/store/...</code> 里的一些核心工具，不包含 <code>/run/current-system/sw/bin</code>。<br> 当在 VNC 里按下快捷键，IceWM 试图执行命令 <code>xterm</code>，但它在它的 PATH 里找不到这个命令，于是执行失败，且没有任何提示。<br>必须要在脚本中手动添加<strong>系统路径</strong>。</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:/run/current-system/sw/bin</span><br></pre></td></tr></table></figure><h2 id="客户端连接"><a href="#客户端连接" class="headerlink" title="客户端连接"></a>客户端连接</h2><h3 id="vncviewer"><a href="#vncviewer" class="headerlink" title="vncviewer"></a>vncviewer</h3><ul><li><p>可以使用在本地使用 vncviewer 查看自己的 vnc 服务是否开启成功，输入 <code>本地 IP:5902</code>，连接输入密码。<br><img src="/assets/file-20251125185422581.png" alt="alt text"><br><img src="/assets/file-20251125185603235.png" alt="alt text"></p></li><li><p>在手机上可以使用 <code>RVNC viewer</code>，也是输入 IP 地址: 5902 就可以连接。出现下面的信息就说明连接成功了。</p></li></ul><p><img src="/assets/file-20251125185926576.png" alt="alt text"></p><h3 id="使用-Zerotier-或者-Tailscale-创建虚拟公网"><a href="#使用-Zerotier-或者-Tailscale-创建虚拟公网" class="headerlink" title="使用 Zerotier 或者 Tailscale 创建虚拟公网"></a>使用 Zerotier 或者 Tailscale 创建虚拟公网</h3><p>使用 Zerotier 或者 Tailscale 创建虚拟公网，将连接设备添加到同一个公网中，这样就可以远程连接 NixOS 服务器</p><h3 id="使用客户端启动-firefox"><a href="#使用客户端启动-firefox" class="headerlink" title="使用客户端启动 firefox"></a>使用客户端启动 firefox</h3><p>在客户端启动 firefox，发现是在物理机上启动 firefox，而不是在 icewm 中启动。需要添加环境环境变量</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">unset</span> WAYLAND_DISPLAY</span><br><span class="line"><span class="built_in">export</span> GDK_BACKEND=x11</span><br></pre></td></tr></table></figure><p>因为 firefox 会优先选择 <code>Wayland</code> 通道，绕过了 vnc 的 <code>x11</code> 协议。所以要使 firefox 强制使用 <code>x11</code> 后端</p>]]></content>
      
      
      
        <tags>
            
            <tag> Tools </tag>
            
            <tag> Nix </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Obsidian-NAS极空间-Cpolar同步</title>
      <link href="/2025/11/21/Obsidian-NAS%E6%9E%81%E7%A9%BA%E9%97%B4-Cpolar%E5%90%8C%E6%AD%A5/"/>
      <url>/2025/11/21/Obsidian-NAS%E6%9E%81%E7%A9%BA%E9%97%B4-Cpolar%E5%90%8C%E6%AD%A5/</url>
      
        <content type="html"><![CDATA[<h2 id="试错-Tailscale-多端同步"><a href="#试错-Tailscale-多端同步" class="headerlink" title="试错 Tailscale 多端同步"></a>试错 Tailscale 多端同步</h2><ul><li><a href="https://post.smzdm.com/p/agqd5k87/p2/?sort_tab=hot/#comments">教程：使用tailscale内网穿透访问你家的极空间</a><br>根据网上的一些教程，通过使用 Tailscale 与 NAS 极空间完成多平台的同步，但是失败了，无法连接到公网。</li></ul><h2 id="使用-Cpolar-同步"><a href="#使用-Cpolar-同步" class="headerlink" title="使用 Cpolar 同步"></a>使用 Cpolar 同步</h2><p><code>Cpolar</code> 比 Tailscale 操作简单很多，只需要下载，以及注册一个账号即可，剩下不需要什么操作。这个教程，省略了使用 <code>Cpolar</code> 的内容</p><ul><li><a href="https://zhuanlan.zhihu.com/p/702018896">教程：极空间+obsidian 同步</a></li></ul><h3 id="在-NAS-极空间中搜索-docker-仓库-Cpolar（踩坑）"><a href="#在-NAS-极空间中搜索-docker-仓库-Cpolar（踩坑）" class="headerlink" title="在 NAS 极空间中搜索 docker 仓库 Cpolar（踩坑）"></a>在 NAS 极空间中搜索 docker 仓库 Cpolar（踩坑）</h3><p>根据教程，在 NAS 极空间 docker 仓库中搜索出来的 Cpolar 部署的容器无法正常运行，一直在重启</p><ul><li><a href="https://www.bilibili.com/opus/978709685396832281">教程：Cpolar 极空间 docker 部署</a></li></ul><h3 id="使用-SSH-安装-Cpolar"><a href="#使用-SSH-安装-Cpolar" class="headerlink" title="使用 SSH 安装 Cpolar"></a>使用 SSH 安装 Cpolar</h3><p>换了一种方式通过 <code>SSH</code> 连接到 NAS 极空间中，下载 Cpolar 运行即可</p><ul><li><a href="https://mp.weixin.qq.com/s/S9vwpHMeXT3sHs8NbJdrzA">教程：极空间 SSH 公网配置</a></li></ul><p>根据上述教程中的配置，将极空间内的 SSH 设置打开，连接到客户端上之后，在本地安装 cpolar<br><img src="/assets/file-20251121155439308.png" alt="alt text"></p><div class="tip">Cpolar 是一款强大的内网穿透工具，无需公网 IP、无需路由器设置，只需要在本地设备上运行一个客户端，就能将内网的 SSH 服务安全地映射到一个公网可访问的地址</div>**以下是安装cpolar 步骤：**官网在此：[https://www.cpolar.com](https://www.cpolar.com/)使用一键脚本安装命令：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> curl https://get.cpolar.sh | sh</span><br></pre></td></tr></table></figure>安装完成后，执行下方命令查看cpolar服务状态：（如图所示即为正常启动）<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> systemctl status cpolar</span><br></pre></td></tr></table></figure>Cpolar安装和成功启动服务后，在浏览器上输入虚拟机主机IP（打开 WebDev 时显示的 IP）加9200端口。<p>例如：<code>http://192.168.5.24:9200</code>，访问Cpolar管理界面，使用Cpolar官网注册的账号登录,登录后即可看到cpolar web 配置界面,接下来在web 界面配置即可。</p><p>打开浏览器访问本地9200端口，使用cpolar账户密码登录即可,登录后即可对隧道进行管理。<br><img src="/assets/file-20251121160152844.png"></p><h3 id="配置公网地址"><a href="#配置公网地址" class="headerlink" title="配置公网地址"></a>配置公网地址</h3><p>通过配置，你可以在本地 WSL 或 Linux 系统上运行 SSH 服务，并通过 Cpolar 将其映射到公网，从而实现从任意设备远程连接开发环境的目的。</p><ul><li>隧道名称：可自定义，本例使用 obsidian，注意不要与已有的隧道名称重复</li><li>协议：http</li><li>本地地址：192.168.5.24:5005</li><li>域名类型：随机域名（其他需要收费，所以有的时候域名会变就要自己更改了）</li><li>地区：China Top</li></ul><p><img src="/assets/file-20251121160600915.png" alt="alt text"><br>创建成功后，打开左侧在线隧道列表,可以看到刚刚通过创建隧道生成了公网地址，接下来就可以在其他电脑或者移动端设备（异地）上，使用任意一个地址在终端中访问即可。</p><ul><li>Http 表示使用的协议类型</li><li><code>http://xxxx.r29.cpolar.top</code> 是 Cpolar 提供的域名</li></ul><p><img src="/assets/file-20251121160757795.png" alt="alt text"></p><h3 id="打开-Obsidian-的-Remotely-Save-插件（踩坑）"><a href="#打开-Obsidian-的-Remotely-Save-插件（踩坑）" class="headerlink" title="打开 Obsidian 的 Remotely Save 插件（踩坑）"></a>打开 Obsidian 的 Remotely Save 插件（踩坑）</h3><p>打开 Obsidian 的 Remotely Save 插件开始同步<br><img src="/assets/file-20251121161245775.png" alt="alt text"><br><strong>问题</strong>：如果将隧道地址填写进服务器地址进行检查的时候显示连接不上这个服务器。<br><strong>解决</strong>：必须在隧道地址后面添加 NAS 极空间的目录地址(比如:<code>http://xxx/public/Public/docker/cpolar</code>)，此时检查才能通过<br><img src="/assets/file-20251121161509981.png" alt="alt text"></p><h3 id="缺陷——域名更新"><a href="#缺陷——域名更新" class="headerlink" title="缺陷——域名更新"></a>缺陷——域名更新</h3><p>因为 Cpolar 的域名固定都是需要花钱的，所以免费的就只能自己更新域名了</p>]]></content>
      
      
      
        <tags>
            
            <tag> Tools </tag>
            
            <tag> Obsidian </tag>
            
            <tag> NAS device </tag>
            
            <tag> Cpolar </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>芯动力——硬件加速设计方法</title>
      <link href="/2024/07/25/HardwareDesign1/"/>
      <url>/2024/07/25/HardwareDesign1/</url>
      
        <content type="html"><![CDATA[<p>硬件加速设计方法：专题一 高质量VerilogHDL描述方法</p><h2 id="VerilogHDL-可综合描述"><a href="#VerilogHDL-可综合描述" class="headerlink" title="VerilogHDL 可综合描述"></a>VerilogHDL 可综合描述</h2><p>VerilogHDL 是描述可综合的硬件电路<br>HDL 语言具有以下的硬件设计的基本概念</p><ul><li><strong>互联 (connectivity)</strong> - wire 型变量描述各个模块之间的端口和网线连接关系</li><li>**并发 (concurrency) **- 可以有效地描述并行的硬件系统</li><li>**时间 (time) **- 定义了绝对和相对的时间度量，可综合操作符都是具有物理延时的</li></ul><h2 id="Verilog-HDL-用于可综合描述的语句"><a href="#Verilog-HDL-用于可综合描述的语句" class="headerlink" title="Verilog HDL 用于可综合描述的语句"></a>Verilog HDL 用于可综合描述的语句</h2><h3 id="可用于综合的语句"><a href="#可用于综合的语句" class="headerlink" title="可用于综合的语句"></a>可用于综合的语句</h3><p><strong>always</strong><br><strong>if-else</strong>: 映射的硬件结构-多路选择器，输出结果由输入的选择确定</p><ul><li>代码和电路是互相等价的。<strong>硬件结构比较复杂，以及控制通道的延迟</strong>等。代码在书写的时候就要注意<strong>综合电路的性能最优化</strong>，要综合考虑硬件电路的性能和结构。</li><li>要根据输入约束，小心设计：<strong>先”加”后“选”</strong>，还是<strong>先”选”后“加”</strong></li><li><strong>单 if 语句</strong>：无优先级的判断结构，描述多条件判断结构</li><li><strong>多 if 语句</strong>：有优先级的判断结构，<strong>最后一级信号具有最高优先级，具有优先级的多选结构会消耗组合逻辑</strong>。若某些设计中，有些信号要求先到达（如<strong>关键使能信号、选择信号</strong>等），有些信号要求后到达（如<strong>慢速信号、有效时间较长的信号</strong>等），此时需要使用 if..if 语句。设计方法：最高优先级给最迟到达的关键信号<br><strong>case</strong>：无优先级的判断结构，与单 if 语句的区别是条件互斥，通常用于指令编码译码电路<br><strong>assign</strong></li></ul><h3 id="不可用于综合的语句"><a href="#不可用于综合的语句" class="headerlink" title="不可用于综合的语句"></a>不可用于综合的语句</h3><p><strong>function</strong>、**for **、<strong>fork-join</strong>、<strong>while</strong></p><h3 id="Latch和D触发器"><a href="#Latch和D触发器" class="headerlink" title="Latch和D触发器"></a>Latch和D触发器</h3><p>一般情况下避免使用 latch (锁存器)，一般只有在异步电路和门控时钟时会用到 latch<br><img src="/assets/Pastedimage20231024202936.png"><br>latch 是电平触发，非同步控制。DFF 由时钟沿触发，同步控制。Latch 容易产生毛刺（glitch），而 DFF 不易产生毛刺。<br>latch 将 STA 变得复杂。因为 Latch 不能过滤毛刺，对下一级电路极其危险，所以避免产生 Latch, 尽可能使用 D 触发器</p><h3 id="避免产生-Latch-的措施"><a href="#避免产生-Latch-的措施" class="headerlink" title="避免产生 Latch 的措施"></a>避免产生 Latch 的措施</h3><p>易引入 latch 的途径：使用不完备的条件判断语句（if-else 语句缺少 else、case 语句缺少 default）</p><blockquote><p>防止产生 latch 的措施</p><ol><li>使用完备的 if… Else 语句</li><li>为每个输入条件设计输出操作，为 case 语句设置 default 操作</li><li>仔细检查综合器生成的报告，latch 会以 warning 的形式报告</li></ol></blockquote><h3 id="full-case-和-parallel-case-综合器指令"><a href="#full-case-和-parallel-case-综合器指令" class="headerlink" title="full-case 和 parallel-case 综合器指令"></a>full-case 和 parallel-case 综合器指令</h3><p>有时会出现设计目标缘故产生 Latch<br><code>full-case</code>: 告诉综合器，当前 case 结构所列条件已完备(<code>//synopsys full_case</code>)<br><code>parallel-case</code>: 告诉 DC，所有条件均互斥，且并行，无优先权(<code>//synopsys parallel_case</code>)</p><p><strong>逻辑复制-&gt;均衡负载</strong><br>通过逻辑复制，降低关键信号的扇出，进而降低该信号的传播延迟，提高电路性能</p><p><strong>资源共享-&gt;减小面积</strong><br>一般进行资源共享会减小电路面积，但是性能会下降，要综合考虑性能和面积而进行取舍</p><p><strong>资源顺序重排-&gt;降低传播延时</strong><br>如果一个输入信号来的晚我们可以尽可能的把它放在后面，隐藏其延迟</p><p><strong>assign 仅用来连线，always 用于逻辑运算</strong><br>尽量少用 assign 进行逻辑运算，不仅难以阅读，且多层嵌套之后很难被综合器解释(不过现在好像更多用是<code>assign</code>来描述逻辑电路)</p><h3 id="可综合风格"><a href="#可综合风格" class="headerlink" title="可综合风格"></a>可综合风格</h3><p><strong>完整的 <code>always</code>  敏感信号列表</strong><br>敏感信号列表必须包含输入信号</p><ul><li>原因：综合过程中会产生一个取决于除敏感列表中所有其他值的结构，它将可能在行为仿真和门级仿真间产生潜在的失配</li></ul><p><strong>每个 <code>always</code> 敏感信号列表只能对应一个时钟</strong></p><ul><li>将每个过程限制在单一寄存器中，有利于 STA 和逻辑综合</li></ul><p><strong>不允许 <code>wait</code> 声明和 <code>#delay</code> 声明</strong>  </p><ul><li>综合器不允许，但是可以在测试模块和表示行为的虚拟模块中使用<blockquote><p>语法说明<br>在时序电路中必须使用非阻塞赋值 <code>&lt;=</code><br>在组合逻辑电路中必须使用阻塞赋值 <code>=</code></p></blockquote></li></ul><h3 id="模块划分"><a href="#模块划分" class="headerlink" title="模块划分"></a>模块划分</h3><p><strong>分开异步逻辑和同步逻辑</strong></p><ul><li>原因：避免综合时的问题，简化约束和编码难度。</li><li>例外：不可应用于非综合模块中（例如：总线模块、总线监视器或是模拟模块）除非他们被设计来综合仿真</li></ul><p><strong>分开控制逻辑和存储器模块</strong></p><ul><li>通常来说，存储器都是用 memory complier 来生成的，其综合方式和 RTL 代码不同，混合在一起不利于综合，不利于很方便地更换工艺库和平台</li></ul><h3 id="在-RTL-书写中如何考虑延迟、面积等"><a href="#在-RTL-书写中如何考虑延迟、面积等" class="headerlink" title="在 RTL 书写中如何考虑延迟、面积等"></a>在 RTL 书写中如何考虑延迟、面积等</h3><p><strong>在 RTL 代码中考虑时</strong></p><ul><li>针对控制信号来到比较晚，尽可能<strong>将延时较大的分支单独拿出来，放在出口最近的选择器中</strong></li><li>注意**“先加后选”<strong>和</strong>“先选后加”**</li><li><strong>加法器、乘法器等复杂的器件少用</strong></li><li>减少设计面积：首先要估计使用设计资源的数量，比如使用了多少触发器、加法器、乘法器。可以借助工具，<strong>最终应该知道在设计中哪些部分占了较大的面积，进而分析和改进</strong></li><li>一般来说触发器由功能决定，很难减少，只能从组合逻辑出发。对于 RTL 代码，就是各种操作符，应该了解<strong>各种操作符对应的电路</strong>，如使用**”+”、”-“、”x”、”&#x2F;“**以及一些条件语句中的比较运算，对于这些操作，<strong>首先判断其必要性，是否能用更简单的方法解决</strong></li><li>如果必须使用复杂的运算符，应考虑<strong>资源共享</strong>，从代码出发，而不是只依靠综合器</li><li>多比特的信号也会占用大量的资源，针对不同的设计有不同的改进方法，对于有可能简化的地方尽可能简化，<u>逻辑简化的同时也对应面积减少和时延减少</u></li></ul><p><strong>对于功耗控制</strong></p><ul><li><strong>门控时钟</strong>，时钟电路的翻转消耗大量资源，此时可以使用门控时钟，减少时钟电路的翻转</li><li><strong>增加使能信号</strong>，使得部分电路只有工作的时候才工作，与门控时钟的差别在与，使用使能信号只使得被控制的电路不再工作，但是其时钟仍然在工作，而门控时钟是使时钟停止工作</li><li><strong>对芯片各个模块进行控制，只有工作的时候才使用</strong></li><li>除了有用信号和时钟的翻转会消耗功耗，组合逻辑的毛刺也会大量消耗功耗，但是在设计过程中毛刺是不可避免的，但是要尽量<strong>减少毛刺的传播</strong>，才可以减少功耗。</li><li>有限状态机，通过<strong>低功耗编码</strong>来减少电路的翻转，比如独热码</li><li>在 RTL 编码阶段对布局布线进行考虑，避免无法布通的情况。<u>如果采用大的 mux，可以将其分解为多级较小的 mux。</u></li></ul><h2 id="RTL-设计指导规则"><a href="#RTL-设计指导规则" class="headerlink" title="RTL 设计指导规则"></a>RTL 设计指导规则</h2><ul><li>RTL 级的设计评判标准很多，如<strong>时序性能、所占面积、可测试性、可重用性、功耗、时钟域的分配、复位信号设计以及与所用 EDA 工具匹配等</strong>。</li><li>一般的指导原则：面积与速度互换、乒乓操作、流水线设计</li></ul><h3 id="面积与速度互换"><a href="#面积与速度互换" class="headerlink" title="面积与速度互换"></a>面积与速度互换</h3><p>面积：一个设计所消耗的目标器件的<strong>硬件资源数量</strong>或者 <strong>ASIC 芯片面积</strong></p><ul><li>FPGA 可以用所消耗的<strong>触发器CFF</strong> 和<strong>查找表数量</strong>来衡量<br>速度：设计在芯片上稳定运行时所能达到的最高频率，这个频率一般由设计的时序状况来决定</li><li>时序特征向量：<strong>时钟周期，PAD to PAD time，Clock setup time, Clock hold time, Clock-to-Output Delay</strong><br>科学的设计目标：</li><li><u>在满足设计时序的要求（包含对设计的最高频率要求）的前提下，占用最小的芯片面积。</u></li><li><u>在所规定的面积下，使设计的时序余量更大，频率更高。</u></li><li>如果设计的时序余量更大，频率更高——设计的健壮性更强, 整个系统的设计质量更有保证</li><li>设计所消耗的面积小——在单位芯片上实现的功能更多，需要的芯片数量更少，成本更低</li><li>满足时序和工作频率的要求更高，即速度优先</li></ul><img src=/assets/Pastedimage20231025195027.png width=80% /><blockquote><p>速度与面积互换</p><ol><li>如果时序余量大，速度-&gt;面积<ul><li>模块复用</li></ul></li><li>如果一个设计时序要求高，普通方法达不到设计频率<ul><li>数据流串并转换</li><li>并行复制多个操作模块</li><li>“乒乓操作”和“串并转换”</li><li>在芯片模块输出处在对数据进行“并串转换”</li></ul></li></ol></blockquote><h3 id="乒乓操作"><a href="#乒乓操作" class="headerlink" title="乒乓操作"></a>乒乓操作</h3><ul><li>乒乓操作一个常常用于数据流控制的处理方法</li></ul><img src=/assets/Pastedimage20231025195210.png width=80% />+ **节约缓冲区**+ **巧妙运用乒乓操作可以做到低速模块处理高速数据流的效果**<h3 id="流水线"><a href="#流水线" class="headerlink" title="流水线"></a>流水线</h3><ul><li>电路的最高频率取决于最长的组合逻辑链路的延迟值</li></ul><img src=/assets/Pastedimage20231025200113.png width=80% /><ul><li>流水线当方法可以有效提高系统的工作频率，但是考虑一个电路的性能通常都是<strong>其单位时间的计算量，或者是一定计算总量下的处理时间</strong></li></ul><img src=/assets/Pastedimage20231025200349.png width=80% /><p><strong>特点</strong></p><ul><li>通过<strong>插入寄存器</strong>，将长的串行逻辑链分成较小的部分</li><li>当系统运算是串行时，利用时钟控制，使运算依照顺序接续执行</li><li>在任何制定时刻，大部分电路都在运行</li></ul><p><strong>好处</strong></p><ul><li><strong>每一部分延时更小-&gt;可使用更快的时钟</strong></li><li><strong>大部分电路同时进行计算-&gt;可提高数据通过量（吞吐量）</strong></li></ul><p><strong>流水线参数设计</strong></p><ul><li>系统时钟取决于最慢的流水线级的延时<ul><li>流水线时钟周期：<br>  $$T_{pipe} &#x3D; max{T_1,T_2,…,T_m}$$</li><li>第 i 级的时钟周期：<br>  $$T_i&gt;t_ff+…+t_{su}+t_{d,i}+t_{s,i}+1$$</li></ul></li><li>流水线分割点及参数确定要考虑的因素<ul><li><strong>单位延迟时间及时间频率的大小决定了数据通过速率</strong></li><li><strong>过多的级数不一定能产生最快的结果</strong></li><li><strong>太多的寄存器的插入会导致芯片面积的增加，布线困难，时钟偏差增加</strong></li></ul></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> FPGA </tag>
            
            <tag> verilog </tag>
            
            <tag> IC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Zerotier-Archlinux-Termius互通教程</title>
      <link href="/2024/07/24/Zerotier/"/>
      <url>/2024/07/24/Zerotier/</url>
      
        <content type="html"><![CDATA[<p>使用Zerotier 和Termius 通过SSH创建个人PC服务器,并且用ipad连接Archlinux</p><h2 id="Zerotier的配置和使用"><a href="#Zerotier的配置和使用" class="headerlink" title="Zerotier的配置和使用"></a>Zerotier的配置和使用</h2><p>Zerotier 是一款不需要公网 IP 内网穿透软件，<code>ZeroTier</code> 是一个专门用来建立点对点虚拟专用网（<code>P2P VPN</code>）的工具，它提供在线管理界面和全平台的客户端，不需要复杂设置，只要安装客户端并加入到自己创建的网络即可。</p><blockquote><ol><li>官方网站地址：<a href="https://www.zerotier.com/">https://www.zerotier.com</a></li></ol></blockquote><blockquote><ol start="2"><li>项目地址：<a href="https://github.com/zerotier">https://github.com/zerotier</a></li></ol></blockquote><h2 id="注册和客户端安装"><a href="#注册和客户端安装" class="headerlink" title="注册和客户端安装"></a>注册和客户端安装</h2><h3 id="注册账号"><a href="#注册账号" class="headerlink" title="注册账号"></a>注册账号</h3><p>ZeroTier 可以通过邮箱或者 <code>Google</code> <code>Github</code> <code>Microsoft</code> 账号注册。</p><p><img src="/assets/Pastedimage20240310163135.png"></p><p>进入 Zerotier 之后就可以创建你的 Networks。<code>NETWORK ID</code> 是客户端连接到行星服务器的唯一识别码，需要牢记, 即每个客户端需要 Join 的 ID, <code>NAME</code> 可以随意更改。</p><p><img src="/assets/Pastedimage20240310163523.png"></p><h3 id="网络配置"><a href="#网络配置" class="headerlink" title="网络配置"></a>网络配置</h3><p><code>SUBNET</code> 是 <code>Zerotier One</code> 使用 <code>STUN</code> 和隧道建立的 <code>NAT</code>，可以更改内网 ip 网段。<code>NODES</code> 是连入 <code>NETWORK</code> 的设备数，以及建立时间 <code>CREATED</code>。</p><p><img src="/assets/Pastedimage20240310164241.png"></p><h2 id="客户端配置"><a href="#客户端配置" class="headerlink" title="客户端配置"></a>客户端配置</h2><p><code>ZeroTier</code> 支持 <code>Windows</code>、<code>macOS</code>、<code>Linux</code> 三大桌面平台，<code>iOS</code>、<code>Android</code> 两大移动平台，<code>QNAP（威连通）</code>、<code>Synology（群晖）</code>、<code>Western Digital MyCloud NAS（西部数据）</code> 三个 <code>NAS</code> 平台，还支持 <code>OpenWrt/LEDE</code> 开源路由器项目。</p><blockquote><p>下载地址：<a href="https://www.zerotier.com/download/">https://www.zerotier.com/download/</a></p></blockquote><p>这里以 <code>Ipad</code> 、<code>Andriod </code>、<code>Archlinux</code> 设备为例介绍一下客户端如何与 <code>planet</code> 相连接挂载到内网地址。</p><p><code>ios</code> 设备通过 <code>Appstore</code> 下载，<code>Andriod</code> 设备通过下载地址下载即可。<code>Network ID</code>，配置好 <code>VPN</code> 后就会启动连接。</p><p><code>SUBNET</code> 是 <code>Zerotier One</code> 使用 <code>STUN</code> 和隧道建立的 <code>NAT</code>，可以更改内网 ip 网段。<code>NODES</code> 是连入 <code>NETWORK</code> 的设备数，以及建立时间 <code>CREATED</code>。</p><p><img src="/assets/IMG20240310165324.jpg"></p><p><img src="/assets/IMG20240310165251.jpg"></p><p><code>Android</code> 使用方法同理。</p><img src=/assets/Screenshot20240310165506.jpg width=60% /><img src=/assets/Screenshot20240310165517.jpg width=60% /><p><code>Archlinux</code> 在 <code>Termial</code> 中使用命令行下载和启动。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装zerotier-one</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">sudo</span> pacman -S zerotier-one</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">开启和加入开机自启</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl start zerotier-one.service</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl <span class="built_in">enable</span> zerotier-one.service</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">加入、离开、列出网络</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">sudo</span> zerotier-cli <span class="built_in">join</span> [此处<span class="built_in">id</span>]</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">sudo</span> zerotier-cli leave</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">sudo</span> zerotier-cli listnetworks</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取地址和服务状态</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">sudo</span> zerotier-cli status</span></span><br><span class="line"> </span><br></pre></td></tr></table></figure><p>这时会根据 <code>MAC</code> 地址分配给设备一个唯一认证字符串 <code>Node ID</code>，可用来在 <code>Web</code> 配置界面保留该设备不被删除以及帮助我们区分设备。我们在 <code>Auth?</code> 处勾上就可以让设备连接到 <code>planet</code> 中。</p><p><img src="/assets/Pastedimage20240310170348.png"></p><h2 id="Ipad-SSH"><a href="#Ipad-SSH" class="headerlink" title="Ipad SSH"></a>Ipad SSH</h2><p>理论上来说在同一个局域网下 <code>ssh</code> 可以通过设备的 <code>IP</code> 地址来连接，此时我们通过 <code>Zerotier</code> 使不同局域网下的设备处于统一 <code>Networks</code> 下，只要 <code>ssh Managed IP</code> 即可完成设备间的互访。</p><h3 id="Termius"><a href="#Termius" class="headerlink" title="Termius"></a>Termius</h3><p><code>Termius</code> 是一个非常好用的 <code>SSH</code> 客户端，免费版就已经提供了 <code>SSH</code> 功能，满足我们连接并操作 <code>Archlinux </code> 的需求。<code>IOS</code> 通过 <code>appstore</code> 下载，<code>Andriod</code> 通过 <code>google play</code> 商店下载，这里以 <code>ipad</code> 设备为例对 <code>archlinux</code> 设备进行访问。在 termius 的设置中要输入连接名称 alias (随便取)、IP 地址（这里你要访问设备的 Managed IP 地址，在 Zerotier 配置页面）、SSH 端口号、用户名与密码。</p><p><img src="/assets/IMG20240310172148.jpg"></p><img src=/assets/IMG20240310171845.jpg width=60% /><h3 id="SSH"><a href="#SSH" class="headerlink" title="SSH"></a>SSH</h3><p>Archlinux 需要设置 SSH 服务，下载配置命令如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">下载SSH</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">sudo</span> pacman -S openssh</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">运行Open SSH</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">sudo</span> systemctl start sshd</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看Open SSH状态</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">sudo</span> systemctl status sshd</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">终止SSH服务器</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">sudo</span> systemctl stop sshd</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">系统重新启动时自动启动 SSH 服务器</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">sudo</span> systemctl <span class="built_in">enable</span> sshd</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">从系统启动中删除</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">sudo</span> systemctl <span class="built_in">disable</span> sshd</span></span><br></pre></td></tr></table></figure><p>下载配置启动 SSH 之后我们要对 SSH 配置文件中修改一些选项，以方便 ipad 或者其他设备可以连接到 linux服务器。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">sudo</span> nvim /etc/ssh/sshd_config</span> </span><br></pre></td></tr></table></figure><p>我们可以在这个配置文件中修改我们的 SSH 端口，默认是 22。以及 Authentication 的状态，将 <code>PermitRootLogin</code> 设置为 <code>yes</code> 并且取消注释，就可以让访问设备打开 ROOT 权限。通过 <code>PubkeyAuthentication</code> 设置为 <code>yes</code> 那么只能允许服务器承认的 key 可以连接。修改完配置文件使用 <code>sudo systemctl restart sshd</code> 重新打开 ssh。</p><img src=/assets/Pastedimage20240310173333.png width=40% /><img src=/assets/Pastedimage20240310173420.png width=40% /><img src=/assets/Pastedimage20240310173550.png width=100% /><h3 id="测试设备间互访"><a href="#测试设备间互访" class="headerlink" title="测试设备间互访"></a>测试设备间互访</h3><p>不同网络访问：<code>Archlinux</code> 连接 <code>5g</code> 网络，<code>iPad</code> 连接 <code>wifi</code>。</p><p><img src="/assets/IMG20240310174149.jpg"></p><p>从图中我们可以看到已经成功连接上了 <code>Archlinux</code> 的 <code>SSH</code>。由于免费的根服务器在国外，可能访问速度不太稳定。 </p><h2 id="笔记本不休眠"><a href="#笔记本不休眠" class="headerlink" title="笔记本不休眠"></a>笔记本不休眠</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">编辑文件</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">sudo</span> nvim /etc/systemd/logind.conf</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将其中</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">HandleLidSwitch=<span class="built_in">suspend</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">去掉前面的#改成</span></span><br><span class="line">HandleLidSwitch=ignore</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">最后重启服务</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Tools </tag>
            
            <tag> Archlinux </tag>
            
            <tag> Termius </tag>
            
            <tag> Zerotier </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
